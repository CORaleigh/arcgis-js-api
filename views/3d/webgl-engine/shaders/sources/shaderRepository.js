// COPYRIGHT Â© 2018 Esri
//
// All rights reserved under the copyright laws of the United States
// and applicable international laws, treaties, and conventions.
//
// This material is licensed for use under the Esri Master License
// Agreement (MLA), and is bound by the terms of that agreement.
// You may redistribute and use this code without modification,
// provided you adhere to the terms of the MLA and include this
// copyright notice.
//
// See use restrictions at http://www.esri.com/legal/pdfs/mla_e204_e300/english
//
// For additional information, contact:
// Environmental Systems Research Institute, Inc.
// Attn: Contracts and Legal Services Department
// 380 New York Street
// Redlands, California, USA 92373
// USA
//
// email: contracts@esri.com
//
// See http://js.arcgis.com/4.11/esri/copyright.txt for details.

define(["require","exports"],function(e,n){return{edgeRenderer:{"adjustProjectedPosition.glsl":"uniform vec2 uDepthBias;\nuniform vec2 uViewportDimInv;\n\n// Utility function to check for NaN values\nbool isNaN(float val) {\n  return ( val < 0.0 || 0.0 < val || val == 0.0 ) ? false : true;\n  // important: some nVidias failed to cope with version below.\n  // Probably wrong optimization.\n  /*return ( val <= 0.0 || 0.0 <= val ) ? false : true;*/\n}\n\n// An offset in xy screen space, along the projected normal of the edge\n// This reduces depth fighting when looking at a face from a flat angle\nvec2 calculateProjectedBiasXY(vec4 projPos, vec3 worldNormal) {\n  float offsetXY = uDepthBias.x;\n  float offsetZ  = uDepthBias.y;\n\n  // screen space pixel offset\n  // we multiply by two to account for the fact that NDC go from -1 to 1\n  // we multiply by projPos.w to compensate for the perspective divison that happens later\n  // normalizing over xyz means that the xy influence is reduced the more the normal is pointing\n  // towards the camera\n  vec4 projNormal = uProj * uView * vec4(worldNormal, 0.0);\n\n  return offsetXY * projPos.w * 2.0 * uViewportDimInv * normalize(projNormal.xyz).xy;\n}\n\n// A z-offset, using a depth based heuristic.\nfloat calculateProjectedBiasZ(vec4 projPos) {\n  float offsetZ = uDepthBias.y;\n  return sqrt(projPos.z) * offsetZ;\n}\n\nvec4 adjustProjectedPosition(vec4 projPos, vec3 worldNormal, float lineWidth) {\n  vec2 offsetXY = calculateProjectedBiasXY(projPos, worldNormal);\n\n  // we currently have to do this check because some geometries come with 0 length edge normals.\n  // see https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/12890\n  if (!isNaN(offsetXY.x) && !isNaN(offsetXY.y)) {\n    projPos.xy += offsetXY;\n  }\n\n  projPos.z += calculateProjectedBiasZ(projPos);\n\n  return projPos;\n}\n","edgeRenderer.frag":"#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n\nvarying vec4 vColor;\nvarying float vRadius;\nvarying vec3 vPosition;\nvarying vec3 vWorldPosition;\nvarying float vLineLengthPixels;\nvarying float vSizeFalloffFactor;\nvarying float vLineIndex;\n\n// At which coverage threshold we discard a fragment completely\n#define COVERAGE_TEST_THRESHOLD 0.01\n\n#include <edgeRenderer/lineOffset.glsl>\n\nvec2 lineWithCapsDistance(float radius, vec2 position, float lineLength) {\n  float lineOffset = calculateLineOffset();\n  float positionX = position.x - lineOffset;\n\n  if (radius < 1.0) {\n    // Handle this specifically for subpixel sizes:\n    // 1. Compute correct coverage (note coverage is computed by\n    //    0.5 - dist, so we make sure that that will lead to correct\n    //    subpixel coverage\n    // 2. Ignore rounded caps\n    float coverageX = clamp(min(radius, positionX + 0.5) - max(-radius, positionX - 0.5), 0.0, 1.0);\n    float coverageY = clamp(min(lineLength, position.y + 0.5) - max(0.0, position.y - 0.5), 0.0, 1.0);\n\n    float coverage = min(coverageX, coverageY);\n\n    return vec2(0.5 - coverage, 0.0);\n  }\n  else {\n    // Between -radius -> 0 for start cap, 0 for line, 0 -> radius\n    float positionOnCap = position.y - clamp(position.y, 0.0, lineLength);\n\n    vec2 lineToPosition = vec2(positionX, positionOnCap);\n    return vec2(length(lineToPosition) - radius, positionOnCap / radius);\n  }\n}\n\nvoid main() {\n\n  float radius = vRadius * calculateLinePressure();\n\n  vec2 distance = lineWithCapsDistance(radius, vPosition.xy, vLineLengthPixels);\n  float coverage = clamp(0.5 - distance.x, 0.0, 1.0);\n\n#ifdef ANTIALIASING\n\n  const float coverageLimit = COVERAGE_TEST_THRESHOLD;\n\n#else /* ANTIALIASING */\n\n  // Use subpixel coverage computation when lines get subpixel widths\n  // so we still render them appropriately. Otherwise discard anything\n  // that is not fully within the line\n  float coverageLimit = radius <= 0.5 ? COVERAGE_TEST_THRESHOLD : 0.75;\n\n#endif /* ANTIALIASING */\n\n  if (coverage < coverageLimit) {\n    discard;\n  }\n\n  discardBySlice(vWorldPosition);\n\n  float alpha = vColor.a * coverage;\n\n  gl_FragColor = vec4(vColor.rgb, alpha);\n}\n","edgeRenderer.vert":"#include <util/vsPrecision.glsl>\n\n// Transformations\nuniform mat4 uProj;\nuniform mat4 uView;\nuniform mat4 uModel;\nuniform vec3 uCameraPosition;\n\n// Line configuration\n\n// Conversion constants\nuniform vec2 uPixelToNDC;\nuniform vec2 uNDCToPixel;\nuniform float uPixelRatio;\n\n// Inputs\nattribute vec3 aPosition0;\nattribute vec3 aPosition1;\nattribute float aVariantOffset;\nattribute float aVariantStroke;\nattribute float aVariantExtension;\n\n#ifdef SILHOUETTE\n\nattribute vec3 aNormalA;\nattribute vec3 aNormalB;\n\n#else /* SILHOUETTE */\n\nattribute vec3 aNormal;\n\n#endif /* SILHOUETTE */\n\nattribute vec2 aSideness;\nattribute vec2 aPackedAttributes;\n\nstruct UnpackedAttributes {\nvec2 sideness;\nvec2 sidenessNorm;\nfloat lineWidthPixels;\nfloat extensionLengthPixels;\n\n#if (MODE == MODE_UBER)\n\nfloat type;\n\n#endif\n};\n\n// Output required to compute color\nvarying vec4 vColor;\n\n// Output required to compute distance to line/caps\nvarying vec3 vPosition;\nvarying vec3 vWorldPosition;\nvarying float vRadius;\nvarying float vLineLengthPixels;\nvarying float vSizeFalloffFactor;\n\n#include <edgeRenderer/adjustProjectedPosition.glsl>\n#include <edgeRenderer/styleOutputs.glsl>\n#include <edgeRenderer/lineAmplitude.glsl>\n#include <edgeRenderer/util.glsl>\n\nvec4 calculateGeometricOutputs(vec4 viewPosV0, vec4 viewPosV1, vec4 worldPosV0, vec4 worldPosV1, vec3 worldNormal, UnpackedAttributes unpackedAttributes) {\n  vec2 sideness = unpackedAttributes.sideness;\n  vec2 sidenessNorm = unpackedAttributes.sidenessNorm;\n\n  vWorldPosition = mix(worldPosV0, worldPosV1, sidenessNorm.y).xyz;\n\n  vec4 viewPos = mix(viewPosV0, viewPosV1, sidenessNorm.y);\n  vec4 projPosV0 = uProj * viewPosV0;\n  vec4 projPosV1 = uProj * viewPosV1;\n  vec4 projPos = uProj * viewPos;\n\n  vec3 screenSpaceLineNDC = (projPosV1.xyz / projPosV1.w - projPosV0.xyz / projPosV0.w);\n  vec2 screenSpaceLinePixels = screenSpaceLineNDC.xy * uNDCToPixel;\n  float lineLengthPixels = length(screenSpaceLinePixels);\n\n  float dzPerPixel = screenSpaceLineNDC.z / lineLengthPixels;\n  vec2 screenSpaceDirection = screenSpaceLinePixels / lineLengthPixels;\n  vec2 perpendicularScreenSpaceDirection = vec2(screenSpaceDirection.y, -screenSpaceDirection.x) * sideness.x;\n\n  float falloffFactor = distanceBasedPerspectiveFactor(-viewPos.z) * uPixelRatio;\n  float lineWidthPixels = unpackedAttributes.lineWidthPixels * falloffFactor;\n\n  float extensionLengthPixels = calculateExtensionLength(unpackedAttributes.extensionLengthPixels, lineLengthPixels) * falloffFactor;\n  float lineAmplitudePixels = calculateLineAmplitude(unpackedAttributes) * uPixelRatio;\n\n  vSizeFalloffFactor = falloffFactor;\n\n  float lineWidthAndAmplitudePixels = lineWidthPixels + lineAmplitudePixels + lineAmplitudePixels;\n  float extendedLineLengthPixels = lineLengthPixels + extensionLengthPixels + extensionLengthPixels;\n\n#ifdef ANTIALIASING\n\n  const float aaPaddingPixels = 1.0;\n\n  // Line size with padding\n  float halfAAPaddedLineWidthAndAmplitudePixels = lineWidthAndAmplitudePixels * 0.5 + aaPaddingPixels;\n  float aaPaddedRoundedCapSizePixels = lineWidthPixels * 0.5 + aaPaddingPixels;\n\n  // Line length with padding\n  float aaPaddedLineLengthPixels = extendedLineLengthPixels + aaPaddingPixels + aaPaddingPixels;\n  float halfAAPaddedLineLengthPixels = aaPaddedLineLengthPixels * 0.5;\n\n#else /* ANTIALIASING */\n\n  // Even if there is no AA, we still want to do proper <1px rendering,\n  // so we effectively clamp the pixel sizes to minimum of 1px and compute\n  // coverage in the fragment shader\n  float halfAAPaddedLineWidthAndAmplitudePixels = max(lineWidthAndAmplitudePixels, 1.0) * 0.5;\n  float aaPaddedRoundedCapSizePixels = max(lineWidthPixels, 1.0) * 0.5;\n\n  float halfAAPaddedLineLengthPixels = max(extendedLineLengthPixels, 1.0) * 0.5;\n\n#endif /* ANTIALIASING */\n\n  // Half line width in NDC including padding for anti aliasing\n  vec2 halfAAPaddedLineWidthAndAmplitudeNDC = halfAAPaddedLineWidthAndAmplitudePixels * uPixelToNDC;\n  vec2 aaPaddedRoundedCapSizeNDC = aaPaddedRoundedCapSizePixels * uPixelToNDC;\n  vec2 extensionLengthNDC = extensionLengthPixels * uPixelToNDC;\n\n  // Compute screen space position of vertex, offsetting for line size and end caps\n  vec2 ndcOffset = (\n      screenSpaceDirection * sideness.y * (aaPaddedRoundedCapSizeNDC + extensionLengthNDC)\n    + perpendicularScreenSpaceDirection * halfAAPaddedLineWidthAndAmplitudeNDC\n  );\n\n  projPos.xy += ndcOffset * projPos.w;\n  projPos.z += (dzPerPixel * (aaPaddedRoundedCapSizePixels + extensionLengthPixels)) * sideness.y * projPos.w;\n\n  projPos = adjustProjectedPosition(projPos, worldNormal, 1.0 + max((lineWidthAndAmplitudePixels - 1.0) * 0.5, 0.0));\n\n  // Line length with end caps\n  float aaPaddedLineWithCapsLengthPixels = extendedLineLengthPixels + aaPaddedRoundedCapSizePixels + aaPaddedRoundedCapSizePixels;\n\n  float pixelPositionAlongLine = aaPaddedLineWithCapsLengthPixels * sidenessNorm.y - aaPaddedRoundedCapSizePixels;\n\n  // Position in pixels with origin at first vertex of line segment\n  vPosition = vec3(\n    halfAAPaddedLineWidthAndAmplitudePixels * sideness.x,\n    pixelPositionAlongLine,\n    pixelPositionAlongLine / extendedLineLengthPixels\n  );\n\n  // The line width radius in pixels\n  vRadius = lineWidthPixels * 0.5;\n  vLineLengthPixels = extendedLineLengthPixels;\n\n#ifdef SILHOUETTE\n\n  gl_Position = isSilhouetteEdge(viewPosV0, aNormalA, aNormalB) ? projPos : vec4(10.0, 10.0, 10.0, 1.0);\n\n#else /* SILHOUETTE */\n\n  gl_Position = projPos;\n\n#endif /* SILHOUETTE */\n\n#if (MODE == MODE_UBER)\n\n  if (unpackedAttributes.type <= 0.0 && lineLengthPixels <= 3.0) {\n    gl_Position = vec4(10.0, 10.0, 10.0, 1.0);\n  }\n\n#elif (MODE == MODE_SKETCH)\n\n  if (lineLengthPixels <= 3.0) {\n    gl_Position = vec4(10.0, 10.0, 10.0, 1.0);\n  }\n\n#endif\n\n  return projPos;\n}\n\n#if (MODE == MODE_UBER)\n\nUnpackedAttributes unpackAttributes(ComponentData component) {\n\n  vec2 sidenessNorm = aSideness;\n  vec2 sideness = sidenessNorm * 2.0 - 1.0;\n\n  float fType = component.type;\n  float extensionLengthPixels = component.extensionLength;\n  float lineWidth = component.lineWidth;\n\n  if (fType <= 0.0) {\n    extensionLengthPixels *= aVariantExtension * 2.0 - 1.0;\n  }\n\n  return UnpackedAttributes(sideness, sidenessNorm, lineWidth, extensionLengthPixels, fType);\n}\n\n#else /* (MODE == MODE_UBER) */\n\nUnpackedAttributes unpackAttributes(ComponentData component) {\n  vec2 sidenessNorm = aSideness;\n  vec2 sideness = sidenessNorm * 2.0 - 1.0;\n  float extensionLengthPixels = component.extensionLength;\n\n#if (MODE == MODE_SKETCH)\n\n  extensionLengthPixels *= aVariantExtension * 2.0 - 1.0;\n\n#endif\n\n  float lineWidth = component.lineWidth;\n\n  return UnpackedAttributes(sideness, sidenessNorm, lineWidth, extensionLengthPixels);\n}\n\n#endif /* (MODE == MODE_UBER) */\n\nvoid main() {\n  ComponentData component = readComponentData();\n  UnpackedAttributes unpackedAttributes = unpackAttributes(component);\n\n  vec4 worldPosV0 = uModel * vec4(aPosition0, 1.0);\n  vec4 worldPosV1 = uModel * vec4(aPosition1, 1.0);\n\n  vec4 viewPosV0 = uView * worldPosV0;\n  vec4 viewPosV1 = uView * worldPosV1;\n\n#ifdef SILHOUETTE\n\n  vec3 worldNormal = silhouetteWorldNormal(aNormalA, aNormalB);\n\n#else /* SILHOUETTE */\n\n  vec3 worldNormal = modelToWorldNormal(aNormal);\n\n#endif /* SILHOUETTE */\n\n  // General geometric computation for all types of edges\n  vec4 projPos = calculateGeometricOutputs(viewPosV0, viewPosV1, worldPosV0, worldPosV1, worldNormal, unpackedAttributes);\n\n  // Component color\n  vColor = component.color;\n\n  // Specific computation for different edge styles\n  calculateStyleOutputs(viewPosV0, viewPosV1, worldPosV0, worldPosV1, projPos, worldNormal, unpackedAttributes);\n}\n","lineAmplitude.glsl":"// Solid\n\n#if (MODE == MODE_UBER || MODE == MODE_SOLID)\n\n  float calculateLineAmplitudeSolid() {\n    return 0.0;\n  }\n\n#endif\n\n#if (MODE == MODE_SOLID)\n\n  float calculateLineAmplitude(UnpackedAttributes unpackedAttributes) {\n    return calculateLineAmplitudeSolid();\n  }\n\n#endif\n\n// Sketch\n\n#if (MODE == MODE_UBER || MODE == MODE_SKETCH)\n\n  uniform float uStrokesAmplitude;\n\n  float calculateLineAmplitudeSketch() {\n    return uStrokesAmplitude;\n  }\n\n#endif\n\n#if (MODE == MODE_SKETCH)\n\n  float calculateLineAmplitude(UnpackedAttributes unpackedAttributes) {\n    return calculateLineAmplitudeSketch();\n  }\n\n#endif\n\n// Uber\n\n#if (MODE == MODE_UBER)\n\n  float calculateLineAmplitude(UnpackedAttributes unpackedAttributes) {\n    float type = unpackedAttributes.type;\n\n    if (type <= 0.0) {\n      return calculateLineAmplitudeSketch();\n    }\n    else {\n      return calculateLineAmplitudeSolid();\n    }\n  }\n\n#endif\n","lineOffset.glsl":"#include <util/encoding.glsl>\n\n// Sketch\n\n#if (MODE == MODE_UBER || MODE == MODE_SKETCH)\n\n  uniform sampler2D uStrokesTexture;\n  uniform float uStrokesNormalizationScale;\n\n  varying vec2 vStrokeUV;\n\n  float calculateLineOffsetSketch() {\n    float offsetNorm = rgba2float(texture2D(uStrokesTexture, vStrokeUV));\n    return (offsetNorm - 0.5) * uStrokesNormalizationScale;\n  }\n\n  float calculateLinePressureSketch() {\n    return rgba2float(texture2D(uStrokesTexture, vStrokeUV + vec2(0.0, 0.5)));\n  }\n\n#endif\n\n#if (MODE == MODE_SKETCH)\n\n  float calculateLineOffset() {\n    return calculateLineOffsetSketch();\n  }\n\n  float calculateLinePressure() {\n    return calculateLinePressureSketch();\n  }\n\n#endif\n\n// Solid\n\n#if (MODE == MODE_UBER || MODE == MODE_SOLID)\n\n  float calculateLineOffsetSolid() {\n    return 0.0;\n  }\n\n  float calculateLinePressureSolid() {\n    return 1.0;\n  }\n\n#endif\n\n#if (MODE == MODE_SOLID)\n\n  float calculateLineOffset() {\n    return calculateLineOffsetSolid();\n  }\n\n  float calculateLinePressure() {\n    return calculateLinePressureSolid();\n  }\n\n#endif\n\n// Uber\n\n#if (MODE == MODE_UBER)\n  varying float vType;\n\n  float calculateLineOffset() {\n    if (vType <= 0.0) {\n      return calculateLineOffsetSketch();\n    }\n    else {\n      return calculateLineOffsetSolid();\n    }\n  }\n\n  float calculateLinePressure() {\n    if (vType <= 0.0) {\n      return calculateLinePressureSketch();\n    }\n    else {\n      return calculateLinePressureSolid();\n    }\n  }\n#endif\n","styleOutputs.glsl":"#if (MODE == MODE_UBER || MODE == MODE_SKETCH)\n\n  uniform vec2 uStrokesTextureScale;\n  uniform float uStrokesLog2Resolution;\n  uniform float uStrokeVariants;\n\n  varying vec2 vStrokeUV;\n  varying float vLineIndex;\n\n  void calculateStyleOutputsSketch(float lineLength, UnpackedAttributes unpackedAttributes) {\n    vec2 sidenessNorm = unpackedAttributes.sidenessNorm;\n\n    float lineIndex = clamp(ceil(log2(lineLength)), 0.0, uStrokesLog2Resolution);\n\n    vStrokeUV = vec2(exp2(lineIndex) * sidenessNorm.y, lineIndex * uStrokeVariants + aVariantStroke + 0.5) * uStrokesTextureScale;\n    vStrokeUV.x += aVariantOffset;\n\n    vLineIndex = lineIndex;\n  }\n#endif\n\n#if (MODE == MODE_SOLID)\n  void calculateStyleOutputs(vec4 viewPosV0, vec4 viewPosV1, vec4 worldPosV0, vec4 worldPosV1, vec4 projPos, vec3 worldNormal, UnpackedAttributes unpackedAttributes) {\n  }\n#elif (MODE == MODE_SKETCH)\n  void calculateStyleOutputs(vec4 viewPosV0, vec4 viewPosV1, vec4 worldPosV0, vec4 worldPosV1, vec4 projPos, vec3 worldNormal, UnpackedAttributes unpackedAttributes) {\n    calculateStyleOutputsSketch(vLineLengthPixels, unpackedAttributes);\n  }\n#elif (MODE == MODE_UBER)\n  varying float vType;\n\n  void calculateStyleOutputs(vec4 viewPosV0, vec4 viewPosV1, vec4 worldPosV0, vec4 worldPosV1, vec4 projPos, vec3 worldNormal, UnpackedAttributes unpackedAttributes) {\n    vType = unpackedAttributes.type;\n\n    if (unpackedAttributes.type <= 0.0) {\n      calculateStyleOutputsSketch(vLineLengthPixels, unpackedAttributes);\n    }\n  }\n#endif\n","util.glsl":"uniform float uDistanceFalloffFactor;\n\nfloat distanceBasedPerspectiveFactor(float distance) {\n  return clamp(sqrt(uDistanceFalloffFactor / distance), 0.0, 1.0);\n}\n\nuniform sampler2D uComponentDataTex;\nuniform vec2 uComponentDataTexInvDim;\n\nattribute float aComponentIndex;\n\n#define COMPONENT_COLOR_FIELD_OFFSET 0.0\n#define COMPONENT_OTHER_FIELDS_OFFSET 1.0\n#define COMPONENT_FIELD_COUNT 2.0\n\n#define LINE_WIDTH_FRACTION_FACTOR 8.0\n#define EXTENSION_LENGTH_OFFSET 128.0\n\n#define COMPONENT_TEX_WIDTH 4096.0\n\nvec2 componentTextureCoords(float componentIndex, float fieldOffset) {\n  float fieldIndex = COMPONENT_FIELD_COUNT * componentIndex + fieldOffset;\n\n  float rowIndex = floor(fieldIndex / COMPONENT_TEX_WIDTH);\n  float colIndex = mod(fieldIndex, COMPONENT_TEX_WIDTH);\n\n  vec2 linearIndex = vec2(\n    (colIndex + 0.5) / COMPONENT_TEX_WIDTH,\n    (rowIndex + 0.5) * uComponentDataTexInvDim.y\n  );\n\n  return linearIndex;\n}\n\nstruct ComponentData {\n  vec4 color;\n  float lineWidth;\n  float extensionLength;\n  float type;\n};\n\nComponentData readComponentData() {\n  vec2 colorIndex = componentTextureCoords(aComponentIndex, COMPONENT_COLOR_FIELD_OFFSET);\n  vec2 otherIndex = componentTextureCoords(aComponentIndex, COMPONENT_OTHER_FIELDS_OFFSET);\n\n  vec4 colorValue = texture2D(uComponentDataTex, colorIndex);\n  vec4 otherValue = texture2D(uComponentDataTex, otherIndex);\n\n  return ComponentData(\n    vec4(colorValue.rgb, colorValue.a * otherValue.w), // otherValue.w stores separate opacity\n    otherValue.x * (255.0 / LINE_WIDTH_FRACTION_FACTOR),\n    otherValue.y * 255.0 - EXTENSION_LENGTH_OFFSET,\n    -(otherValue.z * 255.0) + 0.5 // SOLID (=0/255) needs to be > 0.0, SKETCHY (=1/255) needs to be <= 0;\n  );\n}\n\nvec3 modelToWorldNormal(vec3 normal) {\n  return (uModel * vec4(normal, 0.0)).xyz;\n}\n\nvec3 silhouetteWorldNormal(vec3 normalA, vec3 normalB) {\n  return modelToWorldNormal(normalize(normalA + normalB));\n}\n\n// Fall-off extension length for shorter strokes, starting from strokes that are 256 size,\n// fall-off exponentially\nfloat calculateExtensionLength(float extensionLength, float lineLength) {\n  return extensionLength / (log2(max(1.0, 256.0 / lineLength)) * 0.2 + 1.0);\n}\n\n#ifdef SILHOUETTE\n\n// #uniforms: uView, uModel\nbool isSilhouetteEdge(vec4 viewPos, vec3 normalA, vec3 normalB) {\n  // transform the two face normals\n  vec3 viewNormalA = (uView * uModel * vec4(normalA, 0.0)).xyz;\n  vec3 viewNormalB = (uView * uModel * vec4(normalB, 0.0)).xyz;\n\n  // compute the direction from the edge to the camera\n  vec3 viewDir = -viewPos.xyz;\n\n  // check which of the two faces are visible\n  // display the edge if exactly one of the two is visible\n  float faceAVisible = dot(viewDir, viewNormalA); // positive if visible\n  float faceBVisible = dot(viewDir, viewNormalB); // positive if visible\n\n  // 1 if exactly one face visible, 0 otherwise\n  return faceAVisible * faceBVisible < 0.0;\n}\n\n#endif /* SILHOUETTE */\n"},environment:{
"realisticAtmosphere.frag":"#include <util/fsPrecision.glsl>\n#include <util/encoding.glsl>\n#include <util/color.glsl>\n\n// Light\nuniform vec3 v3LightDir;      // The direction vector to the light source\nuniform vec3 v3InvWavelength; // 1 / pow(wavelength, 4) for the red, green, and blue channels\nuniform vec3 v3InvWavelengthScaled; //v3InvWavelength * fKr4PI + fKm4PI\n\n// Atmosphere\nconst float fKrESun = 0.075;        // Kr * ESun = 0.005 * 15.0\nconst float fKmESun = 0.015;        // Km * ESun = 0.005 * 15\n\n// Radii\nuniform vec4 v4Radii; // (fInnerRadius, fInnerRadius^2, fOuterRadius, fOuterRadius^2)\n\n// The inner (planetary) radius\n#define fInnerRadius v4Radii[0]\n// fInnerRadius^2\n#define fInnerRadius2 v4Radii[1]\n// The outer (atmosphere) radius\n#define fOuterRadius v4Radii[2]\n// fOuterRadius^2\n#define fOuterRadius2 v4Radii[3]\n\n// Atmosphere parameters:\n// fScale:                    1.0 / (fOuterRadius - fInnerRadius)\n// fScaleDepth:               The scale depth (i.e. the altitude at which the atmosphere's average density is found)\n// fScaleOverScaleDepth:      fScale / fScaleDepth\n// fOneOverScaleDepth:        1.0 / fScaleDepth\n\n// fScaleDepthBlue:           The scale depth (i.e. the altitude at which the atmosphere's average density is found)\n// fScaleOverScaleDepthBlue:  fScale / fScaleDepthBlue\n// fOneOverScaleDepthBlue;    1.0 / fScaleDepthBlue\n\nuniform vec4 v4AtmosParams1; // (fScale, fScaleDepth, fScaleOverScaleDepth, fOneOverScaleDepth)\nuniform vec4 v4AtmosParams2; // (g, fScaleDepthBlue, fScaleOverScaleDepthBlue, fOneOverScaleDepthBlue)\n\n#define fScale v4AtmosParams1.x\n// fScaleDepth, fScaleDepthBlue\n#define v2ScaleDepth vec2(v4AtmosParams1.y,v4AtmosParams2.y)\n// fScaleOverScaleDepth, fScaleOverScaleDepthBlue\n#define v2ScaleOverScaleDepth vec2(v4AtmosParams1.z,v4AtmosParams2.z)\n// fOneOverScaleDepth, fOneOverScaleDepthBlue\n#define v2OneOverScaleDepth vec2(v4AtmosParams1.w,v4AtmosParams2.w)\n\n#ifndef HAZE\nuniform vec4 v4AtmosParams3; // (g2, fMiePhaseCoefficients, fLowerAlphaBlendBound, fOneOverOuterRadiusMinusAlphaBlendBound)\nuniform float fInnerFadeDistance;\nuniform float fAltitudeFade;\n\n#define fg v4AtmosParams2.x\n#define fg2 v4AtmosParams3.x\n#define fMiePhaseCoefficients v4AtmosParams3.y\n#define fLowerAlphaBlendBound v4AtmosParams3.z\n#define fOneOverOuterRadiusMinusAlphaBlendBound v4AtmosParams3.w\n#endif\n\n// Camera\nuniform vec3 v3CameraPos;     // The camera's current position\nuniform vec2 nearFar;\n\nuniform vec4 v4SphereComp;              // (fCameraHeight, fCameraHeight2, fC, fCSur)\n// The camera's current height\n#define fCameraHeight v4SphereComp[0]\n// fCameraHeight^2\n#define fCameraHeight2 v4SphereComp[1]\n// fCameraHeight2 - fOuterRadius2; // C = ||o-c||^2 - r^2\n#define fC v4SphereComp[2]\n// fCameraHeight2 - (fInnerRadius2 - 63756370000.0); // C = ||o-c||^2 - r^2\n#define fCSur v4SphereComp[3]\n\n// Camera HDR\n#ifdef HAZE\nconst float fExposure = 1.5;\n#else\nconst float fExposure = 2.0;\n#endif\n\n#ifdef HAZE\n// Depth texture\nuniform sampler2D tDepth;\n#endif\n\n// Testing variables\nuniform float showTest;\n\n// Varyings\nvarying vec3 v3EyeDir;\nvarying vec3 v3WorldRay;\nvarying vec2 vtc;\n\n// Loop constants for integral approximation\nconst float fSamples = 5.0;\nconst int maxSamples = 5;\n\n#ifdef HAZE\n  const float fOneOverGamma = 1.0;//Gamma = 1.0\n#else\n  const float fOneOverGamma = 0.454545; // Gamma = 2.2\n#endif\n\nconst vec3 v3OneOverGamma = vec3(fOneOverGamma);\n\n// ToneMapping operators\nvec3 expTM(vec3 inputColor,float exposure){\n    return pow(1.0 - exp(inputColor * -exposure), v3OneOverGamma);\n}\n\n#ifndef HAZE\nvec3 reinhardTM(vec3 inputColor, float exposure){\n  vec3 intermediate = inputColor *exposure;\n  intermediate /= (1.0+intermediate);\n  return pow(intermediate, v3OneOverGamma);\n}\n#endif\n\n// Approximation for inner integral based on a radii ratio of 10.25:10\nfloat scale(float fCos){\n  float x = 1.0 - fCos;\n  return exp(-0.00287 + x*(0.459 + x*(3.83 + x*(-6.80 + x*5.25))));\n}\n\nvoid main() {\n  vec3 cameraPosition = v3CameraPos;\n\n  // Debug variables\n  vec3 test = vec3(0.0,0.0,0.0);\n\n  // Obtain ray from Camera\n  vec3 worldSpaceRay = normalize(v3WorldRay);\n\n  // Compute Atmosphere intersection; i.e. ray/sphere intersection\n  float B = 2.0 * dot(cameraPosition, worldSpaceRay); // B = 2(l * (o-c))\n  float det = B*B - 4.0 * fC; // det = B^2 - 4.0* C\n\n  // idealized sphere intersection to discard early some pixels\n  float detSur = B*B - 4.0 * fCSur; // det = B^2 - 4.0* C\n\n  // the minimal sample start position:\n  // at the camera by default, on the earth radius surface if the camera is underground.\n  float fMinRayStart = 0.0;\n#ifndef HAZE\n  // When the ray intersects the earth surface, fade the sky to a simple light direction\n  // based color. This is used to make sure we have a white background in underground\n  // mode (at noon).\n  float fSurfaceBlend = 0.0;\n  vec4 surfaceColor = vec4(0.0);\n  if (detSur >= 0.0) {\n    float nearSurfaceT = max(0.0, 0.5 *(-B - sqrt(detSur)));\n    float farSurfaceT = max(0.0, 0.5 *(-B + sqrt(detSur)));\n\n    if (nearSurfaceT == 0.0) {\n      fMinRayStart = farSurfaceT;\n    }\n\n    // Compute lighting at the point where the ray enters the earth surface\n    // Lighting computation is copied from the terrain shader.\n    vec3 vPos = cameraPosition + worldSpaceRay * nearSurfaceT;\n    float fLightAngle = dot(v3LightDir, normalize(vPos));\n    float fBrightness = max(0.0, (smoothstep(-1.0, 0.8, 2.0 * fLightAngle)));\n\n    // Make the surface transparent based on altitude\n    surfaceColor = vec4(fBrightness, fBrightness, fBrightness, 1.0 - fAltitudeFade);\n\n    // Fade based on the distance the ray travels below the earth surface\n    float fRelDist = (farSurfaceT - nearSurfaceT) / fInnerFadeDistance;\n\n    // early exit\n    if (fRelDist > 1.0) {\n      gl_FragColor = surfaceColor;\n      return;\n    }\n\n    fSurfaceBlend = smoothstep(0.0, 1.0, fRelDist * fRelDist);\n  }\n#endif\n\n  // Inside Atmosphere\n  if (det >= 0.0) {\n#ifdef HAZE\n    // only use red channel from depth texture.\n    // see 'Issues' at https://www.khronos.org/registry/webgl/extensions/WEBGL_depth_texture\n    float depthSample = texture2D(tDepth, vtc).r;\n\n    float zNear = nearFar[0];\n    float zFar = nearFar[1];\n\n    // http://web.archive.org/web/20130416194336/http://olivers.posterous.com/linear-depth-in-glsl-for-real\n    float zNorm = 2.0 * depthSample - 1.0;\n    float linDepth = 2.0 * zNear * zFar /\n      (zFar + zNear - zNorm * (zFar - zNear));\n\n    float rayEndT;\n    float altitudeAlpha = 1.0;\n\n    // find intersections with ground, but only between the near and far\n    // clipping planes.\n    if (depthSample < 1.0 && depthSample > 0.0) {\n      vec3 cameraSpaceRay = normalize(v3EyeDir);\n      cameraSpaceRay /= cameraSpaceRay.z;\n      cameraSpaceRay *= linDepth;\n\n      float cameraSpaceRayLength = length(cameraSpaceRay);\n\n      vec3 v3World = cameraPosition + worldSpaceRay * cameraSpaceRayLength;\n      float v3WorldRadius2 = dot(v3World, v3World);\n\n      // Handle tall structures:\n      // https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/5450\n      float transitionStart = fInnerRadius + 20000.0;\n      float transitionHeight = 25000.0;\n      float transitionEnd = transitionStart + transitionHeight;\n\n      float edge0 = transitionStart * transitionStart;\n      float edge1 = transitionEnd * transitionEnd;\n\n      altitudeAlpha = 1.0 - clamp((v3WorldRadius2 - edge0) / (edge1 - edge0), 0.0, 1.0);\n      rayEndT = cameraSpaceRayLength;\n\n      if (altitudeAlpha > 0.0 && detSur > 0.0) {\n        float nearSurfaceT = 0.5 *(-B - sqrt(detSur));\n        float interp = clamp(((fCameraHeight - fInnerRadius) - 2000000.0) / 6000000.0, 0.0, 1.0);\n        rayEndT = mix(cameraSpaceRayLength, nearSurfaceT, interp);\n      }\n    }\n#endif\n\n    float rayStartT = 0.5 *(-B - sqrt(det)); //near intersection with atmosphere\n#ifdef HAZE\n    float nearT = abs(rayStartT);\n    float farT = abs(rayEndT);\n#else\n    float rayEndT = 0.5 *(-B + sqrt(det)); //far intersection with atmosphere\n\n#endif\n\n    float fDistance; // calculate its scattering offset\n    // Calculate the ray's starting position\n    if (rayStartT < fMinRayStart)\n    { // ray starts from camera or inner radius sphere to far\n      rayStartT = fMinRayStart;\n#ifndef HAZE\n      // clamp to value at inner radius altitude\n      fDistance = fScale * min(0.0, fInnerRadius - fCameraHeight);\n#endif\n    }\n#ifndef HAZE\n    else\n    { // outside atmosphere\n      fDistance = -1.0;\n    }\n#endif\n\n    // Initialize the scattering loop variables\n    vec3 v3Start = cameraPosition + worldSpaceRay * rayStartT;\n\n#ifdef HAZE\n    vec3 v3End = cameraPosition + worldSpaceRay * rayEndT;\n\n    float fEndLength = length(v3End);\n    float fAltitudeEnd = fEndLength - fInnerRadius;\n    float fAltitudeStart = length(v3Start) - fInnerRadius;\n\n    // for camera positions below altitude 0, invert the altitudes, to achieve\n    // a similar haze as above ground. Note that there is a small but visible change\n    // when the camera passes altitude 0.\n    if (fAltitudeStart < 0.0) {\n      fAltitudeStart = -fAltitudeStart;\n      fAltitudeEnd = -fAltitudeEnd;\n    }\n\n    // computed for the original end point to get consistent light angles after possible inversions\n    float fLightAngle = dot(v3LightDir, v3End) / fEndLength;\n\n    if (nearT > farT)\n    {\n      if (fAltitudeStart < fAltitudeEnd)\n      {\n        // Switch positive slopes for flipped rays\n        v3End = cameraPosition + worldSpaceRay * rayStartT;\n        v3Start = cameraPosition + worldSpaceRay * rayEndT;\n        worldSpaceRay *= -1.0;\n        float fTmp = fAltitudeStart;\n        fAltitudeStart = fAltitudeEnd;\n        fAltitudeEnd = fTmp;\n      }\n      else if (fAltitudeStart == fAltitudeEnd)\n      { // create minuscule fake slope for integration if the slope is zero\n        fAltitudeStart += 1.0; //BUGFIX, if the height of camera and ground is equal the equation breaks, add fake meter to camera height to get\n        // slope for the camera function\n      }\n    }\n\n    // Calculate its scattering offset\n    // Assumes camera constrains of WSV 3.8\n    float fCameraDepth;\n    float fCameraDepthBlue;\n    if (fAltitudeStart > fOuterRadius - fInnerRadius)\n    { // outside atmosphere\n      fDistance = fInnerRadius - fOuterRadius;\n    } else\n    {\n      fDistance = fAltitudeEnd - fAltitudeStart;\n    }\n\n#endif\n    vec2 v2OpticalStartDepth = exp(fDistance * v2OneOverScaleDepth);\n\n    float fRayLength = rayEndT - rayStartT;\n    float fSampleLength = fRayLength / fSamples;\n    float fScaledLength = fSampleLength * fScale;\n    vec3 v3SampleRay = worldSpaceRay * fSampleLength;\n    vec3 v3SamplePoint = v3Start + v3SampleRay * 0.5;\n\n#ifdef HAZE\n    float fCameraAngle = dot(-worldSpaceRay, v3End) / length(v3End);\n    float fScaleCameraAngle = scale(fCameraAngle);\n    vec2 v2CameraOffset = fScaleCameraAngle*v2OpticalStartDepth;\n\n    float scaledValues = scale(fLightAngle) + fScaleCameraAngle;\n    vec2 v2ScaledValuesDepth = scaledValues * v2ScaleDepth;\n#else\n    float fCameraAngle = dot(worldSpaceRay, v3Start / length(v3Start));\n    float angleMultiplier = fCameraAngle>0.0?fCameraAngle:0.0;\n\n    float fScaleCameraAngle = scale(fCameraAngle);\n    vec2 v2CameraOffset = fScaleCameraAngle*v2OpticalStartDepth * v2ScaleDepth;\n#endif\n\n    // Loop variables\n    vec3 v3FrontColor = vec3(0.0, 0.0, 0.0);\n    vec3 v3FrontColorBlue = vec3(0.0, 0.0, 0.0);\n    vec3 v3Attenuate= vec3(0.0, 0.0, 0.0);\n    vec3 v3AttenuateBlue = vec3(0.0, 0.0, 0.0);\n\n    // Now loop through the sample rays\n    for(int i=0; i<maxSamples; i++) {\n      float fHeight = length(v3SamplePoint);\n      float fAltitude = abs(fHeight - fInnerRadius);\n\n      vec2 v2Depth = exp(-fAltitude * v2ScaleOverScaleDepth);\n#ifdef HAZE\n      vec2 v2Scatter = v2Depth*v2ScaledValuesDepth-v2CameraOffset;\n#else\n      float fLightAngle = dot(v3LightDir, v3SamplePoint) / fHeight;\n      float fCameraAngle = dot(worldSpaceRay, v3SamplePoint) / fHeight;\n      float fTempScaledValues = scale(fLightAngle) - scale(fCameraAngle);\n      vec2 v2Scatter = v2CameraOffset + fTempScaledValues*v2Depth* v2ScaleDepth;\n#endif\n      v3Attenuate = exp(-v2Scatter.x * v3InvWavelengthScaled);\n      v3AttenuateBlue = exp(-v2Scatter.y * v3InvWavelengthScaled);\n\n      v3FrontColor += v3Attenuate * v2Depth.x;\n      v3FrontColorBlue += v3AttenuateBlue * v2Depth.y;\n\n      v3SamplePoint += v3SampleRay;\n    }\n\n    // Phase computation\n    // clamp to avoid numerical instability at fCos == -1.0 (and close values) to display fake sun\n    float fCos = clamp(dot(v3LightDir, -worldSpaceRay ),-0.9999999,1.0);\n    float fOnePlusCos2 = fCos*fCos + 1.0;\n#ifdef HAZE\n    // Finally, scale the Rayleigh colors and set up the varying variables for the pixel shader\n    vec3 colorCoefficients = (fScaledLength* 0.75 * fOnePlusCos2)*(fKrESun*v3InvWavelength+fKmESun);\n\n    // Scaled Length is only applied afterwards to save multiplications\n    vec3 v3Color = colorCoefficients *v3FrontColor;\n    vec3 v3ColorBlue = colorCoefficients *v3FrontColorBlue;\n#else\n    vec3 v3RayleighCoefficients = (fScaledLength*0.75 * fOnePlusCos2*fKrESun)*v3InvWavelength;\n    float fMieCoefficients = fScaledLength*fKmESun * fMiePhaseCoefficients * fOnePlusCos2 / pow(1.0 + fg2 - 2.0*fg*fCos, 1.5);\n\n    // Calculate the attenuation factor for the ground\n    vec3 v3Color = v3RayleighCoefficients * v3FrontColor + fMieCoefficients * v3FrontColor;\n    vec3 v3ColorBlue = v3RayleighCoefficients * v3FrontColorBlue + fMieCoefficients * v3FrontColorBlue;\n#endif\n\n    // HDR to LDR conversion\n    vec3 ldrBlue = expTM(v3ColorBlue,2.0*fExposure);\n    vec3 ldrRed = expTM(v3Color,fExposure);\n\n    // mix reddish and blueish atmosphere\n    vec3 LDR = mix(ldrBlue,ldrRed,0.2);\n#ifdef HAZE\n    LDR *= (1.0-fCameraAngle);\n    vec3 hsv = rgb2hsv(LDR);\n    hsv.y = clamp(hsv.y*1.5,0.0,1.0); // boost haze saturation by 50%\n    LDR = hsv2rgb(hsv);\n    vec3 finalColor = LDR;\n    // when rendering we specify the blend functions such that\n    // newDestColor = oldDestColor*(1.0-finalColor) + finalColor\n#else\n    // reinhard tonemapper for looking upwards\n    vec3 ldrReinhard = reinhardTM(v3Color,fExposure);\n    LDR += angleMultiplier*ldrReinhard;\n\n    // height dependent parameter to smooth out reddish atmosphere\n    float side = (rayEndT+rayStartT)*0.5;\n    float atmoHeight = sqrt(fCameraHeight2 - side*side);\n    float h2 = clamp(1.0-(atmoHeight-fLowerAlphaBlendBound)/(fOuterRadius-fLowerAlphaBlendBound),0.0,1.0);\n\n    vec3 finalColor = LDR*h2;\n    vec3 hsv = rgb2hsv(finalColor);\n    hsv.y = clamp(hsv.y*1.5,0.0,1.0); // boost sky saturation by 50%\n    finalColor = hsv2rgb(hsv);\n#endif\n\n#ifndef HAZE\n    float atmosStrength = clamp((length(ldrRed)-0.05)*1.05,0.0,1.0);\n    gl_FragColor = vec4(finalColor, atmosStrength*clamp(1.0-(atmoHeight-fInnerRadius)/(fOuterRadius-fInnerRadius),0.0,1.0));\n    if (fSurfaceBlend > 0.0) {\n      gl_FragColor = mix(gl_FragColor, surfaceColor, fSurfaceBlend);\n    }\n#else\n    gl_FragColor = vec4(finalColor, 1.0) * altitudeAlpha;\n#endif\n\n    // Debug variable overlay\n    if(showTest>0.0){\n      gl_FragColor = vec4(test,1.0);\n    }\n  } else { // Outside Atmosphere\n    gl_FragColor = vec4(0.0);\n  }\n}\n","realisticAtmosphere.vert":"#include <util/vsPrecision.glsl>\n\n// Camera\nuniform vec2 halfSizeNearPlane;\nuniform vec3 v3CameraUp;\nuniform vec3 v3CameraRight;\nuniform vec3 v3CameraDir;\nuniform vec2 v2CameraCenterOffset;\n\n// Attributes\nattribute vec3 position;\nattribute vec2 uv0;\n\n// Varyings\nvarying vec3 v3WorldRay;\nvarying vec2 vtc;\n\n#ifdef HAZE\nvarying vec3 v3EyeDir;\n#endif\n\nvoid main(void) {\n  vec3 v3Pos = position;\n  vtc = uv0;\n  vec2 rayvtc = uv0 - v2CameraCenterOffset;\n\n#ifdef HAZE\n  v3EyeDir = vec3((2.0*halfSizeNearPlane *rayvtc)-halfSizeNearPlane,-1.0);\n#else\n  vec3 v3EyeDir = vec3((2.0*halfSizeNearPlane *rayvtc)-halfSizeNearPlane,-1.0);\n#endif\n  v3WorldRay = v3EyeDir.z*v3CameraDir + v3EyeDir.y*v3CameraUp + v3EyeDir.x*v3CameraRight;\n  gl_Position = vec4(v3Pos, 1.0);\n}\n","simpleAtmosphere.frag":"#include <util/fsPrecision.glsl>\n\nuniform sampler2D tex;\n\nvarying vec2 vtc;\nvarying float falloff;\n\n#ifndef PANORAMIC\nuniform float altitudeFade;\nvarying float innerFactor;\n#endif\n\nvoid main() {\n  vec4 texColor = texture2D(tex, vtc);\n\n#ifdef PANORAMIC\n  gl_FragColor = texColor * falloff;\n#else\n  vec4 atmosphereColor = texColor * falloff;\n  vec4 innerColor = vec4(texColor.rgb * falloff, 1.0 - altitudeFade);\n  gl_FragColor = mix(atmosphereColor, innerColor, smoothstep(0.0, 1.0, innerFactor));\n#endif\n}\n","simpleAtmosphere.vert":"#include <util/vsPrecision.glsl>\n\nuniform mat4 proj;\nuniform mat4 view;\n\n#ifndef PANORAMIC\nconst float TWICEPI = 2.0*3.14159265;\nconst float ATMOSPHERE_RIM_SEGMENTS = 128.0;\n\nuniform vec3 silCircleCenter;\nuniform vec3 silCircleV1;\nuniform vec3 silCircleV2;\nuniform vec2 texV;\n\nuniform float innerScale;  // scale for inner rim\nvarying float innerFactor; // 0: outer atmosphere, 1: inner atmosphere\n#endif\n\nuniform vec3 lightDirection;\n\nattribute vec3 position;\nvarying vec2 vtc;\nvarying float falloff;\n\nvoid main(void) {\n\n#ifdef PANORAMIC\n\n  vec3 pos = position;\n  float ndotl = lightDirection.z;\n  vtc = vec2(0.0, position.z+0.05);\n\n#else\n\n  innerFactor = clamp(-position.z, 0.0, 1.0);\n  float scale = position.y * (1.0 + innerFactor * innerScale);\n  float phi = position.x * (TWICEPI / ATMOSPHERE_RIM_SEGMENTS) + 1.0;\n  vec3 pos =  (silCircleCenter + sin(phi) * silCircleV1 + cos(phi) * silCircleV2) * scale;\n  float ndotl = dot(normalize(position.y > 0.0 ? pos: silCircleCenter), lightDirection);\n\n  vtc.x = position.x / ATMOSPHERE_RIM_SEGMENTS;\n  vtc.y = texV.x * (1.0 - position.z) + texV.y * position.z;\n\n#endif\n\n  falloff = max(0.0, smoothstep(-1.0, 0.8, 2.0 * ndotl));\n\n  gl_Position = proj * view * vec4(pos, 1.0);\n  gl_Position.z = gl_Position.w; // project atmosphere onto the far plane\n}\n","simpleAtmosphereFade.frag":"#include <util/fsPrecision.glsl>\n\nvarying vec4 color;\n\nvoid main() {\n  gl_FragColor = color;\n}\n","simpleAtmosphereFade.vert":"#include <util/vsPrecision.glsl>\n\nattribute vec2 position;\n\nuniform vec3 lightDirection;\nuniform vec3 cameraPosition;\n\nuniform float undergroundFadeAlpha;\n\nvarying vec4 color;\n\nvoid main(void) {\n  float ndotl = dot(normalize(cameraPosition), lightDirection);\n  float lighting = max(0.0, smoothstep(-1.0, 0.8, 2.0 * ndotl));\n\n  color = vec4(vec3(lighting), undergroundFadeAlpha);\n\n  gl_Position = vec4(position.xy, 1.0, 1.0); // on the far plane\n}\n","stars.frag":"#include <util/fsPrecision.glsl>\n\nvarying vec4 vcolor;\nvarying float vsize;\n\nvoid main() {\n  float cap = 0.7;\n  float scale = 1.0/cap;\n  float helper = clamp(length(abs(gl_PointCoord-vec2(0.5))),0.0,cap);\n  float alpha = clamp((cap-helper)*scale,0.0,1.0);\n  float intensity = alpha*alpha*alpha;\n  if (vsize < 3.0)\n    intensity *= 0.5;\n  gl_FragColor = vec4(1.0,1.0,1.0,intensity);\n  gl_FragColor.xyz *= vcolor.xyz;\n}\n","stars.vert":"#include <util/vsPrecision.glsl>\n#include <util/alignPixel.glsl>\n\nuniform mat4 proj;\nuniform mat4 view;\nuniform mat4 model;\nuniform vec4 viewport;\nuniform float pixelRatio;\n\nattribute vec3 position;\nattribute vec4 color;\nattribute float size;\n\nvarying vec4 vcolor;\nvarying float vsize;\n\nvoid main(void) {\n  vec4 posProj = proj * view * model*vec4(position*1.0e25,1.0);//move infinitely far away\n  gl_Position = alignToPixelCenter(posProj, viewport.zw); //pixel align position\n  gl_Position.z = gl_Position.w; // project atmosphere onto the far plane\n  vcolor = color / 1.2;\n  vsize = size * 5.0 * pixelRatio;\n  gl_PointSize = vsize;\n}\n"},materials:{checkerBoard:{"checkerBoard.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n\nuniform vec2 size;\nuniform vec4 color1;\nuniform vec4 color2;\n\nvarying vec2 vUV;\n\nvoid main() {\n  vec2 uvScaled = vUV / (2.0 * size);\n\n  vec2 uv = fract(uvScaled - 0.25);\n  vec2 ab = clamp((abs(uv - 0.5) - 0.25) / fwidth(uvScaled), -0.5, 0.5);\n  float fade = smoothstep(0.25, 0.5, max(fwidth(uvScaled.x), fwidth(uvScaled.y)));\n  float t = mix(abs(ab.x + ab.y), 0.5, fade);\n\n  gl_FragColor = mix(color2, color1, t);\n}\n","checkerBoard.vert":"#include <util/vsPrecision.glsl>\n\nuniform mat4 proj;\nuniform mat4 view;\nuniform mat4 model;\n\nattribute vec3 position;\nattribute vec2 uv0;\n\nvarying vec2 vUV;\n\nvoid main(void) {\n  vUV = uv0;\n  gl_Position = proj * view * vec4((model * vec4(position, 1.0)).xyz, 1.0);\n}\n"},color:{"color.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n\nuniform vec4 eColor;\n#ifdef VERTEX_COLORS\nvarying vec4 vColor;\n#endif\n\nvarying vec3 vpos;\n\nvoid main() {\n  discardBySlice(vpos);\n\n#ifdef VERTEX_COLORS\n  gl_FragColor = vColor * eColor;\n#else\n  gl_FragColor = eColor;\n#endif\n\n  gl_FragColor = highlightSlice(gl_FragColor, vpos);\n}\n","color.vert":"#include <util/vsPrecision.glsl>\n\nuniform mat4 proj;\nuniform mat4 view;\nuniform mat4 model;\n\nattribute vec3 position;\n#ifdef VERTEX_COLORS\nattribute vec4 color;\n\nvarying vec4 vColor;\n#endif\n\nvarying vec3 vpos;\n\nvoid main(void) {\n#ifdef VERTEX_COLORS\n  vColor = color * 0.003921568627451; // = 1/255;\n#endif\n  vpos = (model * vec4(position, 1.0)).xyz;\n\n  gl_Position = proj * view * vec4(vpos, 1.0);\n}\n"},defaultMaterial:{"colorMixMode.glsl":"#include <util/color.glsl>\n\n/*\n * The color mix modes are encoded in the symbol color as follows:\n *  - Fully transparent symbols are represented with alpha 0 for\n *    all color mix modes (except ignore).\n *  - color mix mode ignore is encoded as multiply with white\n *  - the other 3 color mix modes (tint, replace, multiply) are\n *    equally distributed on the remaining 255 alpha values, which\n *    gives us 85 possible alpha values\n *\n * alpha             0 : fully transparent\n * alpha in [  1 -  85]: tint\n * alpha in [ 86 - 170]: replace\n * alpha in [171 - 255]: multiply\n * \n */\nvec4 decodeSymbolColor(vec4 symbolColor, out int colorMixMode) {\n  float symbolAlpha = 0.0;\n\n  const float maxTint = 85.0;\n  const float maxReplace = 170.0;\n  const float scaleAlpha = 3.0;\n\n  if (symbolColor.a > maxReplace) {\n    colorMixMode = 1;  // multiply\n    symbolAlpha = scaleAlpha * (symbolColor.a - maxReplace);\n  } else if (symbolColor.a > maxTint) {\n    colorMixMode = 3; // replace\n    symbolAlpha = scaleAlpha * (symbolColor.a - maxTint);\n  } else if (symbolColor.a > 0.0) {\n    colorMixMode = 0; // tint\n    symbolAlpha = scaleAlpha * symbolColor.a;\n  } else {\n    colorMixMode = 1; // fully transparent -> multiply\n    symbolAlpha = 0.0;\n  }\n\n  return vec4(symbolColor.r, symbolColor.g, symbolColor.b, symbolAlpha);\n}\n\nvec3 mixExternalColor(vec3 internalColor, vec3 textureColor, vec3 externalColor, int mode) {\n\n  // workaround for artifacts in OSX using Intel Iris Pro\n  // see: https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/10475\n  vec3 internalMixed = internalColor * textureColor;\n  vec3 allMixed = internalMixed * externalColor;\n\n  if (mode == 1 /* multiply */) {\n    return allMixed;\n  }\n  else if (mode == 2 /* ignore */ ) {\n    return internalMixed;\n  }\n  else if (mode == 3 /* replace */ ) {\n    return externalColor;\n  }\n  else {\n    // tint (or something invalid)\n    vec3 hsvIn = rgb2hsv(internalMixed);\n    vec3 hsvTint = rgb2hsv(externalColor);\n    vec3 hsvOut = vec3(hsvTint.x, hsvTint.y, hsvIn.z * hsvTint.z);\n    return hsv2rgb(hsvOut);\n  }\n}\n\nfloat mixExternalOpacity(float internalOpacity, float textureOpacity, float externalOpacity, int mode) {\n\n  // workaround for artifacts in OSX using Intel Iris Pro\n  // see: https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/10475\n  float internalMixed = internalOpacity * textureOpacity;\n  float allMixed = internalMixed * externalOpacity;\n\n  if (mode == 2 /* ignore */ ) {\n    return internalMixed;\n  }\n  else if (mode == 3 /* replace */ ) {\n    return externalOpacity;\n  }\n  else {\n    // multiply or tint (or something invalid)\n    return allMixed;\n  }\n}\n","colorPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n#include <util/sceneLighting.glsl>\n\n#ifdef TEXTURING\n#include <materials/defaultMaterial/texturingInputs.glsl>\n#endif\n\n#define FRAGMENT_SHADER\n#include <materials/defaultMaterial/vertexTangents.glsl>\n#include <materials/defaultMaterial/textureNormals.glsl>\n\nuniform vec3 camPos;\nuniform vec3 localOrigin;\n\n// material parameters\n//////////////////////////////////////////\nuniform vec3 ambient;\nuniform vec3 diffuse;\nuniform vec3 specular;\nuniform float opacity;\nuniform float layerOpacity;\n\n#if defined(SYMBOLVERTEXCOLORS) || defined(COMPONENTCOLORS)\nvarying mediump float colorMixMode; // varying int is not supported in WebGL\n#else\nuniform int colorMixMode;\n#endif\n\n#ifdef RECEIVE_SHADOWS\nuniform sampler2D depthTex;\nuniform int shadowMapNum;\nuniform vec4 shadowMapDistance;\nuniform mat4 shadowMapMatrix[4];\nuniform float depthHalfPixelSz;\n#endif\n\n#ifdef RECEIVE_SSAO\nuniform sampler2D ssaoTex;\nuniform vec4 viewportPixelSz;\n#endif\n\nvarying vec3 vpos;\n\n#if (NORMALS == NORMALS_COMPRESSED) || (NORMALS == NORMALS_DEFAULT)\n  varying vec3 vnormal;\n#endif\n\n#if defined(VERTEXCOLORS)\nvarying vec4 vcolor;\n#endif\nvarying vec4 vcolorExt;\n\n#ifdef RECEIVE_SHADOWS\nvarying float linearDepth;\n#include <util/shadow.glsl>\n#endif\n\n#ifdef TREE_RENDERING\n  uniform mat4 view;\n#endif\n\n#ifdef TEXTURING\n#include <materials/defaultMaterial/texturing.glsl>\n#endif\n\n#include <materials/defaultMaterial/colorMixMode.glsl>\n\nvoid main() {\n  discardBySlice(vpos);\n\n#ifdef TEXTURING\n  vec4 texColor = textureLookup(tex, vtc);\n\n  #if defined(TEXTURE_ALPHA_PREMULTIPLIED)\n    texColor.rgb /= texColor.a;\n  #endif\n\n  discardOrAdjustTextureAlpha(texColor);\n#else /* TEXTURING */\n  vec4 texColor = vec4(1.0);\n#endif /* TEXTURING */\n\n  vec3 viewDir = vpos - camPos;\n\n  // compute normal\n  // TODO: this is not in sync with the normal pass\n#ifdef GROUND_NORMAL_SHADING\n  #if VIEWING_MODE == VIEWING_MODE_GLOBAL\n    vec3 normal = normalize(vpos + localOrigin);\n  #else\n    vec3 normal = vec3(0.0, 0.0, 1.0);\n  #endif\n#else\n  #if (NORMALS == NORMALS_SCREEN_DERIVATIVE)\n    vec3 normal = normalize(cross(dFdx(vpos),dFdy(vpos)));\n  #else\n    #ifdef DOUBLESIDED\n      vec3 normal = dot(vnormal, viewDir)>0.0 ? -vnormal : vnormal;\n    #elif defined(WINDINGORDERDOUBLESIDED)\n      vec3 normal = gl_FrontFacing ? vnormal : -vnormal;\n    #else\n      vec3 normal = vnormal;\n    #endif\n    normal = normalize(normal);\n  #endif\n#endif\n\n  // compute ssao\n#ifdef RECEIVE_SSAO\n  float ssao = texture2D(ssaoTex, (gl_FragCoord.xy - viewportPixelSz.xy) * viewportPixelSz.zw).a;\n  ssao = viewportPixelSz.z < 0.0 ? 1.0 : ssao;\n#else\n  float ssao = 1.0;\n#endif\n\n  // At global scale we create some additional ambient light based on the main light to simulate global illumination\n  float additionalAmbientScale;\n  vec3 additionalLight = sceneLightingAdditionalLightGlobal(vpos + localOrigin, ssao, additionalAmbientScale);\n\n  // compute shadowing\n  float shadow = 0.0;\n#ifdef RECEIVE_SHADOWS\n  shadow = evalShadow(vpos, linearDepth, depthTex, shadowMapNum, shadowMapDistance, shadowMapMatrix, depthHalfPixelSz);\n#elif VIEWING_MODE == VIEWING_MODE_GLOBAL\n  // at global scale (and in global scenes) we fall back to this approximation\n  // to shadow objects on the dark side of the earth\n  shadow = lightingGlobalFactor * (1.0 - additionalAmbientScale);\n#endif\n\n  vec3 matColor = max(ambient, diffuse); // combine the old material parameters into a single one\n#if defined(VERTEXCOLORS)\n  // Internal colors: varying vcolor + uniform ambient/diffuse, external colors: varying vcolorExt\n  vec3 albedo_ = mixExternalColor(vcolor.rgb * matColor, texColor.rgb, vcolorExt.rgb, int(colorMixMode));\n  float opacity_ = layerOpacity * mixExternalOpacity(vcolor.a * opacity, texColor.a, vcolorExt.a, int(colorMixMode));\n#else\n  // Internal colors: uniform ambient/diffuse, external colors: varying vcolorExt\n  vec3 albedo_ = mixExternalColor(matColor, texColor.rgb, vcolorExt.rgb, int(colorMixMode));\n  float opacity_ = layerOpacity * mixExternalOpacity(opacity, texColor.a, vcolorExt.a, int(colorMixMode));\n#endif\n  albedo_+= 0.25 * specular; // don't completely ignore specular for now\n\n\n  #if defined(TEXTURE_NORMALS)\n    mat3 tangentSpace = computeTangentSpace(normal);\n    vec3 shadingNormal = computeTextureNormal(tangentSpace);\n  #else\n    vec3 shadingNormal = normal;\n  #endif\n\n  #ifdef TREE_RENDERING\n    // make sure we use unflipped normal\n    shadingNormal = normalize(vnormal);\n\n    // make tree 20% brighter\n    albedo_ *= 1.2;\n\n    // view forward vector in global coordinates\n    vec3 viewForward = - vec3(view[0][2], view[1][2], view[2][2]);\n\n    // factor indicating how aligned the lighting direction and view axis are\n    float alignmentLightView = clamp(dot(-viewForward, lightingMainDirection), 0.0, 1.0);\n\n    // we approximate the tree crown transmittance based on view direction and tree crown normal\n    float transmittance = 1.0 - clamp(dot(-viewForward, shadingNormal), 0.0, 1.0);\n\n    float treeRadialFalloff = vcolor.r;\n    float backLightFactor = 0.5 * treeRadialFalloff * alignmentLightView * transmittance * (1.0 - shadow);\n    additionalLight += backLightFactor * lightingMainIntensity;\n  #endif\n\n  vec3 shadedColor = evaluateSceneLighting(shadingNormal, albedo_, shadow, 1.0 - ssao, additionalLight);\n  gl_FragColor = highlightSlice(vec4(shadedColor, opacity_), vpos);\n}\n",
"colorPass.vert":"#include <util/vsPrecision.glsl>\n\n#include <materials/defaultMaterial/commonInputs.glsl>\n\n#define VERTEX_SHADER\n#include <materials/defaultMaterial/vertexTangents.glsl>\n\n#ifdef INSTANCEDCOLOR\nattribute vec4 instanceColor;\n#endif\nattribute vec3 position;\n\n#if (NORMALS == NORMALS_COMPRESSED)\n  attribute vec2 normalCompressed;\n  varying vec3 vnormal;\n#elif (NORMALS == NORMALS_DEFAULT)\n  attribute vec3 normal;\n  varying vec3 vnormal;\n#endif\n\nvarying vec3 vpos;\n\n#ifdef TEXTURING\n    attribute vec2 uv0;\n    varying vec2 vtc;\n  #ifdef TEXTURE_ATLAS\n    attribute vec4 region;\n    varying vec4 regionV;\n  #endif\n#endif\n\n#ifdef COMPONENTCOLORS\n#include <materials/defaultMaterial/componentColors.glsl>\n#endif\n\n#ifdef RECEIVE_SHADOWS\nvarying float linearDepth;\n#endif\n\n#ifdef VERTEXCOLORS\nattribute vec4 color;\n#endif\n\n#ifdef SYMBOLVERTEXCOLORS\nattribute vec4 symbolColor;\n#endif\n\n#if defined(VERTEXCOLORS)\nvarying vec4 vcolor;\n#endif\n\n// Workaround for https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/13452\n// We pass the externalColor uniform from VS to FS through the vcolorExt varying because\n// there is a driver bug for Intel Integrated Graphics which led to rendering artifacts\n// since the introduction of https://devtopia.esri.com/WebGIS/arcgis-js-api/pull/12673\n// This should be further cleaned up later with through the following issue:\n// https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/12763\nuniform vec4 externalColor;\nvarying vec4 vcolorExt;\n\n#if defined(SYMBOLVERTEXCOLORS) || defined(COMPONENTCOLORS)\nvarying mediump float colorMixMode; // varying int is not supported in WebGL\n#endif\n\n#include <util/visualVariables.glsl>\n\n#if defined(VV_SIZE) || defined(VV_COLOR)\nattribute vec4 instanceFeatureAttribute;\n#endif\n\n#include <materials/defaultMaterial/colorMixMode.glsl>\n#include <materials/defaultMaterial/commonFunctions.glsl>\n#include <materials/defaultMaterial/constants.glsl>\n#include <materials/defaultMaterial/localCenter.glsl>\n#include <materials/defaultMaterial/localNormal.glsl>\n\nvoid main() {\n\n#ifdef VERTEXCOLORS\n  vcolor = color * 0.003921568627451; // = 1/255\n#endif\n\n  vcolorExt = externalColor;\n\n#ifdef INSTANCEDCOLOR\n  vcolorExt *= instanceColor;\n#endif\n\n#ifdef VV_COLOR\n  vcolorExt *= vvGetColor(instanceFeatureAttribute, vvColorValues, vvColorColors);\n#endif\n\n#ifdef SYMBOLVERTEXCOLORS\n  int symbolColorMixMode;\n  vcolorExt *= decodeSymbolColor(symbolColor, symbolColorMixMode) * 0.003921568627451; // = 1/255;\n  colorMixMode = float(symbolColorMixMode) + 0.5; // add 0.5 to avoid interpolation artifacts\n#endif\n\n#ifdef COMPONENTCOLORS\n  int symbolColorMixMode;\n  vcolorExt *= decodeSymbolColor(readComponentColor() * 255.0, symbolColorMixMode) * 0.003921568627451; // = 1/255;\n  colorMixMode = float(symbolColorMixMode) + 0.5; // add 0.5 to avoid interpolation artifacts\n#endif\n\n  if (vcolorExt.a < SYMBOL_ALPHA_CUTOFF) {\n    // Discard this vertex\n    gl_Position = vec4(1e38, 1e38, 1e38, 1.0);\n  }\n  else {\n    vpos = calculateVPos();\n\n#ifdef INSTANCED_DOUBLE_PRECISION\n  #if (NORMALS == NORMALS_COMPRESSED) || (NORMALS == NORMALS_DEFAULT)\n    vnormal = normalize(modelNormal * localNormal().xyz);\n  #endif\n\n  vec3 originDelta = dpAdd(viewOriginHi, viewOriginLo, -modelOriginHi, -modelOriginLo);\n  #ifdef IOS_SAFARI_FIX\n    originDelta = originDelta - fract(originDelta * 1000000.0) * (1.0 / 1000000.0);\n  #endif\n  vpos -= originDelta;\n\n  #ifdef VERTICAL_OFFSET\n    vec3 centerPos = model * localCenter().xyz + originDelta;\n    vpos += calculateVerticalOffset(centerPos, localOrigin);\n  #endif\n#else /* INSTANCED_DOUBLE_PRECISION */\n  #if (NORMALS == NORMALS_COMPRESSED) || (NORMALS == NORMALS_DEFAULT)\n    vnormal = normalize((modelNormal * localNormal()).xyz);\n  #endif\n\n  #ifdef VERTICAL_OFFSET\n    vec3 centerPos = (model * localCenter()).xyz;\n    vpos += calculateVerticalOffset(centerPos, localOrigin);\n  #endif\n#endif /* INSTANCED_DOUBLE_PRECISION */\n\n    #if defined(VERTEX_TANGENTS)\n      transformVertexTangent(mat3(modelNormal));\n    #endif\n\n    gl_Position = proj * view * vec4(vpos, 1.0);\n  }\n\n#ifdef RECEIVE_SHADOWS\n  // Shadowmap's cascading index used to be based on '1.0 / gl_FragCoord.w'\n  // (i.e. the perspective interpolation of 'gl_Position.w'). Precision\n  // issues on iPad/iPhone with the 'w' component require the depth to be\n  // passed as varying to properly drive the cascading shadow map index.\n  linearDepth = gl_Position.w;\n#endif\n\n\n#ifdef TEXTURING\n  #ifndef FLIPV\n    vtc = uv0;\n  #else\n    vtc = vec2(uv0.x, 1.0-uv0.y);\n  #endif\n  #ifdef TEXTURE_ATLAS\n    regionV = region;\n  #endif\n#endif /* TEXTURING */\n\n}\n","commonFunctions.glsl":"#include <materials/defaultMaterial/localPosition.glsl>\n#include <util/doublePrecision.glsl>\n\nvec3 calculateVPos() {\n#ifdef INSTANCED_DOUBLE_PRECISION\n  return model * localPosition().xyz;\n#else\n  return (model * localPosition()).xyz;\n#endif\n}\n\n#ifdef VERTICAL_OFFSET\n#ifdef SCREEN_SIZE_PERSPECTIVE\n#include <util/screenSizePerspective.glsl>\n#endif\n\nvec3 calculateVerticalOffset(vec3 worldPos, vec3 localOrigin) {\n  float viewDistance = length((view * vec4(worldPos, 1.0)).xyz);\n  float verticalOffsetOffsetDistance = verticalOffset.x * viewDistance;\n\n#if VIEWING_MODE == VIEWING_MODE_GLOBAL\n  vec3 worldNormal = normalize(worldPos + localOrigin);\n#else\n  vec3 worldNormal = vec3(0.0, 0.0, 1.0);\n#endif\n\n#ifdef SCREEN_SIZE_PERSPECTIVE\n  float cosAngle = dot(worldNormal, normalize(worldPos - camPos));\n\n  float verticalOffsetScreenHeight = screenSizePerspectiveScaleFloat(verticalOffset.x, abs(cosAngle), viewDistance, screenSizePerspectiveAlignment);\n#else\n  float verticalOffsetScreenHeight = verticalOffset.x;\n#endif\n\n  // Screen sized offset in world space, used for example for line callouts\n  float worldOffset = clamp(verticalOffsetScreenHeight * verticalOffset.y * viewDistance, verticalOffset.z, verticalOffset.w);\n\n  return worldNormal * worldOffset;\n}\n#endif\n","commonInputs.glsl":"uniform mat4 proj;\nuniform mat4 view;\n#ifdef INSTANCED_DOUBLE_PRECISION\nuniform vec3 viewOriginHi;\nuniform vec3 viewOriginLo;\n#endif\nuniform vec3 camPos;\nuniform vec3 localOrigin;\n\n#ifdef INSTANCED\n#ifdef INSTANCED_DOUBLE_PRECISION\nattribute vec3 modelOriginHi;\nattribute vec3 modelOriginLo;\nattribute mat3 model;\nattribute mat3 modelNormal;\n#else /* INSTANCED_DOUBLE_PRECISION */\nattribute mat4 model;\nattribute mat4 modelNormal;\n#endif /* INSTANCED_DOUBLE_PRECISION */\n#else /* INSTANCED */\nuniform mat4 model;\nuniform mat4 modelNormal;\n#endif /* INSTANCED */\n\n#ifdef VERTICAL_OFFSET\n// [ verticalOffsetPerDistance, minWorldLength, maxWorldLength ]\nuniform vec4 verticalOffset;\n#ifdef SCREEN_SIZE_PERSPECTIVE\nuniform vec4 screenSizePerspectiveAlignment;\n#endif\n#endif\n","componentColors.glsl":"\nuniform sampler2D uComponentColorTex;\nuniform vec2 uComponentColorTexInvDim;\n\nattribute float componentIndex;\n\nvec4 readComponentColor() {\n  float normalizedIndex = (componentIndex + 0.5) * uComponentColorTexInvDim.x;\n  vec2 indexCoord = vec2(\n    mod(normalizedIndex, 1.0),\n    (floor(normalizedIndex) + 0.5) * uComponentColorTexInvDim.y\n  );\n  vec4 componentColor = texture2D(uComponentColorTex, indexCoord);\n  // NB: we clear the least significant bit of the blue channel as this contains\n  // the castShadows flag\n  return vec4( componentColor.r, componentColor.g, componentColor.b - mod(componentColor.b*255.0, 2.0)/255.0, componentColor.a);\n}\n\n// returns 1.0 if shadowCasting is enabled and 0.0 otherwise\n// this is found by reading the least significant bit of the\n// componentColors blue color channel which contains the castShadows flag\nbool readComponentCastShadowsFlag(){\n  float normalizedIndex = (componentIndex + 0.5) * uComponentColorTexInvDim.x;\n  vec2 indexCoord = vec2(\n    mod(normalizedIndex, 1.0),\n    (floor(normalizedIndex) + 0.5) * uComponentColorTexInvDim.y\n  );\n  if( mod(texture2D(uComponentColorTex, indexCoord).b*255.0, 2.0) < 1.0 )\n      return false;\n  return true;\n}\n","constants.glsl":"#define SYMBOL_ALPHA_CUTOFF 0.001\n","depthPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/encoding.glsl>\n#include <util/depth.glsl>\n#include <util/slice.glsl>\n\nvarying float depth;\nvarying vec3 vpos;\n\n#if defined(TEXTURING)\n  #include <materials/defaultMaterial/texturingInputs.glsl>\n  #include <materials/defaultMaterial/texturing.glsl>\n#endif\n\n\nvoid main() {\n  discardBySlice(vpos);\n\n  #if defined(TEXTURING)\n    vec4 texColor = textureLookup(tex, vtc);\n    discardOrAdjustTextureAlpha(texColor);\n  #endif\n\n  #ifndef BIAS_SHADOWMAP\n    gl_FragColor = float2rgba(depth);\n  #else\n    gl_FragColor = float2rgba(calcFragDepth(depth));\n  #endif\n}\n","depthPass.vert":"#include <util/vsPrecision.glsl>\n\n#include <materials/defaultMaterial/commonInputs.glsl>\n\nuniform vec2 nearFar;\nattribute vec3 position;\n\nvarying float depth;\nvarying vec3 vpos;\n\n#ifdef TEXTURING\nattribute vec2 uv0;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nattribute vec4 region;\nvarying vec4 regionV;\n#endif\n#endif\n\n#include <util/visualVariables.glsl>\n\n#if defined(VV_CUSTOM_MODEL_MATRIX)\nattribute vec4 instanceFeatureAttribute;\n#endif\n\n#include <materials/defaultMaterial/commonFunctions.glsl>\n#include <materials/defaultMaterial/localCenter.glsl>\n\n#if defined(COMPONENTCOLORS)\n#include <materials/defaultMaterial/componentColors.glsl>\n#endif\n\n\nvoid main(void) {\n  vpos = calculateVPos();\n\n\n\n#if defined(COMPONENTCOLORS)\n  if( !readComponentCastShadowsFlag() ){\n    // discard vertex so that it doesnt show up in depth buffer\n    gl_Position = vec4(1e38, 1e38, 1e38, 1.0);\n  }else\n  {\n#endif\n\n\n#ifdef INSTANCED_DOUBLE_PRECISION\n  vec3 originDelta = dpAdd(viewOriginHi, viewOriginLo, -modelOriginHi, -modelOriginLo);\n#ifdef IOS_SAFARI_FIX\n  originDelta = originDelta - fract(originDelta * 1000000.0) * (1.0 / 1000000.0);\n#endif\n  vpos -= originDelta;\n\n#ifdef VERTICAL_OFFSET\n  vec3 centerPos = model * localCenter().xyz + originDelta;\n  vpos += calculateVerticalOffset(centerPos, localOrigin);\n#endif\n#else /* INSTANCED_DOUBLE_PRECISION */\n#ifdef VERTICAL_OFFSET\n  vec3 centerPos = (model * localCenter()).xyz;\n  vpos += calculateVerticalOffset(centerPos, localOrigin);\n#endif\n#endif /* INSTANCED_DOUBLE_PRECISION */\n\n  vec4 eye = view * vec4(vpos, 1.0);\n\n  gl_Position = proj * eye;\n  depth = (-eye.z - nearFar[0]) / (nearFar[1] - nearFar[0]) ;\n\n#if defined(COMPONENTCOLORS)\n  } // if readComponentCastShadowsFlag==true\n#endif\n\n#ifdef TEXTURING\n#ifndef FLIPV\n  vtc = uv0;\n#else\n  vtc = vec2(uv0.x, 1.0-uv0.y);\n#endif\n#ifdef TEXTURE_ATLAS\n  regionV = region;\n#endif\n#endif /* TEXTURING */\n\n}\n","highlightPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n#include <util/highlight.glsl>\n\nvarying vec3 vpos;\n\nuniform sampler2D depthTex;\nuniform vec4 highlightViewportPixelSz;\n\n#if defined(TEXTURING)\n  #include <materials/defaultMaterial/texturingInputs.glsl>\n  #include <materials/defaultMaterial/texturing.glsl>\n#endif\n\nvoid main() {\n  discardBySlice(vpos);\n\n  #if defined(TEXTURING)\n    vec4 texColor = textureLookup(tex, vtc);\n    discardOrAdjustTextureAlpha(texColor);\n  #endif\n\n  gl_FragColor = highlightData(gl_FragCoord, depthTex, highlightViewportPixelSz);\n}\n","highlightPass.vert":"#include <util/vsPrecision.glsl>\n\n#include <materials/defaultMaterial/commonInputs.glsl>\n\nattribute vec3 position;\n\nvarying vec3 vpos;\n\n#ifdef TEXTURING\nattribute vec2 uv0;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nattribute vec4 region;\nvarying vec4 regionV;\n#endif\n#endif\n\n#include <util/visualVariables.glsl>\n\n#if defined(VV_CUSTOM_MODEL_MATRIX)\nattribute vec4 instanceFeatureAttribute;\n#endif\n\n#include <materials/defaultMaterial/commonFunctions.glsl>\n#include <materials/defaultMaterial/localCenter.glsl>\n\nvoid main(void) {\n  vpos = calculateVPos();\n\n#ifdef INSTANCED_DOUBLE_PRECISION\n  vec3 originDelta = dpAdd(viewOriginHi, viewOriginLo, -modelOriginHi, -modelOriginLo);\n#ifdef IOS_SAFARI_FIX\n  originDelta = originDelta - fract(originDelta * 1000000.0) * (1.0 / 1000000.0);\n#endif\n  vpos -= originDelta;\n\n#ifdef VERTICAL_OFFSET\n  vec3 centerPos = model * localCenter().xyz + originDelta;\n  vpos += calculateVerticalOffset(centerPos, localOrigin);\n#endif\n#else /* INSTANCED_DOUBLE_PRECISION */\n#ifdef VERTICAL_OFFSET\n  vec3 centerPos = (model * localCenter()).xyz;\n  vpos += calculateVerticalOffset(centerPos, localOrigin);\n#endif\n#endif /* INSTANCED_DOUBLE_PRECISION */\n\n  gl_Position = proj * view * vec4(vpos, 1.0);\n\n#ifdef TEXTURING\n#ifndef FLIPV\n  vtc = uv0;\n#else\n  vtc = vec2(uv0.x, 1.0-uv0.y);\n#endif\n#ifdef TEXTURE_ATLAS\n  regionV = region;\n#endif\n#endif /* TEXTURING */\n\n}\n","localCenter.glsl":"#ifdef VV_CUSTOM_MODEL_MATRIX\n# ifdef VERTICAL_OFFSET\nvec4 localCenter() { return vvTransformPosition(vec3(0.0), instanceFeatureAttribute); }\n# endif\n#else\n# ifdef VERTICAL_OFFSET\nvec4 localCenter() { return vec4(vec3(0.0), 1.0); }\n# endif\n#endif\n","localNormal.glsl":"#include <util/normalEncoding.glsl>\n\n#ifdef VV_CUSTOM_MODEL_MATRIX\n  # if (NORMALS == NORMALS_COMPRESSED)\n    vec4 localNormal() { return vvTransformNormal(decodeNormal(normalCompressed), instanceFeatureAttribute); }\n  # elif (NORMALS == NORMALS_DEFAULT)\n    vec4 localNormal() { return vvTransformNormal(normal, instanceFeatureAttribute); }\n  # endif\n#else\n  # if (NORMALS == NORMALS_COMPRESSED)\n    vec4 localNormal() { return vec4(decodeNormal(normalCompressed), 1.0); }\n  # elif (NORMALS == NORMALS_DEFAULT)\n    vec4 localNormal() { return vec4(normal, 1.0); }\n  # endif\n#endif\n","localPosition.glsl":"#ifdef VV_CUSTOM_MODEL_MATRIX\nvec4 localPosition() { return vvTransformPosition(position, instanceFeatureAttribute); }\n#else\nvec4 localPosition() { return vec4(position, 1.0); }\n#endif\n","normalPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n\n#if (NORMALS == NORMALS_COMPRESSED) || (NORMALS == NORMALS_DEFAULT)\n  varying vec3 vnormal;\n#endif\n\nvarying vec3 vpos;\n\n#if defined(TEXTURING)\n  #include <materials/defaultMaterial/texturingInputs.glsl>\n  #include <materials/defaultMaterial/texturing.glsl>\n#endif\n\nvoid main() {\n  discardBySlice(vpos);\n\n  #if defined(TEXTURING)\n    vec4 texColor = textureLookup(tex, vtc);\n    discardOrAdjustTextureAlpha(texColor);\n  #endif\n\n#if (NORMALS == NORMALS_SCREEN_DERIVATIVE)\n  vec3 normal = normalize(cross(dFdx(vpos),dFdy(vpos)));\n#else\n  vec3 normal = normalize(vnormal);\n  if (gl_FrontFacing == false) normal = -normal;\n#endif\n\n  #ifndef ALPHA_ZERO\n    gl_FragColor = vec4(vec3(.5) + .5 * normal, 1.0);\n  #else\n    gl_FragColor = vec4(vec3(.5) + .5 * normal, 0.0);\n  #endif\n}\n","normalPass.vert":"#include <util/vsPrecision.glsl>\n\n#include <materials/defaultMaterial/commonInputs.glsl>\n\nuniform mat4 viewNormal;\nattribute vec3 position;\n\n#if (NORMALS == NORMALS_COMPRESSED)\n  attribute vec2 normalCompressed;\n  varying vec3 vnormal;\n#elif (NORMALS == NORMALS_DEFAULT)\n  attribute vec3 normal;\n  varying vec3 vnormal;\n#endif\n\n#ifdef TEXTURING\nattribute vec2 uv0;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nattribute vec4 region;\nvarying vec4 regionV;\n#endif\n#endif\n\n\nvarying vec3 vpos;\n\n#include <util/visualVariables.glsl>\n\n#if defined(VV_CUSTOM_MODEL_MATRIX)\nattribute vec4 instanceFeatureAttribute;\n#endif\n\n#include <materials/defaultMaterial/commonFunctions.glsl>\n#include <materials/defaultMaterial/localCenter.glsl>\n#include <materials/defaultMaterial/localNormal.glsl>\n\nvoid main(void) {\n  vpos = calculateVPos();\n\n#ifdef INSTANCED_DOUBLE_PRECISION\n  #if (NORMALS == NORMALS_COMPRESSED) || (NORMALS == NORMALS_DEFAULT)\n    vnormal = normalize((viewNormal * vec4(modelNormal * localNormal().xyz, 1.0)).xyz);\n  #endif\n\n  vec3 originDelta = dpAdd(viewOriginHi, viewOriginLo, -modelOriginHi, -modelOriginLo);\n\n  #ifdef IOS_SAFARI_FIX\n    originDelta = originDelta - fract(originDelta * 1000000.0) * (1.0 / 1000000.0);\n  #endif\n  vpos -= originDelta;\n\n  #ifdef VERTICAL_OFFSET\n    vec3 centerPos = model * localCenter().xyz + originDelta;\n    vpos += calculateVerticalOffset(centerPos, localOrigin);\n  #endif\n#else /* INSTANCED_DOUBLE_PRECISION */\n  #if (NORMALS == NORMALS_COMPRESSED) || (NORMALS == NORMALS_DEFAULT)\n    vnormal = normalize((viewNormal * modelNormal * localNormal()).xyz);\n  #endif\n\n  #ifdef VERTICAL_OFFSET\n    vec3 centerPos = (model * localCenter()).xyz;\n    vpos += calculateVerticalOffset(centerPos, localOrigin);\n  #endif\n#endif /* INSTANCED_DOUBLE_PRECISION */\n\n  gl_Position = proj * view * vec4(vpos, 1.0);\n\n#ifdef TEXTURING\n#ifndef FLIPV\n  vtc = uv0;\n#else\n  vtc = vec2(uv0.x, 1.0-uv0.y);\n#endif\n#ifdef TEXTURE_ATLAS\n  regionV = region;\n#endif\n#endif /* TEXTURING */\n\n}\n","textureNormals.glsl":"#if defined(TEXTURE_NORMALS)\n  uniform sampler2D texNormal;\n\n  vec3 computeTextureNormal(mat3 tangentSpace) {\n    vec3 rawNormal = texture2D(texNormal, vtc).rgb * 2.0 - 1.0;\n    return tangentSpace * rawNormal;\n  }\n#endif","texturing.glsl":'float calcMipMapLevel(const vec2 ddx, const vec2 ddy) {\n  // from:\n  //   - OpenGLES Common Profile Specification Version 2.0.25, Section 3.7.7 - Texture Minification\n  //   - https://www.opengl.org/discussion_boards/showthread.php/171485-Texture-LOD-calculation-(useful-for-atlasing)\n  //   - http://www.linedef.com/virtual-texture-demo.html\n  float deltaMaxSqr = max(dot(ddx, ddx), dot(ddy, ddy));\n  return max(0.0, 0.5 * log2(deltaMaxSqr));\n}\n\nvec4 textureAtlasLookup(sampler2D tex, vec2 uv, vec4 region, vec2 texSize) {\n  //[umin, vmin, umax, vmax]\n  vec2 atlasScale = region.zw - region.xy;\n  vec2 uvAtlas = fract(uv) * atlasScale + region.xy;\n\n  vec4 texColor;\n\n  // calculate derivative of continuous texture coordinate\n  // to avoid mipmapping artifacts caused by manual wrapping in shader\n  vec2 dUVdx = dFdx(uv) * atlasScale;\n  vec2 dUVdy = dFdy(uv) * atlasScale;\n\n#ifdef GL_EXT_shader_texture_lod\n  return texture2DGradEXT(tex, uvAtlas, dUVdx, dUVdy);\n#else\n  // use bias to compensate for difference in automatic vs desired mipmap level\n  vec2 dUVdxAuto = dFdx(uvAtlas);\n  vec2 dUVdyAuto = dFdy(uvAtlas);\n  float mipMapLevel = calcMipMapLevel(dUVdx * texSize, dUVdy * texSize);\n  float autoMipMapLevel = calcMipMapLevel(dUVdxAuto * texSize, dUVdyAuto * texSize);\n\n  return texture2D(tex, uvAtlas, mipMapLevel - autoMipMapLevel);\n#endif\n}\n\nvec4 textureLookup(sampler2D tex, vec2 uv) {\n#ifdef TEXTURE_ATLAS\n  return textureAtlasLookup(tex, uv, regionV, texSize);\n#else\n  return texture2D(tex, uv);\n#endif\n}\n\n/**\n * Based on the texture alpha mode:\n * - discards fragments if necessary\n * - adjusts read texture alpha if necessary\n */\nvoid discardOrAdjustTextureAlpha(inout vec4 texColor) {\n  // if the texture alpha mode is set to "mask"\n  // the resulting alpha is either 0.0 (discard) or 1.0\n  #if defined(TEXTURE_ALPHA_MODE_MASK)\n    if (texColor.a < textureAlphaCutoff) {\n      discard;\n    } else {\n      texColor.a = 1.0;\n    }\n  // if the texture alpha mode is set to "maskBlend"\n  // the resulting alpha is either 0.0 (discard) or untouched for further use in blending\n  #elif defined(TEXTURE_ALPHA_MODE_MASK_BLEND)\n    if (texColor.a < textureAlphaCutoff) {\n      discard;\n    }\n  // if the texture alpha mode is set to "opaque"\n  // the resulting alpha is always 1.0\n  #elif defined(TEXTURE_ALPHA_MODE_OPAQUE)\n    texColor.a = 1.0;\n  // for "blend" we don\'t need to do anyting\n  #else // defined(TEXTURE_ALPHA_MODE_BLEND)\n\n  #endif\n}\n\n\n\n',"texturingInputs.glsl":"#ifdef TEXTURING\nuniform sampler2D tex;\nuniform vec2 texSize;\n\n#if defined(TEXTURE_ALPHA_MODE_MASK) || defined(TEXTURE_ALPHA_MODE_MASK_BLEND)\nuniform float textureAlphaCutoff;\n#endif\n\n#ifdef TEXTURE_ATLAS\nvarying vec4 regionV;\n#endif\n\n#endif\n\n#if defined(TEXTURING) || defined(TEXTURE_COORDINATES)\nvarying vec2 vtc;\n#endif\n","vertexTangents.glsl":"#if defined(VERTEX_SHADER)\n\n  #if defined(VERTEX_TANGENTS)\n    attribute vec4 aTangent;\n    varying vec4 vTangent;\n\n    void transformVertexTangent(mat3 modelTransformForNormals) {\n      vTangent.xyz = modelTransformForNormals * aTangent.xyz;\n      vTangent.w = aTangent.w;\n    }\n  #endif // VERTEX_TANGENTS\n\n#elif defined(FRAGMENT_SHADER)\n\n  #if defined(VERTEX_TANGENTS)\n    varying vec4 vTangent;\n\n    #if defined(WINDINGORDERDOUBLESIDED)\n      mat3 computeTangentSpace(vec3 normal) {\n        float tangentHeadedness = gl_FrontFacing ? vTangent.w : -vTangent.w;\n        vec3 tangent = normalize(gl_FrontFacing ? vTangent.xyz : -vTangent.xyz);\n        vec3 bitangent = cross(normal, tangent) * tangentHeadedness;\n        return mat3(tangent, bitangent, normal);\n      }\n    #else // WINDINGORDERDOUBLESIDED\n      mat3 computeTangentSpace(vec3 normal) {\n        float tangentHeadedness = vTangent.w;\n        vec3 tangent = normalize(vTangent.xyz);\n        vec3 bitangent = cross(normal, tangent) * tangentHeadedness;\n        return mat3(tangent, bitangent, normal);\n      }\n    #endif // WINDINGORDERDOUBLESIDED\n  #endif // VERTEX_TANGENTS\n\n#endif // VERTEX_SHADER\n"},hud:{"colorPass.frag":"#include <materials/hud/hudHeader.glsl>\n\nvoid main() {\n#include <materials/hud/hudMain.glsl>\n}\n","highlightPass.frag":"#include <materials/hud/hudHeader.glsl>\n#include <util/highlight.glsl>\n\nuniform sampler2D depthTex;\nuniform vec4 highlightViewportPixelSz;\n\nvoid main() {\n#include <materials/hud/hudMain.glsl>\n#ifdef BINARY_HIGHLIGHT_OCCLUSION\n  // Instead of deciding on a per-pixel basis if the highlight is occluded,\n  // do it for all highlight pixel based on the centroid occlusion. This\n  // is a temporary solution for:\n  // https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/9645\n  if (voccluded == 1.0) {\n    gl_FragColor = vec4(1.0, 1.0, 0.0, 1.0);\n  } else {\n    gl_FragColor = vec4(1.0, 0.0, 1.0, 1.0);\n  }\n#else\n  gl_FragColor = highlightData(gl_FragCoord, depthTex, highlightViewportPixelSz);\n#endif\n}\n","hud.vert":"#include <util/vsPrecision.glsl>\n#include <util/alignPixel.glsl>\n#include <util/hud.glsl>\n#include <util/visualVariables.glsl>\n#include <util/slice.glsl>\n\nuniform vec2 screenOffset;\nuniform vec2 anchorPos;\n\n// textureCoordinateScaleFactor can be used when there is a uniform texture scaling per material.\n// This is used in the case where we enforce a POT texture (for mipmaps) and the effective\n// texture is only in a subregion of the full POT texture.\nuniform vec2 textureCoordinateScaleFactor;\n\n#ifdef SCREEN_SIZE_PERSPECTIVE\nuniform vec4 screenSizePerspective;\n#endif\n\n#ifdef DEBUG_DRAW_BORDER\nvarying vec3 debugBorderCoords;\n#endif\n\nattribute vec2 uv0;\nattribute vec4 color;\nattribute vec2 size;\nattribute vec4 auxpos2;\n\nvarying vec4 vcolor;\n\nvarying vec2 vtc;\nvarying vec2 vsize;\n\n#ifdef BINARY_HIGHLIGHT_OCCLUSION\nvarying float voccluded;\n#endif\n\nvoid main(void) {\n  ProjectHUDAux projectAux;\n  vec4 posProj = projectPositionHUD(projectAux);\n\n  if (rejectBySlice(projectAux.posModel)) {\n    // Project outside of clip plane\n    gl_Position = vec4(1e038, 1e038, 1e038, 1.0);\n    return;\n  }\n\n  vec2 inputSize;\n\n#ifdef SCREEN_SIZE_PERSPECTIVE\n\n  inputSize = screenSizePerspectiveScaleVec2(size, projectAux.absCosAngle, projectAux.distanceToCamera, screenSizePerspective);\n\n  vec2 screenOffsetScaled = screenSizePerspectiveScaleVec2(screenOffset, projectAux.absCosAngle, projectAux.distanceToCamera, screenSizePerspectiveAlignment);\n\n#else\n\n  inputSize = size;\n\n  vec2 screenOffsetScaled = screenOffset;\n#endif\n\n#ifdef VV_SIZE\n  // only use width (.xx) for proportional scaling\n  // (if no width was defined in vv, width\n  //  will be a copy of height vv)\n  inputSize *= vvGetScale(auxpos2).xx;\n#endif\n\n  vec2 combinedSize = inputSize * pixelRatio;\n  vec4 quadOffset = vec4(0.0);\n\n#if defined(OCCL_TEST) || defined(BINARY_HIGHLIGHT_OCCLUSION)\n  bool visible = testVisibilityHUD(posProj);\n#endif\n\n#ifdef BINARY_HIGHLIGHT_OCCLUSION\nvoccluded = visible ? 0.0 : 1.0;\n#endif\n\n#ifdef OCCL_TEST\n  if (visible) {\n#endif\n    // UV goes from 0 to 1.99999, where the integer part is used\n    // for the normalized vertex coordinates, and the fractional\n    // part is used for texture sampling\n    vec2 uv01 = floor(uv0);\n    vec2 uv = uv0 - uv01;\n\n    // Displace icon based on anchor position (normalized for size) and\n    // absolute screen offset. anchorPos is [-0.5, 0.5]\n    quadOffset.xy = ((uv01 - anchorPos) * 2.0 * combinedSize + screenOffsetScaled) / viewport.zw * posProj.w;\n\n#ifdef SIGNED_DISTANCE_FIELD\n\n    // SDF primitives might be scaled so that the SDF texture resolution does\n    // not match the resolution of the canvas, but we still want to render\n    // outline-only ('cross' and 'x') primitives cleanly. Aligning to a screen\n    // pixel border at the geometry center achieves this, since SDF textures\n    // always have power of 2 dimensions.\n    posProj = alignToPixelOrigin(posProj, viewport.zw) + quadOffset;\n#else\n    posProj += quadOffset;\n\n    // Aligning vertex positions to the nearest (using 'floor') screen pixel\n    // border renders textures with pixel-perfect results. If the texture\n    // resolution does not match the canvas resolution then aligning is\n    // redundant.\n    if (inputSize.x == size.x) {\n      posProj = alignToPixelOrigin(posProj, viewport.zw);\n    }\n#endif\n\n    gl_Position = posProj;\n\n    vtc = uv * textureCoordinateScaleFactor;\n\n#ifdef DEBUG_DRAW_BORDER\n    debugBorderCoords = vec3(uv01, 1.0 / combinedSize);\n#endif\n\n    vsize = inputSize;\n#ifdef OCCL_TEST\n  } else {\n    vtc = vec2(.0);\n\n#ifdef DEBUG_DRAW_BORDER\n    debugBorderCoords = vec3(0.0);\n#endif\n\n  }\n#endif\n\n  gl_Position = posProj;\n\n#ifdef VV_COLOR\n  vcolor = vvGetColor(auxpos2, vvColorValues, vvColorColors);\n#else\n  vcolor = color / 255.0;\n#endif\n}\n","hudHeader.glsl":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/encoding.glsl>\n#include <util/color.glsl>\n\nuniform sampler2D tex;\nuniform vec4 overrideColor;\nuniform vec4 outlineColor;\nuniform float outlineSize;\n\nvarying vec4 vcolor;\n\nvarying vec2 vtc;\nvarying vec2 vsize;\n\n#ifdef BINARY_HIGHLIGHT_OCCLUSION\nvarying float voccluded;\n#endif\n\n#ifdef DEBUG_DRAW_BORDER\nvarying vec3 debugBorderCoords;\n#endif\n","hudMain.glsl":"#ifdef SIGNED_DISTANCE_FIELD\n  vec4 color = vec4(0.0, 0.0, 0.0, 0.0);\n  vec4 fillPixelColor = overrideColor * vcolor;\n\n  // Attempt to sample texel centers to avoid that thin cross outlines\n  // disappear with large symbol sizes.\n  // see: https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/7058#issuecomment-603041\n  const float txSize = 128.0;\n  const float texelSize = 1.0 / txSize;\n  // Calculate how much we have to add/subtract to/from each texel to reach the size of an onscreen pixel\n  vec2 scaleFactor = (vsize - txSize) * texelSize;\n  vec2 samplePos = vtc + (vec2(1.0, -1.0) * texelSize) * scaleFactor;\n\n  // Get distance and map it into [-0.5, 0.5]\n  float d = rgba2float(texture2D(tex, samplePos)) - 0.5;\n\n  // Distance in output units (i.e. pixels)\n  float dist = d * vsize.x;\n\n  // Create smooth transition from the icon into its outline\n  fillPixelColor.a *= clamp(0.5 - dist, 0.0, 1.0);\n\n  if (outlineSize > 0.25) {\n    vec4 outlinePixelColor = outlineColor;\n    float clampedOutlineSize = min(outlineSize, 0.5*vsize.x);\n\n    // Create smooth transition around outline\n    outlinePixelColor.a *= clamp(0.5 - (abs(dist) - 0.5*clampedOutlineSize), 0.0, 1.0);\n\n    // perform un-premultiplied over operator (see https://en.wikipedia.org/wiki/Alpha_compositing#Description)\n    float compositeAlpha = outlinePixelColor.a + fillPixelColor.a * (1.0 - outlinePixelColor.a);\n    vec3 compositeColor = vec3(outlinePixelColor) * outlinePixelColor.a +\n      vec3(fillPixelColor) * fillPixelColor.a * (1.0 - outlinePixelColor.a);\n\n    gl_FragColor = vec4(compositeColor, compositeAlpha);\n  }\n  else {\n    gl_FragColor = premultiplyAlpha(fillPixelColor);\n  }\n\n  // visualize SDF:\n  // gl_FragColor = vec4(clamp(-dist/vsize.x*2.0, 0.0, 1.0), clamp(dist/vsize.x*2.0, 0.0, 1.0), 0.0, 1.0);\n#else\n\n  // HUDMaterial is rendered with a blending mode that assumes a pre-multiplied\n  // fragment color. Input textures should already be pre-multiplied and so\n  // don't require adjustment, but the override and vertex colors must be\n  // modulated by their alpha values.\n\n  gl_FragColor = texture2D(tex, vtc, -0.5) * premultiplyAlpha(overrideColor * vcolor);\n\n#endif\n\n#ifdef DEBUG_DRAW_BORDER\n   float isBorder = float(any(lessThan(debugBorderCoords.xy, vec2(debugBorderCoords.z))) || any(greaterThan(debugBorderCoords.xy, vec2(1.0 - debugBorderCoords.z))));\n   gl_FragColor = mix(gl_FragColor, vec4(1.0, 0.0, 1.0, 1.0), isBorder);\n#endif\n\n  if (gl_FragColor.a < 0.1) {\n    discard;\n  }\n","occlusionTest.frag":"#include <util/fsPrecision.glsl>\n\nuniform vec4 color;\n\nvoid main() {\n  gl_FragColor = color;\n}\n","occlusionTest.vert":"#include <util/vsPrecision.glsl>\n#include <util/alignPixel.glsl>\n#include <util/hud.glsl>\n#include <util/slice.glsl>\n\nvoid main(void) {\n  vec4 posProjCenter;\n\n  // Check for special value of position (0, 0, 0) which is used by the Renderer when graphics\n  // are removed before the VBO is recompacted. If this is the case, then we just project outside\n  // of clip space.\n  if (dot(position, position) > 0.0) {\n    // Render single point to center of the pixel to avoid subpixel filtering to affect\n    // the marker color\n    ProjectHUDAux projectAux;\n    vec4 posProj = projectPositionHUD(projectAux);\n    posProjCenter = alignToPixelCenter(posProj, viewport.zw);\n\n    vec3 vpos = projectAux.posModel;\n    if (rejectBySlice(vpos)) {\n      // Project out of clip space\n      posProjCenter = vec4(1e038, 1e038, 1e038, 1.0);\n    }\n  }\n  else {\n    // Project out of clip space\n    posProjCenter = vec4(1e038, 1e038, 1e038, 1.0);\n  }\n\n  gl_Position = posProjCenter;\n  gl_PointSize = 1.0;\n}\n"},lineCallout:{"lineCallout.frag":"#include <util/fsPrecision.glsl>\n\nuniform vec4 color;\nuniform vec4 borderColor;\n\nvarying vec4 coverageSampling;\nvarying vec2 lineSizes;\n\nvoid main() {\n  // Mix between line and border coverage offsets depending on whether we need\n  // a border (based on the sidedness).\n  vec2 coverage = min(1.0 - clamp(abs(coverageSampling.xy) - coverageSampling.zw, 0.0, 1.0), lineSizes);\n\n  // Mix between border and line color based on the line coverage (conceptually the line\n  // blends on top of the border background).\n  //\n  // Anti-alias by blending final result using the full (including optional border) coverage\n  // and the color alpha\n  float borderAlpha = color.a * borderColor.a * coverage.y;\n  float colorAlpha = color.a * coverage.x;\n\n  float finalAlpha = mix(borderAlpha, 1.0, colorAlpha);\n\n#ifdef DEPTH_HUD\n\n  if (finalAlpha < 0.01) {\n    discard;\n  }\n\n#else\n\n  // Compute the finalRgb, but keep it pre-multiplied (for unpre-multiplied you\n  // need to divide by finalAlpha). We avoid the division here by setting the\n  // appropriate blending function in the material.\n  vec3 finalRgb = mix(borderColor.rgb * borderAlpha, color.rgb, colorAlpha);\n\n  gl_FragColor = vec4(finalRgb, finalAlpha);\n\n#endif\n\n}\n",
"lineCallout.vert":"#include <util/vsPrecision.glsl>\n#include <util/alignPixel.glsl>\n#include <util/hud.glsl>\n#include <util/slice.glsl>\n\nattribute vec2 uv0;\n\nuniform float lineSize;\nuniform vec2 pixelToNDC;\nuniform float borderSize;\nuniform vec2 screenOffset;\n\nvarying vec4 coverageSampling;\nvarying vec2 lineSizes;\n\nvoid main(void) {\n\n  ProjectHUDAux projectAux;\n  vec4 endPoint = projectPositionHUD(projectAux);\n\n  vec3 vpos = projectAux.posModel;\n  if (rejectBySlice(vpos)) {\n    gl_Position = vec4(1e38, 1e38, 1e38, 1.0);\n    return;\n  }\n\n#ifdef OCCL_TEST\n  if (!testVisibilityHUD(endPoint)) {\n    gl_Position = vec4(1e38, 1e38, 1e38, 1.0);\n    return;\n  }\n#endif\n\n#ifdef SCREEN_SIZE_PERSPECTIVE\n  vec4 perspectiveFactor = screenSizePerspectiveScaleFactor(projectAux.absCosAngle, projectAux.distanceToCamera, screenSizePerspectiveAlignment);\n  vec2 screenOffsetScaled = applyScreenSizePerspectiveScaleFactorVec2(screenOffset, perspectiveFactor);\n#else\n  vec2 screenOffsetScaled = screenOffset;\n#endif\n\n  // Add view dependent polygon offset to get exact same original starting point. This is mostly\n  // used to get the correct depth value\n  vec3 posView = (view * (model * vec4(position, 1.0))).xyz;\n  applyHUDViewDependentPolygonOffset(auxpos1.w, projectAux.absCosAngle, posView);\n\n  vec4 startPoint = proj * vec4(posView, 1.0);\n\n  // Apply screen offset to both start and end point\n  vec2 screenOffsetNorm = screenOffsetScaled * 2.0 / viewport.zw;\n\n  startPoint.xy += screenOffsetNorm * startPoint.w;\n  endPoint.xy += screenOffsetNorm * endPoint.w;\n\n  // Align start and end to pixel origin\n  vec4 startAligned = alignToPixelOrigin(startPoint, viewport.zw);\n  vec4 endAligned = alignToPixelOrigin(endPoint, viewport.zw);\n\n#ifdef DEPTH_HUD\n\n#ifdef DEPTH_HUD_ALIGN_START\n  endAligned = vec4(endAligned.xy / endAligned.w * startAligned.w, startAligned.zw);\n#else\n  startAligned = vec4(startAligned.xy / startAligned.w * endAligned.w, endAligned.zw);\n#endif\n\n#endif\n\n  vec4 projectedPosition = mix(startAligned, endAligned, uv0.y);\n\n  // The direction of the line in screen space\n  vec2 screenSpaceDirection = normalize(endAligned.xy / endAligned.w - startAligned.xy / startAligned.w);\n  vec2 perpendicularScreenSpaceDirection = vec2(screenSpaceDirection.y, -screenSpaceDirection.x);\n\n#ifdef SCREEN_SIZE_PERSPECTIVE\n\n  float lineSizeScaled = applyScreenSizePerspectiveScaleFactorFloat(lineSize, perspectiveFactor);\n  float borderSizeScaled = applyScreenSizePerspectiveScaleFactorFloat(borderSize, perspectiveFactor);\n\n#else\n\n  float lineSizeScaled = lineSize;\n  float borderSizeScaled = borderSize;\n\n#endif\n\n  float halfPixelSize = lineSizeScaled * 0.5;\n  // Calculate a pixel offset from the edge of the pixel, s.t. we keep the line aligned\n  // to pixels if it has a full pixel size. Since pixel aligned biases to the bottom-left,\n  // we bias the size to the right (for odd sizes) to balance out the bias. Grow sub-pixel\n  // sizes towards the left or right s.t. there is a smooth transition (e.g. from 2 to 3 px).\n  float halfWholePixelSize = floor(lineSizeScaled) * 0.5;\n  float halfPixelSizeInt = floor(halfWholePixelSize);\n\n  // Sub-pixel offset if we need to grow sub-pixels to the left\n  float subpixelOffset = -fract(lineSizeScaled) * float(halfWholePixelSize > 0.0);\n\n  // Pixel offset aligning to whole pixels and adding subpixel offset if needed\n  float pixelOffset = -halfPixelSizeInt + subpixelOffset;\n\n  // Compute full ndc offset, adding 1px padding for doing anti-aliasing and the border size\n  float padding = 1.0 + borderSizeScaled;\n  vec2 ndcOffset = (pixelOffset - padding + uv0.x * (lineSizeScaled + padding + padding)) * pixelToNDC;\n\n  // Offset x/y from the center of the line in screen space\n  projectedPosition.xy += perpendicularScreenSpaceDirection * ndcOffset * projectedPosition.w;\n\n  // Compute a coverage varying which we can use in the fragment shader to determine\n  // how much a pixel is actually covered by the line (i.e. to anti alias the line).\n  // This works by computing two coordinates that can be linearly interpolated and then\n  // subtracted to find out how far away from the line edge we are.\n  float edgeDirection = (uv0.x * 2.0 - 1.0);\n\n  float halfBorderSize = 0.5 * borderSizeScaled;\n  float halfPixelSizeAndBorder = halfPixelSize + halfBorderSize;\n  float outerEdgeCoverageSampler = edgeDirection * (halfPixelSizeAndBorder + halfBorderSize + 1.0);\n\n  float isOneSided = float(lineSizeScaled < 2.0 && borderSize < 2.0);\n\n  coverageSampling = vec4(\n    // Edge coordinate\n    outerEdgeCoverageSampler,\n\n    // Border edge coordinate\n    outerEdgeCoverageSampler - halfPixelSizeAndBorder * isOneSided,\n\n    // Line offset\n    halfPixelSize - 0.5,\n\n    // Border offset\n    halfBorderSize - 0.5 + halfPixelSizeAndBorder * (1.0 - isOneSided)\n  );\n\n  lineSizes = vec2(lineSizeScaled, borderSizeScaled);\n\n  gl_Position = projectedPosition;\n}\n"},measurementArrow:{"measurementArrow.frag":"#include <util/fsPrecision.glsl>\n\nuniform float outlineSize;\nuniform vec4 outlineColor;\nuniform float stripeLength;\nuniform vec4 stripeEvenColor;\nuniform vec4 stripeOddColor;\n\nvarying vec2 vtc;\nvarying float vlength;\nvarying float vradius;\n\n#define INV_SQRT2 (1.0 / sqrt(2.0))\n\nvec4 arrowColor(vec2 tc, float len) {\n  float d = INV_SQRT2 * (tc.x - abs(tc.y));\n  d = min(d, INV_SQRT2 * (len - tc.x - abs(tc.y)));\n  d = min(d, 1.0 - abs(tc.y));\n\n  if (d < 0.0) {\n    return vec4(0.0);\n  } else if (d < outlineSize) {\n    return outlineColor;\n  } else {\n    return fract(0.5 / stripeLength * tc.x * vradius) >= 0.5 ? stripeOddColor : stripeEvenColor;\n  }\n}\n\nvoid main(void) {\n  vec2 ntc = vec2(vtc.x / vradius, vtc.y);\n  vec4 color = arrowColor(ntc, vlength / vradius);\n  if (color.a == 0.0) {\n    discard;\n  }\n  gl_FragColor = color;\n}\n","measurementArrow.vert":"#include <util/vsPrecision.glsl>\n\nuniform mat4 proj;\nuniform mat4 view;\nuniform mat4 model;\n\nuniform float width;\n\nattribute vec3 position;\nattribute vec3 normal;\nattribute vec2 uv0;\nattribute float auxpos1;\n\nvarying vec2 vtc;\nvarying float vlength;\nvarying float vradius;\n\nvoid main(void) {\n  vec3 bitangent = normal;\n\n  vtc = uv0;\n  vlength = auxpos1;\n  vradius = 0.5 * width;\n\n  vec4 pos = view * vec4((model * vec4(position + vradius * bitangent * uv0.y, 1.0)).xyz, 1.0);\n  gl_Position = proj * pos;\n}\n"},nativeLine:{"colorPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n\nuniform vec4 constantColor;\n\nvarying vec3 vpos;\n\n#ifdef VERTEXCOLORS\nvarying vec4 vcolor;\n#endif\n\nvoid main() {\n  discardBySlice(vpos);\n#ifdef VERTEXCOLORS\n  gl_FragColor = highlightSlice(vcolor, vpos);\n#else\n  gl_FragColor = highlightSlice(constantColor, vpos);\n#endif\n}\n","highlightPass.frag":"#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n#include <util/highlight.glsl>\n\nvarying vec3 vpos;\n\nuniform sampler2D depthTex;\nuniform vec4 highlightViewportPixelSz;\n\nvoid main() {\n  discardBySlice(vpos);\n\n  gl_FragColor = highlightData(gl_FragCoord, depthTex, highlightViewportPixelSz);\n}\n","nativeLine.vert":"#include <util/vsPrecision.glsl>\n\nuniform mat4 proj;\nuniform mat4 view;\nuniform mat4 model;\n\nattribute vec3 position;\n\n#ifdef VERTEXCOLORS\nattribute vec4 color;\n#endif\n\n\nvarying vec3 vpos;\n\n#ifdef VERTEXCOLORS\nvarying vec4 vcolor;\n#endif\n\n\nvoid main(void) {\n  vpos = (model * vec4(position, 1.0)).xyz;\n  #ifdef VERTEXCOLORS\n    vcolor = color * 0.003921568627451; // = 1/255\n  #endif\n\n  gl_Position = proj * view * vec4(vpos, 1.0);\n}\n"},pathMaterial:{"colorMixMode.glsl":"#include <util/color.glsl>\n\n/*\n * The color mix modes are encoded in the symbol color as follows:\n *  - Fully transparent symbols are represented with alpha 0 for\n *    all color mix modes (except ignore).\n *  - color mix mode ignore is encoded as multiply with white\n *  - the other 3 color mix modes (tint, replace, multiply) are\n *    equally distributed on the remaining 255 alpha values, which\n *    gives us 85 possible alpha values\n *\n * alpha             0 : fully transparent\n * alpha in [  1 -  85]: tint\n * alpha in [ 86 - 170]: replace\n * alpha in [171 - 255]: multiply\n */\nvec4 decodeSymbolColor(vec4 symbolColor, out int colorMixMode) {\n  float symbolAlpha = 0.0;\n\n  const float maxTint = 85.0;\n  const float maxReplace = 170.0;\n  const float scaleAlpha = 3.0;\n\n  if (symbolColor.a == 0.0) {\n    colorMixMode = 1; // fully transparent -> multiply\n    symbolAlpha = 0.0;\n  }\n  else if (symbolColor.a <= maxTint) {\n    colorMixMode = 0; // tint\n    symbolAlpha = scaleAlpha * symbolColor.a;\n  }\n  else if (symbolColor.a <= maxReplace) {\n    colorMixMode = 3; // replace\n    symbolAlpha = scaleAlpha * (symbolColor.a - maxTint);\n  }\n  else {\n    colorMixMode = 1;  // multiply\n    symbolAlpha = scaleAlpha * (symbolColor.a - maxReplace);\n  }\n\n  return vec4(symbolColor.rgb, symbolAlpha);\n}\n\nvec3 mixExternalColor(vec3 internalColor, vec3 textureColor, vec3 externalColor, int mode) {\n\n  // workaround for artifacts in OSX using Intel Iris Pro\n  // see: https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/10475\n  vec3 internalMixed = internalColor * textureColor;\n  vec3 allMixed = internalMixed * externalColor;\n\n  if (mode == 1 /* multiply */) {\n    return allMixed;\n  }\n  else if (mode == 2 /* ignore */ ) {\n    return internalMixed;\n  }\n  else if (mode == 3 /* replace */ ) {\n    return externalColor;\n  }\n  else {\n    // tint (or something invalid)\n    vec3 hsvIn = rgb2hsv(internalMixed);\n    vec3 hsvTint = rgb2hsv(externalColor);\n    vec3 hsvOut = vec3(hsvTint.x, hsvTint.y, hsvIn.z * hsvTint.z);\n    return hsv2rgb(hsvOut);\n  }\n}\n\nfloat mixExternalOpacity(float internalOpacity, float textureOpacity, float externalOpacity, int mode) {\n\n  // workaround for artifacts in OSX using Intel Iris Pro\n  // see: https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/10475\n  float internalMixed = internalOpacity * textureOpacity;\n  float allMixed = internalMixed * externalOpacity;\n\n  if (mode == 2 /* ignore */ ) {\n    return internalMixed;\n  }\n  else if (mode == 3 /* replace */ ) {\n    return externalOpacity;\n  }\n  else {\n    // multiply or tint (or something invalid)\n    return allMixed;\n  }\n}\n","colorPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n#include <util/sceneLighting.glsl>\n\n#ifdef TEXTURING\nuniform sampler2D tex;\nuniform vec2 texSize;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nvarying vec4 regionV;\n#endif\n#endif\n\nuniform vec3 camPos;\nuniform vec3 localOrigin;\n\n// material parameters\n//////////////////////////////////////////\nuniform vec3 ambient;\nuniform vec3 diffuse;\nuniform vec3 specular;\nuniform float opacity;\nuniform float layerOpacity;\n\n#if defined(SYMBOLVERTEXCOLORS) || defined(COMPONENTCOLORS)\nvarying mediump float colorMixMode; // varying int is not supported in WebGL\n#else\nuniform int colorMixMode;\n#endif\n\n#ifdef RECEIVE_SHADOWS\nuniform sampler2D depthTex;\nuniform int shadowMapNum;\nuniform vec4 shadowMapDistance;\nuniform mat4 shadowMapMatrix[4];\nuniform float depthHalfPixelSz;\n#endif\n\n#ifdef RECEIVE_SSAO\nuniform sampler2D ssaoTex;\nuniform vec4 viewportPixelSz;\n#endif\n\nvarying vec3 vpos;\nvarying vec3 vnormal;\n// the vertex color variable will contain vvColor and/or vvOpacity or 1,1,1,1\nvarying vec4 vcolor; \nvarying vec4 vcolorExt;\n\n#ifdef RECEIVE_SHADOWS\nvarying float linearDepth;\n#include <util/shadow.glsl>\n#endif\n\n#ifdef TEXTURING\n#include <materials/pathMaterial/texturing.glsl>\n#endif\n\n#include <materials/pathMaterial/colorMixMode.glsl>\n\nvoid main() {\n  discardBySlice(vpos);\n\n#ifdef TEXTURING\n  vec4 texColor = textureLookup(tex, vtc);\n  if (texColor.a < ALPHA_THRESHOLD) {\n    discard;\n  }\n#else /* TEXTURING */\n  vec4 texColor = vec4(1.0);\n#endif /* TEXTURING */\n\n  vec3 viewDir = vpos - camPos;\n\n  // compute normal\n  // TODO: this is not in sync with the normal pass\n#ifdef GROUND_NORMAL_SHADING\n#if VIEWING_MODE == VIEWING_MODE_GLOBAL\n  vec3 normal = normalize(vpos + localOrigin);\n#else\n  vec3 normal = vec3(0.0, 0.0, 1.0);\n#endif\n#else\n#ifdef DOUBLESIDED\n  vec3 normal = dot(vnormal, viewDir)>0.0 ? -vnormal : vnormal;\n#elif defined(WINDINGORDERDOUBLESIDED)\n  vec3 normal = gl_FrontFacing ? vnormal : -vnormal;\n#else\n  vec3 normal = vnormal;\n#endif\n  normal = normalize(normal);\n#endif\n\n  // compute ssao\n#ifdef RECEIVE_SSAO\n  float ssao = texture2D(ssaoTex, (gl_FragCoord.xy - viewportPixelSz.xy) * viewportPixelSz.zw).a;\n  ssao = viewportPixelSz.z < 0.0 ? 1.0 : ssao;\n#else\n  float ssao = 1.0;\n#endif\n\n  // At global scale we create some additional ambient light based on the main light to simulate global illumination\n  float additionalAmbientScale;\n  vec3 additionalLight = sceneLightingAdditionalLightGlobal(vpos + localOrigin, ssao, additionalAmbientScale);\n\n  // compute shadowing\n  float shadow = 0.0;\n#ifdef RECEIVE_SHADOWS\n  shadow = evalShadow(vpos, linearDepth, depthTex, shadowMapNum, shadowMapDistance, shadowMapMatrix, depthHalfPixelSz);\n#elif VIEWING_MODE == VIEWING_MODE_GLOBAL\n  // at global scale (and in global scenes) we fall back to this approximation\n  // to shadow objects on the dark side of the earth\n  shadow = lightingGlobalFactor * (1.0 - additionalAmbientScale);\n#endif\n\n  vec3 matColor = max(ambient, diffuse); // combine the old material parameters into a single one\n\n  vec3 albedo_ = mixExternalColor(vcolor.rgb * matColor, texColor.rgb, vcolorExt.rgb, int(colorMixMode));\n  float opacity_ = layerOpacity * mixExternalOpacity(vcolor.a * opacity, texColor.a, vcolorExt.a, int(colorMixMode));\n  albedo_+= 0.25 * specular; // don't completely ignore specular for now\n\n#ifdef TRANSPARENCY_DISCARD\n  if (opacity_ < 0.001) {\n    discard;\n  }\n#endif\n\n  vec3 shadedColor = evaluateSceneLighting(normal, albedo_, shadow, 1.0 - ssao, additionalLight);\n  gl_FragColor = vec4(shadedColor, opacity_);\n  gl_FragColor = highlightSlice(gl_FragColor, vpos);\n}\n","colorPass.vert":"#include <util/vsPrecision.glsl>\n\n#include <materials/pathMaterial/commonInputs.glsl>\n\nattribute vec3 position;\nattribute vec4 auxpos1; // direction offset\n#ifdef COMPRESSED_NORMALS\nattribute vec2 normalCompressed;\n#else\nattribute vec3 normal;\n#endif\nvarying vec3 vpos;\nvarying vec3 vnormal;\n\n#ifdef TEXTURING\nattribute vec2 uv0;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nattribute vec4 region;\nvarying vec4 regionV;\n#endif\n#endif\n\n#ifdef COMPONENTCOLORS\nuniform sampler2D uComponentColorTex;\nuniform vec2 uComponentColorTexInvDim;\n\nattribute float componentIndex;\n\nvec4 readComponentColor() {\n  float normalizedIndex = (componentIndex + 0.5) * uComponentColorTexInvDim.x;\n  vec2 indexCoord = vec2(\n    mod(normalizedIndex, 1.0),\n    (floor(normalizedIndex) + 0.5) * uComponentColorTexInvDim.y\n  );\n  return texture2D(uComponentColorTex, indexCoord);\n}\n#endif\n\n#ifdef RECEIVE_SHADOWS\nvarying float linearDepth;\n#endif\n\n#ifdef SYMBOLVERTEXCOLORS\nattribute vec4 symbolColor;\n#endif\n\n// Workaround for https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/13452\n// We pass the externalColor uniform from VS to FS through the vcolorExt varying because\n// there is a driver bug for Intel Integrated Graphics which led to rendering artifacts\n// since the introduction of https://devtopia.esri.com/WebGIS/arcgis-js-api/pull/12673\n// This should be further cleaned up later with through the following issue:\n// https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/12763\nuniform vec4 externalColor;\n// the vertex color variable will contain vvColor and/or vvOpacity or 1,1,1,1\nvarying vec4 vcolor;\nvarying vec4 vcolorExt;\n\n#if defined(SYMBOLVERTEXCOLORS) || defined(COMPONENTCOLORS)\nvarying mediump float colorMixMode; // varying int is not supported in WebGL\n#endif\n\n#include <materials/pathMaterial/visualVariables.glsl>\n\n#if defined(VV_SIZE) || defined(VV_COLOR) || defined(VV_OPACITY)\nattribute vec4 auxpos2;\n#endif\n\n#include <materials/pathMaterial/commonFunctions.glsl>\n#include <materials/pathMaterial/localNormal.glsl>\n#include <materials/pathMaterial/colorMixMode.glsl>\n\nvoid main() {\n  vpos = calculateVPos();\n\n  vnormal = normalize((modelNormal * localNormal()).xyz);\n\n  gl_Position = proj * view * vec4(vpos, 1.0);\n\n#ifdef RECEIVE_SHADOWS\n  // Shadowmap's cascading index used to be based on '1.0 / gl_FragCoord.w'\n  // (i.e. the perspective interpolation of 'gl_Position.w'). Precision\n  // issues on iPad/iPhone with the 'w' component require the depth to be\n  // passed as varying to properly drive the cascading shadow map index.\n  linearDepth = gl_Position.w;\n#endif\n\n  vcolorExt = externalColor;\n\n  vcolor = vec4(1.0, 1.0, 1.0, 1.0);\n#ifdef VV_COLOR\n  vcolor = vvGetColor(auxpos2, vvColorValues, vvColorColors);\n#endif\n#ifdef VV_OPACITY\n  // there might be opacity values in vvColor but according to the logic in graphicUtils.mixinColorAndOpacity,\n  // this value will be overridden by vvOpacity so we do the same here\n  vcolor.a = vvGetOpacity(auxpos2, vvOpacityValues, vvOpacityOpacities);\n#endif\n\n\n#ifdef SYMBOLVERTEXCOLORS\n  int symbolColorMixMode;\n  vcolorExt *= decodeSymbolColor(symbolColor, symbolColorMixMode) * 0.003921568627451; // = 1/255;\n  colorMixMode = float(symbolColorMixMode) + 0.5; // add 0.5 to avoid interpolation artifacts\n#endif\n\n#ifdef COMPONENTCOLORS\n  int symbolColorMixMode;\n  vcolorExt *= decodeSymbolColor(readComponentColor() * 255.0, symbolColorMixMode) * 0.003921568627451; // = 1/255;\n  colorMixMode = float(symbolColorMixMode) + 0.5; // add 0.5 to avoid interpolation artifacts\n#endif\n\n#ifdef TEXTURING\n  // the v coordinate is stored in auxpos1.w\n#ifndef FLIPV\n  vtc = vec2(uv0.x, auxpos1.w);\n#else\n  vtc = vec2(uv0.x, 1.0-auxpos1.w);\n#endif\n#ifdef TEXTURE_ATLAS\n  regionV = region;\n#endif\n#endif /* TEXTURING */\n\n}\n","commonFunctions.glsl":"#include <materials/pathMaterial/localPosition.glsl>\n#include <util/doublePrecision.glsl>\n\nvec3 calculateVPos() {\n  return (model * localPosition()).xyz;\n}","commonInputs.glsl":"uniform mat4 proj;\nuniform mat4 view;\n\nuniform vec3 camPos;\nuniform vec3 localOrigin;\n\nuniform mat4 model;\nuniform mat4 modelNormal;\n\nuniform float size;\n\n// ---------------------------------------------- ++","depthPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/encoding.glsl>\n#include <util/depth.glsl>\n#include <util/slice.glsl>\n\nvarying float depth;\nvarying vec3 vpos;\n\n#ifdef TEXTURING\nuniform sampler2D tex;\nuniform vec2 texSize;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nvarying vec4 regionV;\n#endif\n#endif\n\n#ifdef TEXTURING\n#include <materials/pathMaterial/texturing.glsl>\n#endif\n\nvoid main() {\n  discardBySlice(vpos);\n\n#ifdef TEXTURING\n  if (textureLookup(tex, vtc).a < ALPHA_THRESHOLD) {\n    discard;\n  }\n#endif\n\n#ifndef BIAS_SHADOWMAP\n  gl_FragColor = float2rgba(depth);\n#else\n  gl_FragColor = float2rgba(calcFragDepth(depth));\n#endif\n}\n","depthPass.vert":"#include <util/vsPrecision.glsl>\n\n#include <materials/pathMaterial/commonInputs.glsl>\n\nuniform vec2 nearFar;\nattribute vec3 position;\nattribute vec4 auxpos1; // direction offset\n\nvarying float depth;\nvarying vec3 vpos;\n\n#ifdef TEXTURING\nattribute vec2 uv0;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nattribute vec4 region;\nvarying vec4 regionV;\n#endif\n#endif\n\n#include <materials/pathMaterial/visualVariables.glsl>\n\n#if defined(VV_SIZE)\nattribute vec4 auxpos2;\n#endif\n\n#include <materials/pathMaterial/commonFunctions.glsl>\n\nvoid main(void) {\n  vpos = calculateVPos();\n\n  vec4 eye = view * vec4(vpos, 1.0);\n\n  gl_Position = proj * eye;\n  depth = (-eye.z - nearFar[0]) / (nearFar[1] - nearFar[0]) ;\n\n#ifdef TEXTURING\n#ifndef FLIPV\n  vtc = uv0;\n#else\n  vtc = vec2(uv0.x, 1.0-uv0.y);\n#endif\n#ifdef TEXTURE_ATLAS\n  regionV = region;\n#endif\n#endif /* TEXTURING */\n\n}\n","highlightPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n#include <util/highlight.glsl>\n\nvarying vec3 vpos;\n\n#ifdef TEXTURING\nuniform sampler2D tex;\nuniform vec2 texSize;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nvarying vec4 regionV;\n#endif\n#endif\n\nuniform sampler2D depthTex;\nuniform vec4 highlightViewportPixelSz;\n\n#ifdef TEXTURING\n#include <materials/pathMaterial/texturing.glsl>\n#endif\n\nvoid main() {\n  discardBySlice(vpos);\n\n#ifdef TEXTURING\n  if (textureLookup(tex, vtc).a < ALPHA_THRESHOLD) {\n    discard;\n  }\n#endif\n\n  gl_FragColor = highlightData(gl_FragCoord, depthTex, highlightViewportPixelSz);\n}\n","highlightPass.vert":"#include <util/vsPrecision.glsl>\n\n#include <materials/pathMaterial/commonInputs.glsl>\n\nattribute vec3 position;\nattribute vec4 auxpos1; // direction offset\n\nvarying vec3 vpos;\n\n#ifdef TEXTURING\nattribute vec2 uv0;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nattribute vec4 region;\nvarying vec4 regionV;\n#endif\n#endif\n\n#include <materials/pathMaterial/visualVariables.glsl>\n\n#if defined(VV_SIZE)\nattribute vec4 auxpos2;\n#endif\n\n#include <materials/pathMaterial/commonFunctions.glsl>\n\nvoid main(void) {\n  vpos = calculateVPos();\n\n  gl_Position = proj * view * vec4(vpos, 1.0);\n\n#ifdef TEXTURING\n#ifndef FLIPV\n  vtc = uv0;\n#else\n  vtc = vec2(uv0.x, 1.0-uv0.y);\n#endif\n#ifdef TEXTURE_ATLAS\n  regionV = region;\n#endif\n#endif /* TEXTURING */\n\n}\n","localNormal.glsl":"#include <util/normalEncoding.glsl>\n\n# ifdef COMPRESSED_NORMALS\nvec4 localNormal() { return vec4(decodeNormal(normalCompressed), 1.0); }\n# else\nvec4 localNormal() { return vec4(normal, 1.0); }\n# endif\n","localPosition.glsl":"#ifdef VV_SIZE\nvec4 localPosition() {\n    vec3 sizeScale = vvGetScale(auxpos2);\n    vec3 positionOffset = auxpos1.xyz*sizeScale;\n    return vec4( position+positionOffset, 1.0 );\n}\n#else\nvec4 localPosition() {\n    vec3 sizeScale = vec3(size);\n    vec3 positionOffset = auxpos1.xyz*sizeScale;\n    return vec4(position+positionOffset, 1.0);\n}\n#endif\n","normalPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n\nvarying vec3 vnormal;\nvarying vec3 vpos;\n\n#ifdef TEXTURING\nuniform sampler2D tex;\nuniform vec2 texSize;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nvarying vec4 regionV;\n#endif\n#endif\n\n#ifdef TEXTURING\n#include <materials/pathMaterial/texturing.glsl>\n#endif\n\nvoid main() {\n  discardBySlice(vpos);\n\n#ifdef TEXTURING\n  if (textureLookup(tex, vtc).a < ALPHA_THRESHOLD) {\n    discard;\n  }\n#endif\n\n  vec3 normal = normalize(vnormal);\n  if (gl_FrontFacing == false) normal = -normal;\n\n#ifndef ALPHA_ZERO\n  gl_FragColor = vec4(vec3(.5) + .5 * normal, 1.0);\n#else\n  gl_FragColor = vec4(vec3(.5) + .5 * normal, 0.0);\n#endif\n}\n","normalPass.vert":"#include <util/vsPrecision.glsl>\n\n#include <materials/pathMaterial/commonInputs.glsl>\n\nuniform mat4 viewNormal;\nattribute vec3 position;\nattribute vec4 auxpos1; // direction offset\n#ifdef COMPRESSED_NORMALS\nattribute vec2 normalCompressed;\n#else\nattribute vec3 normal;\n#endif\n\n#ifdef TEXTURING\nattribute vec2 uv0;\nvarying vec2 vtc;\n#ifdef TEXTURE_ATLAS\nattribute vec4 region;\nvarying vec4 regionV;\n#endif\n#endif\n\nvarying vec3 vnormal;\nvarying vec3 vpos;\n\n#include <materials/pathMaterial/visualVariables.glsl>\n\n#if defined(VV_SIZE)\nattribute vec4 auxpos2;\n#endif\n\n#include <materials/pathMaterial/commonFunctions.glsl>\n#include <materials/pathMaterial/localNormal.glsl>\n\nvoid main(void) {\n  vpos = calculateVPos();\n\n  vnormal = normalize((viewNormal * modelNormal * localNormal()).xyz);\n\n  gl_Position = proj * view * vec4(vpos, 1.0);\n\n#ifdef TEXTURING\n#ifndef FLIPV\n  vtc = uv0;\n#else\n  vtc = vec2(uv0.x, 1.0-uv0.y);\n#endif\n#ifdef TEXTURE_ATLAS\n  regionV = region;\n#endif\n#endif /* TEXTURING */\n\n}\n","texturing.glsl":"float calcMipMapLevel(const vec2 ddx, const vec2 ddy) {\n  // from:\n  //   - OpenGLES Common Profile Specification Version 2.0.25, Section 3.7.7 - Texture Minification\n  //   - https://www.opengl.org/discussion_boards/showthread.php/171485-Texture-LOD-calculation-(useful-for-atlasing)\n  //   - http://www.linedef.com/virtual-texture-demo.html\n  float deltaMaxSqr = max(dot(ddx, ddx), dot(ddy, ddy));\n  return max(0.0, 0.5 * log2(deltaMaxSqr));\n}\n\nvec4 textureAtlasLookup(sampler2D tex, vec2 uv, vec4 region, vec2 texSize) {\n  //[umin, vmin, umax, vmax]\n  vec2 atlasScale = region.zw - region.xy;\n  vec2 uvAtlas = fract(uv) * atlasScale + region.xy;\n\n  // calculate derivative of continuous texture coordinate\n  // to avoid mipmapping artifacts caused by manual wrapping in shader\n  vec2 dUVdx = dFdx(uv) * atlasScale;\n  vec2 dUVdy = dFdy(uv) * atlasScale;\n\n#ifdef GL_EXT_shader_texture_lod\n  return texture2DGradEXT(tex, uvAtlas, dUVdx, dUVdy);\n#else\n  // use bias to compensate for difference in automatic vs desired mipmap level\n  vec2 dUVdxAuto = dFdx(uvAtlas);\n  vec2 dUVdyAuto = dFdy(uvAtlas);\n  float mipMapLevel = calcMipMapLevel(dUVdx * texSize, dUVdy * texSize);\n  float autoMipMapLevel = calcMipMapLevel(dUVdxAuto * texSize, dUVdyAuto * texSize);\n\n  return texture2D(tex, uvAtlas, mipMapLevel - autoMipMapLevel);\n#endif\n}\n\nvec4 textureLookup(sampler2D tex, vec2 uv) {\n#ifdef TEXTURE_ATLAS\n  return textureAtlasLookup(tex, uv, regionV, texSize);\n#else\n  return texture2D(tex, uv);\n#endif\n}\n\n","visualVariables.glsl":"\n#if defined(VV_SIZE)\n  uniform vec3 vvSizeMinSize;\n  uniform vec3 vvSizeMaxSize;\n  uniform vec3 vvSizeOffset;\n  uniform vec3 vvSizeFactor;\n\n  vec3 vvGetScale(vec4 featureAttribute) {\n    // the 0.5 factor comes from the fact that the generated profiles have radius of 1\n    // but the old implementation of the Graphics3DPathSymbolLayer actually had a profile radius of 0.5\n    // for constant size values the 0.5 is applied in Graphcis3DPathSymbolLayer when setting material parms\n    // we might want to change the path geometry generation so that it produces profile radius of 0.5 too\n    return clamp(vvSizeOffset + featureAttribute.x * vvSizeFactor, vvSizeMinSize, vvSizeMaxSize)*0.5;\n  }\n#endif\n\n#ifdef VV_COLOR\n  #define VV_COLOR_N 8\n  uniform float vvColorValues[VV_COLOR_N];\n  uniform vec4 vvColorColors[VV_COLOR_N];\n\n  vec4 vvGetColor(vec4 featureAttribute, float values[VV_COLOR_N], vec4 colors[VV_COLOR_N]) {\n    float value = featureAttribute.y;\n    if (value <= values[0]) {\n      return colors[0];\n    }\n\n    for (int i = 1; i < VV_COLOR_N; ++i) {\n      if (values[i] >= value) {\n        float f = (value - values[i-1]) / (values[i] - values[i-1]);\n        return mix(colors[i-1], colors[i], f);\n      }\n    }\n\n    return colors[VV_COLOR_N - 1];\n  }\n#endif\n\n\n#ifdef VV_OPACITY\n  #define VV_OPACITY_N 8\n  uniform float vvOpacityValues[VV_OPACITY_N];\n  uniform float vvOpacityOpacities[VV_OPACITY_N];\n\n  float vvGetOpacity(vec4 featureAttribute, float values[VV_OPACITY_N], float opacities[VV_OPACITY_N]) {\n    float value = featureAttribute.z;\n    if (value <= values[0]) {\n      return opacities[0];\n    }\n\n    for (int i = 1; i < VV_OPACITY_N; ++i) {\n      if (values[i] >= value) {\n        float f = (value - values[i-1]) / (values[i] - values[i-1]);\n        return mix(opacities[i-1], opacities[i], f);\n      }\n    }\n\n    return opacities[VV_OPACITY_N - 1];\n  }\n#endif\n\n"},ribbonLine:{"colorPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n\nuniform vec4 eColor;\nvarying vec4 vColor;\nvarying vec2 vtc;\nvarying vec3 vpos;\n\n#ifdef STIPPLE\nuniform float stippleLengthDoubleInv;\n#endif\n\nvoid main() {\n  discardBySlice(vpos);\n\n#ifdef STIPPLE\n  if (fract(vtc.x * stippleLengthDoubleInv) > 0.5) {\n    discard;\n  }\n#endif\n\n  gl_FragColor = highlightSlice(eColor * vColor, vpos);\n}\n","highlightPass.frag":"#include <util/fsPrecision.glsl>\n#include <util/slice.glsl>\n\nvarying vec2 vtc;\nvarying vec3 vpos;\n\n#ifdef STIPPLE\nuniform float stippleLengthDoubleInv;\n#endif\n\nvoid main() {\n  discardBySlice(vpos);\n\n#ifdef STIPPLE\n  if (fract(vtc.x * stippleLengthDoubleInv) > 0.5) {\n    discard;\n  }\n#endif\n\n  gl_FragColor = vec4(1.0, 1.0, 1.0, 1.0);\n}\n",
"ribbonLine.vert":'#include <util/vsPrecision.glsl>\n\nuniform mat4 proj;\nuniform mat4 view;\nuniform mat4 model;\n\nuniform float extLineWidth;\nuniform float nearPlane;\nuniform float pixelRatio;\n\nattribute vec3 position;\nattribute vec2 uv0;\nattribute vec4 color;\n\nvarying vec2 vtc;\nvarying vec4 vColor;\nvarying vec3 vpos;\n\nattribute float size;\n\n#ifndef WALL\nuniform float miterLimit;\nattribute vec3 auxpos1;\nattribute vec3 auxpos2;\n#endif\n\n#ifdef SCREENSCALE\nuniform vec2 screenSize;\n\nvec4 toScreenCoords(vec3 vertex) {\n  vec4 vClipSpace = proj * view * vec4((model * vec4(vertex, 1.0)).xyz, 1.0);\n  vClipSpace.xy *= screenSize;\n  return vClipSpace/abs(vClipSpace.w);\n}\n\n#define VECTYPE vec2\n#define ZEROVEC vec2(0.0, 0.0)\n#define PERPENDICULAR(v) vec2(v.y, -v.x);\n#define ISOUTSIDE (left.x * right.y - left.y * right.x)*uv0.y > 0.0\n\n#else //ifdef SCREENSCALE\n\n#define VECTYPE vec3\n#define ZEROVEC vec3(0.0, 0.0, 0.0)\n// these macros are only valid for "strip" type lines:\n#define PERPENDICULAR(v) cross(up/*vec3(0.0, 1.0, 0.0)*/, v)\n#define ISOUTSIDE dot(cross(left, right), up/*vec3(0.0, 1.0, 0.0)*/)*uv0.y < 0.0\n\n#endif //ifdef SCREENSCALE\n\nfloat interp(float ncp, vec4 a, vec4 b) {\n  return (-ncp - a.z) / (b.z - a.z);\n}\n\n#ifdef SCREENSCALE\n\nvoid clipAndTransform(inout vec4 pos, inout vec4 prev, inout vec4 next) {\n  float vnp = nearPlane*0.99;\n\n  //We have four vertices per point on the line. Start and end vertices\n  //are treated differently --\x3e d > 0, d < 0\n  float d = abs(uv0.y) - 1.1;\n\n  //current pos behind ncp --\x3e we need to clip\n  if(pos.z > -nearPlane) {\n    if (d < 0.0) {\n      //previous in front of ncp\n      if(prev.z < -nearPlane) {\n        pos = mix(prev, pos, interp(vnp, prev, pos));\n        next = pos;\n      } else {\n        pos = vec4(0.0, 0.0, 0.0, 1.0);\n      }\n    }\n    //next in front of ncp\n    if(d > 0.0) {\n      if(next.z < -nearPlane) {\n        pos = mix(pos, next, interp(vnp, pos, next));\n        prev = pos;\n      } else {\n        pos = vec4(0.0, 0.0, 0.0, 1.0);\n      }\n    }\n  } else {\n    //current position visible\n    //previous behind ncp\n    if (prev.z > -nearPlane) {\n      prev = mix(pos, prev, interp(vnp, pos, prev));\n    }\n    //next behind ncp\n    if (next.z > -nearPlane) {\n      next = mix(next, pos, interp(vnp, next, pos));\n    }\n  }\n\n  pos= proj * pos;\n  pos.xy *= screenSize;\n  pos /= pos.w;\n\n  next = proj * next;\n  next.xy *= screenSize;\n  next /= next.w;\n\n  prev = proj * prev;\n  prev.xy *= screenSize;\n  prev /= prev.w;\n}\n\n#endif // SCREENSCALE\n\nvoid main(void) {\n  vpos = (model * vec4(position, 1.0)).xyz;\n\n#ifdef SCREENSCALE\n// Check for special value of uv0.y which is used by the Renderer when graphics\n// are removed before the VBO is recompacted. If this is the case, then we just\n// project outside of clip space.\nif (uv0.y == 0.0) {\n  // Project out of clip space\n  gl_Position = vec4(1e038, 1e038, 1e038, 1.0);\n}\nelse {\n#endif\n\nfloat lineWidth = (extLineWidth + size) * pixelRatio;\n\n#ifdef SCREENSCALE\n\n#if 0\n  vec4 pos = toScreenCoords(position.xyz);\n  vec2 left = (pos - toScreenCoords(auxpos1)).xy;\n  vec2 right = (toScreenCoords(auxpos2) - pos).xy;\n#else\n  vec4 pos  = view * vec4((model * vec4(position.xyz, 1.0)).xyz, 1.0);\n  vec4 prev = view * vec4((model * vec4(auxpos1.xyz, 1.0)).xyz, 1.0);\n  vec4 next = view * vec4((model * vec4(auxpos2.xyz, 1.0)).xyz, 1.0);\n\n  clipAndTransform(pos, prev, next);\n\n  vec2 left = (pos - prev).xy;\n  vec2 right = (next - pos).xy;\n#endif\n\n#else // ifdef SCREENSCALE\n  vec4 pos = vec4(position, 1.0);\n#ifndef WALL\n  vec3 left = position.xyz - auxpos1;\n  vec3 right = auxpos2 - position.xyz;\n  vec3 up = normalize(position.xyz);\n#endif // ifndef WALL\n#endif // ifdef SCREENSCALE\n\n#ifdef WALL\n  float displacementLen = lineWidth;\n  vec3 displacementDir = normalize(position.xyz);//vec3(0.0, 1.0, 0.0);\n#else // ifdef WALL\n\n  float leftLen = length(left);\n  left = (leftLen > 0.001) ? left/leftLen : ZEROVEC;\n\n  float rightLen = length(right);\n  right = (rightLen > 0.001) ? right/rightLen : ZEROVEC;\n\n  // determine if vertex is on the "outside or "inside" of the join\n  bool isOutside = ISOUTSIDE;\n\n  // compute miter join position first\n  float displacementLen = lineWidth;\n  VECTYPE displacementDir = normalize(left + right);\n  displacementDir = PERPENDICULAR(displacementDir);\n  if (leftLen > 0.001 && rightLen > 0.001) {\n    float nDotSeg = dot(displacementDir, left);\n    displacementLen /= length(nDotSeg*left - displacementDir);\n\n    // limit displacement of inner vertices\n    if (!isOutside) {\n      displacementLen = min(displacementLen, min(leftLen, rightLen)/abs(nDotSeg));\n    }\n  }\n\n  if (isOutside && (displacementLen > miterLimit*lineWidth)) {\n    // convert to bevel join if miterLimit is exceeded\n    if (leftLen < 0.001) {\n      displacementDir = right;\n    }\n    else if (rightLen < 0.001) {\n      displacementDir = left;\n    }\n    else {\n      displacementDir = (abs(uv0.y) - 1.1 < 0.0) ? left : right;\n    }\n    displacementDir = normalize(displacementDir);\n    displacementDir = PERPENDICULAR(displacementDir);\n    displacementLen = lineWidth;\n  }\n\n#endif // ifdef WALL\n\n#ifdef SCREENSCALE\n  pos.xy += displacementDir * floor(uv0.y + 0.5) * displacementLen;\n  pos.xy /= screenSize;\n#else\n  pos.xyz += displacementDir * floor(uv0.y + 0.5) * displacementLen;\n  pos = proj * view * model * pos;\n#endif\n\n  vtc = uv0;\n  vColor = color * 0.003921568627451; // = 1/255\n  gl_Position = pos;\n\n#ifdef SCREENSCALE\n  }\n#endif\n}\n'},slicePlane:{"slicePlane.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n\nuniform vec4 backgroundColor;\nuniform vec4 gridColor;\nuniform float ratio;\nuniform float gridWidth;\n\nvarying vec2 vUV;\n\nvoid main() {\n  const float LINE_WIDTH = 1.0;\n\n  vec2 uvScaled = vUV * gridWidth;\n  vec2 gridUV = (fract(uvScaled + 0.5) - 0.5) / (LINE_WIDTH * fwidth(uvScaled));\n  vec2 grid = (1.0 - step(0.5, gridUV)) * step(-0.5, gridUV);\n\n  // mask aliasing along edges\n  grid.x *= step(0.5, uvScaled.x) * step(uvScaled.x, gridWidth - 0.5);\n  grid.y *= step(0.5, uvScaled.y) * step(uvScaled.y, gridWidth - 0.5);\n\n  float gridFade = max(grid.x, grid.y);\n\n  float gridAlpha = gridColor.a * gridFade;\n\n  // premultiply alpha in output\n  gl_FragColor =\n    vec4(backgroundColor.rgb * backgroundColor.a, backgroundColor.a) * (1.0 - gridAlpha) +\n    vec4(gridColor.rgb, 1.0) * gridAlpha;\n}\n","slicePlane.vert":"#include <util/vsPrecision.glsl>\n\nuniform mat4 proj;\nuniform mat4 view;\nuniform mat4 model;\n\nattribute vec3 position;\nattribute vec2 uv0;\n\nvarying vec2 vUV;\n\nvoid main(void) {\n  vUV = uv0;\n  gl_Position = proj * view * vec4((model * vec4(position, 1.0)).xyz, 1.0);\n}\n"}},misc:{"blendLayers.frag":"#include <util/fsPrecision.glsl>\n\nvarying vec2 uv;\n\nuniform sampler2D tex;\nuniform float opacity;\n\nvoid main() {\n  vec4 color = texture2D(tex, uv);\n\n  // Note: output in pre-multiplied alpha for correct alpha compositing\n  gl_FragColor = vec4(color.xyz, 1.0) * color.a * opacity;\n}\n","blendLayers.vert":"#include <util/vsPrecision.glsl>\n\nattribute vec3 position;\nattribute vec2 uv0;\n\nuniform float scale;\nuniform vec2 offset;\n\nvarying vec2 uv;\n\nvoid main(void) {\n  gl_Position = vec4(position, 1.0);\n  uv = uv0 * scale + offset;;\n}\n","texOnly.frag":"#include <util/fsPrecision.glsl>\n\nuniform sampler2D tex;\nuniform vec4 color;\nvarying vec2 vtc;\n\nvoid main() {\n  vec4 texColor = texture2D(tex, vtc);\n  gl_FragColor = texColor * color;\n}\n","texOnly.vert":"#include <util/vsPrecision.glsl>\n\nattribute vec3 position;\nattribute vec2 uv0;\n\nvarying vec2 vtc;\n\nvoid main(void) {\n  gl_Position = vec4(position, 1.0);\n  vtc = uv0;\n}\n"},pointRenderer:{"pointRenderer.frag":"#include <util/fsPrecision.glsl>\n#include <util/encoding.glsl>\n\n#ifdef DEPTH_PASS\nvarying float depth;\n#else\nvarying vec3 vColor;\n#endif\n\nvoid main(void) {\n  vec2 vOffset = gl_PointCoord - vec2(0.5, 0.5);\n  float r2 = dot(vOffset, vOffset);\n\n  if (r2 > 0.25) {\n    discard;\n  }\n\n#ifdef DEPTH_PASS\n  gl_FragColor = float2rgba(depth);\n#else\n  gl_FragColor = vec4(vColor, 1.0);\n#endif\n}\n","pointRenderer.vert":"#include <util/slice.glsl>\n#include <util/vsPrecision.glsl>\n\nattribute vec3 aPosition;\nattribute vec3 aColor;\n\nuniform mat4 uModelViewMatrix;\nuniform mat4 uProjectionMatrix;\nuniform vec2 uScreenMinMaxSize;\nuniform vec2 uPointScale;\nuniform vec3 uClipMin;\nuniform vec3 uClipMax;\n\n#ifdef DEPTH_PASS\nuniform vec2 nearFar;\n\nvarying float depth;\n#else\nvarying vec3 vColor;\n#endif\n\nvoid main(void) {\n\n  // Move clipped points outside of clipspace\n  if (aPosition.x < uClipMin.x || aPosition.y < uClipMin.y || aPosition.z < uClipMin.z ||\n      aPosition.x > uClipMax.x || aPosition.y > uClipMax.y || aPosition.z > uClipMax.z) {\n    gl_Position = vec4(0.0,0.0,0.0,2.0);\n    gl_PointSize = 0.0;\n    return;\n  }\n\n  if (rejectBySlice(aPosition)) {\n    gl_Position = vec4(0.0,0.0,0.0,2.0);\n    gl_PointSize = 0.0;\n    return;\n  }\n\n  // Position in camera space\n  vec4 camera = uModelViewMatrix * vec4(aPosition, 1.0);\n\n  float pointSize = uPointScale.x;\n  vec4 position = uProjectionMatrix * camera;\n\n  // Calculate Size\n#ifdef DRAW_SCREEN_SIZE\n    float clampedScreenSize = pointSize;\n#else\n    float pointRadius = 0.5 * pointSize;\n    vec4 cameraOffset = camera + vec4(0.0, pointRadius, 0.0, 0.0);\n    vec4 positionOffset = uProjectionMatrix * cameraOffset;\n    float radius = abs(positionOffset.y - position.y);\n\n    float viewHeight = uPointScale.y;\n\n    // screen diameter = (2 * r / w) * (h / 2)\n    float screenPointSize = (radius / position.w) * viewHeight;\n    float clampedScreenSize = clamp(screenPointSize, uScreenMinMaxSize.x, uScreenMinMaxSize.y);\n\n    // Shift towards camera, to move rendered point out of terrain i.e. to\n    // the camera-facing end of the virtual point when considering it as a\n    // 3D sphere.\n    camera.xyz -= normalize(camera.xyz) * pointRadius * clampedScreenSize / screenPointSize;\n    position = uProjectionMatrix * camera;\n#endif\n\n  gl_PointSize = clampedScreenSize;\n  gl_Position = position;\n\n#ifdef DEPTH_PASS\n  depth = (-camera.z - nearFar[0]) / (nearFar[1] - nearFar[0]);\n#else\n  vColor = aColor;\n#endif\n}\n"},renderer:{highlight:{"apply.frag":"#include <util/fsPrecision.glsl>\n\n// ===============================================================================\n// Merging blurred outlines with source image, advanced version\n\n// Defines:\n// GRID_OPTIMIZATION (set or !set)\n// GRID_DEBUG (set or !set)\n// ===============================================================================\n\nuniform sampler2D tex;\nuniform sampler2D origin;\n\nuniform vec4 color;\nuniform float outlineSize;\nuniform float blurSize;\nuniform vec4 opacities; // [outline, outlineOccluded, fill, fillOccluded]\n\nvarying vec2 uv;\n\nvoid main() {\n  #if defined(GRID_OPTIMIZATION) && defined(GRID_DEBUG)\n    gl_FragColor = vec4(uv, 0.0, 1.0);\n  #else\n    // Read the highlight intensity from the blurred highlight image\n    vec4 blurredHighlightValue = texture2D(tex, uv);\n    float highlightIntensity = blurredHighlightValue.a;\n\n    // Discard all pixels which are not affected by highlight\n    if (highlightIntensity == 0.0) {\n      discard;\n    }\n\n    vec4 origin_color = texture2D(origin, uv);\n\n    float outlineIntensity;\n    float fillIntensity;\n\n    // if occluded\n    if (blurredHighlightValue.g > blurredHighlightValue.b) {\n      outlineIntensity = color.w * opacities[1];\n      fillIntensity = color.w * opacities[3];\n    }\n    // if unoccluded\n    else {\n      outlineIntensity = color.w * opacities[0];\n      fillIntensity = color.w * opacities[2];\n    }\n\n    float inner = 1.0 - outlineSize / 9.0;\n    float outer = 1.0 - (outlineSize + blurSize) / 9.0;\n\n    float outlineFactor = smoothstep(outer, inner, highlightIntensity);\n    //float fillFactor = smoothstep(0.6, 0.72, highlightIntensity);\n    float fillFactor = any(notEqual(origin_color, vec4(0.0, 0.0, 0.0, 0.0))) ? 1.0 : 0.0;\n    float intensity = outlineIntensity * outlineFactor * (1.0 - fillFactor) + fillIntensity * fillFactor;\n\n    // Blending equation: gl.blendFunc(gl.SRC_ALPHA, gl.ONE_MINUS_SRC_ALPHA);\n    // I.e., color should not be premultiplied with alpha\n    gl_FragColor = vec4(color.xyz, intensity);\n  #endif\n}\n","apply.vert":"#include <util/vsPrecision.glsl>\n\nattribute vec2 position;\nvarying vec2 uv;\n\n#ifdef GRID_OPTIMIZATION\n  attribute vec2 uv0;\n  uniform sampler2D coverageTex;\n#endif\n\nvoid main() {\n  #ifdef GRID_OPTIMIZATION\n    #ifdef GRID_DEBUG\n      vec4 cov = texture2D(coverageTex, uv0);\n      // if no highlight pixel set in this block,\n      // or all pixels set, hide block\n      if (cov.r == 0.0 || cov.g == 1.0 || cov.b == 1.0) {\n        gl_Position = vec4(0.0);\n        return;\n      }\n      gl_Position = vec4(position, .0, 1.0);\n      uv = uv0;\n      return;\n    #else\n      vec4 cov = texture2D(coverageTex, uv0);\n      // if no highlight pixel set in this block, hide block\n      if (cov.r == 0.0) {\n        gl_Position = vec4(0.0);\n        return;\n      }\n    #endif\n  #endif\n\n  gl_Position = vec4(position, .0, 1.0);\n  uv = position.xy * .5 + vec2(.5);\n}\n","blur.frag":"#include <util/fsPrecision.glsl>\n\n// ===============================================================================\n// Gaussian blur with linear sampling. Supports different number of samples, but\n// only 5 samples have proper weights. Uses linear texture interpolation to reduce\n// the number of samples taken.\n\n// Defines:\n// GRID_OPTIMIZATION (set or !set)\n// GAUSSIAN_SAMPLES (3,5,7)\n\n// This technique requires linear filtering on source texture\n// http://rastergrid.com/blog/2010/09/efficient-gaussian-blur-with-linear-sampling/\n// ===============================================================================\n\nuniform sampler2D tex;\n\n#ifdef GRID_OPTIMIZATION\n  uniform vec2 blurSize;\n  varying vec3 blurCoordinate;\n#else\n  varying vec2 blurCoordinates[GAUSSIAN_SAMPLES];\n#endif\n\nvoid main() {\n  #ifdef GRID_OPTIMIZATION\n    vec2 uv = blurCoordinate.xy;\n    vec4 center = texture2D(tex, uv);\n\n    // do not blur if no pixel or all pixels in neighborhood are set\n    if (blurCoordinate.z == 1.0) {\n      gl_FragColor = center;\n    }\n    else {\n      vec4 sum = vec4(0.0);\n\n      #if GAUSSIAN_SAMPLES == 3\n        // not proper gaussian weights\n        sum += center * 0.204164;\n        sum += texture2D(tex, uv + blurSize * 1.407333) * 0.304005;\n        sum += texture2D(tex, uv - blurSize * 1.407333) * 0.304005;\n      #elif GAUSSIAN_SAMPLES == 5\n        sum += center * 0.204164;\n        sum += texture2D(tex, uv + blurSize * 1.407333) * 0.304005;\n        sum += texture2D(tex, uv - blurSize * 1.407333) * 0.304005;\n        sum += texture2D(tex, uv + blurSize * 3.294215) * 0.093913;\n        sum += texture2D(tex, uv - blurSize * 3.294215) * 0.093913;\n      #elif GAUSSIAN_SAMPLES == 7\n        // not proper gaussian weights\n        sum += center * 0.204164;\n        sum += texture2D(tex, uv + blurSize * 1.407333) * 0.304005;\n        sum += texture2D(tex, uv - blurSize * 1.407333) * 0.304005;\n        sum += texture2D(tex, uv + blurSize * 3.294215) * 0.093913;\n        sum += texture2D(tex, uv - blurSize * 3.294215) * 0.093913;\n        sum += texture2D(tex, uv + blurSize * 5.1) * 0.03;\n        sum += texture2D(tex, uv - blurSize * 5.1) * 0.03;\n      #elif GAUSSIAN_SAMPLES == 9\n        // not proper gaussian weights\n        sum += center * 0.154164;\n        sum += texture2D(tex, uv + blurSize * 1.5) * 0.204005;\n        sum += texture2D(tex, uv - blurSize * 1.5) * 0.204005;\n        sum += texture2D(tex, uv + blurSize * 3.5) * 0.123913;\n        sum += texture2D(tex, uv - blurSize * 3.5) * 0.123913;\n        sum += texture2D(tex, uv + blurSize * 5.5) * 0.123913;\n        sum += texture2D(tex, uv - blurSize * 5.5) * 0.123913;\n        sum += texture2D(tex, uv + blurSize * 7.5) * 0.05;\n        sum += texture2D(tex, uv - blurSize * 7.5) * 0.05;\n      #endif\n\n      gl_FragColor = sum;\n    }\n  #else\n    vec4 sum = vec4(0.0);\n\n    #if GAUSSIAN_SAMPLES == 3\n      // not proper gaussian weights\n      sum += texture2D(tex, blurCoordinates[0]) * 0.204164;\n      sum += texture2D(tex, blurCoordinates[1]) * 0.304005;\n      sum += texture2D(tex, blurCoordinates[2]) * 0.304005;\n    #elif GAUSSIAN_SAMPLES == 5\n      sum += texture2D(tex, blurCoordinates[0]) * 0.204164;\n      sum += texture2D(tex, blurCoordinates[1]) * 0.304005;\n      sum += texture2D(tex, blurCoordinates[2]) * 0.304005;\n      sum += texture2D(tex, blurCoordinates[3]) * 0.093913;\n      sum += texture2D(tex, blurCoordinates[4]) * 0.093913;\n    #elif GAUSSIAN_SAMPLES == 7\n      // not proper gaussian weights\n      sum += texture2D(tex, blurCoordinates[0]) * 0.204164;\n      sum += texture2D(tex, blurCoordinates[1]) * 0.304005;\n      sum += texture2D(tex, blurCoordinates[2]) * 0.304005;\n      sum += texture2D(tex, blurCoordinates[3]) * 0.093913;\n      sum += texture2D(tex, blurCoordinates[4]) * 0.093913;\n      sum += texture2D(tex, blurCoordinates[5]) * 0.03;\n      sum += texture2D(tex, blurCoordinates[6]) * 0.03;\n    #elif GAUSSIAN_SAMPLES == 9\n      // not proper gaussian weights\n      sum += texture2D(tex, blurCoordinates[0]) * 0.154164;\n      sum += texture2D(tex, blurCoordinates[1]) * 0.204005;\n      sum += texture2D(tex, blurCoordinates[2]) * 0.204005;\n      sum += texture2D(tex, blurCoordinates[3]) * 0.123913;\n      sum += texture2D(tex, blurCoordinates[4]) * 0.123913;\n      sum += texture2D(tex, blurCoordinates[5]) * 0.09;\n      sum += texture2D(tex, blurCoordinates[6]) * 0.09;\n      sum += texture2D(tex, blurCoordinates[7]) * 0.05;\n      sum += texture2D(tex, blurCoordinates[8]) * 0.05;\n    #endif\n\n    gl_FragColor = sum;\n  #endif\n}\n","blur.vert":"#include <util/vsPrecision.glsl>\n\nattribute vec2 position;\nattribute vec2 uv0;\n\n#ifdef GRID_OPTIMIZATION\n  uniform sampler2D coverageTex;\n  varying vec3 blurCoordinate;\n#else\n  uniform vec2 blurSize;\n  varying vec2 blurCoordinates[GAUSSIAN_SAMPLES];\n#endif\n\nvoid main() {\n  gl_Position = vec4(position, 0.0, 1.0);\n\n  #ifdef GRID_OPTIMIZATION\n    // sample the coverage texture at the block center\n    // and if no coverage detected, create degenerate triangle\n    vec4 cov = texture2D(coverageTex, uv0);\n    if (cov.r == 0.0) {\n      gl_Position = vec4(0.0);\n    }\n\n    // create texture coordinate for blur center\n    // encode information about fully inside block in z coordinate\n    blurCoordinate = vec3(gl_Position.xy * .5 + vec2(.5), max(cov.g, cov.b));\n  #else\n    vec2 uv = position.xy * .5 + vec2(.5);\n\n    #if GAUSSIAN_SAMPLES == 3\n      // not proper gaussian weights\n      blurCoordinates[0] = uv;\n      blurCoordinates[1] = uv + blurSize * 1.407333;\n      blurCoordinates[2] = uv - blurSize * 1.407333;\n    #elif GAUSSIAN_SAMPLES == 5\n      blurCoordinates[0] = uv;\n      blurCoordinates[1] = uv + blurSize * 1.407333;\n      blurCoordinates[2] = uv - blurSize * 1.407333;\n      blurCoordinates[3] = uv + blurSize * 3.294215;\n      blurCoordinates[4] = uv - blurSize * 3.294215;\n    #elif GAUSSIAN_SAMPLES == 7\n      // not proper gaussian weights\n      blurCoordinates[0] = uv;\n      blurCoordinates[1] = uv + blurSize * 1.407333;\n      blurCoordinates[2] = uv - blurSize * 1.407333;\n      blurCoordinates[3] = uv + blurSize * 3.294215;\n      blurCoordinates[4] = uv - blurSize * 3.294215;\n      blurCoordinates[5] = uv + blurSize * 5.1;\n      blurCoordinates[6] = uv - blurSize * 5.1;\n    #elif GAUSSIAN_SAMPLES == 9\n      // not proper gaussian weights\n      blurCoordinates[0] = uv;\n      blurCoordinates[1] = uv + blurSize * 1.407333;\n      blurCoordinates[2] = uv - blurSize * 1.407333;\n      blurCoordinates[3] = uv + blurSize * 3.294215;\n      blurCoordinates[4] = uv - blurSize * 3.294215;\n      blurCoordinates[5] = uv + blurSize * 5.1;\n      blurCoordinates[6] = uv - blurSize * 5.1;\n      blurCoordinates[7] = uv + blurSize * 7.1;\n      blurCoordinates[8] = uv - blurSize * 7.1;\n    #endif\n  #endif\n}\n","downsample.frag":"#include <util/fsPrecision.glsl>\n\n// ===============================================================================\n// Smartly downsamples a texture, halfing its resolution. This allows for a square\n// screen region to check if none, any or all pixels were set.\n\n// The red channel is always ceiled after interpolating the 4 merged pixels.\n// This allows to evaluate:\n// any(pixels.red != 0.0) as red == 1.0\n// none(pixels.red != 0.0) as red == 0.0\n\n// The green and blue channels are set to floor(max(green, blue)).\n// This allows to evaluate:\n// all(pixels.green || pixels.blue) as green == 1.0\n// ===============================================================================\n\nuniform sampler2D tex;\nuniform vec2 invFramebufferDim;\n\nvoid main() {\n  vec2 coord = gl_FragCoord.xy * invFramebufferDim;\n  vec4 value = texture2D(tex, coord);\n  float mx = floor(max(value.g, value.b));\n  gl_FragColor = vec4(ceil(value.r), mx, mx, 1.0);\n}\n","downsample.vert":"#include <util/vsPrecision.glsl>\n\nattribute vec2 position;\n\nvoid main() {\n  gl_Position = vec4(vec2(1.0) - position * 2.0, .0, 1.0);\n}\n"},laserLine:{"laserLine.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/depth.glsl>\n\n//--------------------------------------------------------------------------\n// Uniforms\n//--------------------------------------------------------------------------\n\nuniform sampler2D depthMap;\n\nuniform vec2 nearFar;\nuniform vec4 projInfo;\nuniform vec2 zScale;\nuniform float maxPixelDistance;\n\n// focus plane in camera space\nuniform vec4 focusPlane;\n\n// focus sphere in camera space\nuniform vec4 focusSphere;\n\n// segment plane in camera space\nuniform vec4 segmentPlane;\n\n// line segment\nuniform vec3 segmentStart;\nuniform vec3 segmentEnd;\n\n// styling\nuniform vec3 glowColor;\nuniform float glowWidth;\nuniform vec3 innerColor;\nuniform float innerWidth;\nuniform float globalAlpha;\n\n//--------------------------------------------------------------------------\n// Inputs\n//--------------------------------------------------------------------------\n\nvarying vec2 uv;\n\n//--------------------------------------------------------------------------\n// Defines\n//--------------------------------------------------------------------------\n\n#define INFINITY 100000.0\n\n// reconstruct position in view space\nvec3 reconstructPosition(vec2 fragCoord, float depth) {\n  return vec3((fragCoord * projInfo.xy + projInfo.zw) * (zScale.x * depth + zScale.y), depth);\n}\n\nfloat planeDistancePixels(vec4 plane, vec3 pos) {\n  // compute distance to plane\n  float dist = dot(plane.xyz, pos) + plane.w;\n  // compute derivative of distance function with respect to pixels\n  float width = fwidth(dist);\n  // normalize distance by the derivative to get a measurement with respect to pixels\n  // the clamping is used to prevent excessive artifacts along depth discontinuities\n  dist /= min(width, maxPixelDistance);\n  return abs(dist);\n}\n\nfloat sphereDistancePixels(vec4 sphere, vec3 pos) {\n  // compute distance to sphere\n  float dist = distance(sphere.xyz, pos) - sphere.w;\n  // compute derivative of distance function with respect to pixels\n  float width = fwidth(dist);\n  // normalize distance by the derivative to get a measurement with respect to pixels\n  // the clamping is used to prevent excessive artifacts along depth discontinuities\n  dist /= min(width, maxPixelDistance);\n  return abs(dist);\n}\n\nvec4 blendPremultiplied(vec4 source, vec4 dest) {\n  float oneMinusSourceAlpha = 1.0 - source.a;\n\n  return vec4(\n    source.rgb + dest.rgb * oneMinusSourceAlpha,\n    source.a + dest.a * oneMinusSourceAlpha\n  );\n}\n\nvec4 premultipliedColor(vec3 rgb, float alpha) {\n  return vec4(rgb * alpha, alpha);\n}\n\n// computes laser line color based on distance in pixels\nvec4 laserLineProfile(float dist) {\n  if (dist > glowWidth) {\n    return vec4(0.0);\n  }\n\n  float innerAlpha = (1.0 - smoothstep(0.0, innerWidth, dist));\n  float glowAlpha = pow(max(0.0, 1.0 - dist / glowWidth), 8.0);\n\n  return blendPremultiplied(\n    premultipliedColor(innerColor, innerAlpha),\n    premultipliedColor(glowColor, glowAlpha)\n  );\n}\n\nvoid main() {\n  // do not draw laserline on background\n  float depth = linearDepth(depthMap, uv, nearFar);\n  if (-depth == nearFar[0]) {\n    discard;\n  }\n\n  // reconstruct position in view space\n  vec3 pos = reconstructPosition(gl_FragCoord.xy, depth);\n\n  // empirical hack to fade out laser line in problematic areas:\n  // the derivatives to normalize the distance function are valid inside smooth surfaces,\n  // but break down at depth discontinuities (e.g. edges). We fade out the laser lines in\n  // areas where depth valus have large variations in order to avoid this problem.\n  float ddepth = fwidth(depth);\n  float depthDiscontinuityAlpha = 1.0 - smoothstep(0.0, 0.01, -ddepth / depth);\n\n  // reconstruct normal using derivatives\n  vec3 normal = normalize(cross(dFdx(pos), dFdy(pos)));\n\n  // distance to focus plane\n  float focusPlaneDistance = planeDistancePixels(focusPlane, pos);\n\n  // distance to focus sphere\n  float focusSphereDistance = sphereDistancePixels(focusSphere, pos);\n\n  // distance to segment plane\n  float segmentDistance = INFINITY;\n  float segmentLength = length(segmentEnd - segmentStart);\n  vec3 segmentDir = (segmentEnd - segmentStart) / segmentLength;\n  float t = dot(segmentDir, pos - segmentStart);\n\n  if (segmentLength > 0.0 && t >= 0.0 && t <= segmentLength) {\n    segmentDistance = planeDistancePixels(segmentPlane, pos);\n  }\n\n  // evaluate color profile for both planes and the sphere\n  vec4 focusPlaneColor = laserLineProfile(focusPlaneDistance);\n  vec4 focusSphereColor = laserLineProfile(focusSphereDistance);\n  vec4 segmentColor = laserLineProfile(segmentDistance);\n\n  // empirical hack to fade out laser line when planes are nearly parallel\n  float focusPlaneAlpha = 1.0 - smoothstep(0.995, 0.999, abs(dot(normal, focusPlane.xyz)));\n  float focusSphereAlpha = 1.0 - smoothstep(0.995, 0.999, abs(dot(normal, normalize(pos - focusSphere.xyz))));\n  float segmentAlpha = 1.0 - smoothstep(0.995, 0.999, abs(dot(normal, segmentPlane.xyz)));\n\n  // combine colors\n  vec4 color = max(\n    focusPlaneColor * focusPlaneAlpha,\n    max(\n      focusSphereColor * focusSphereAlpha,\n      segmentColor * segmentAlpha\n    )\n  );\n\n  gl_FragColor = color * globalAlpha * depthDiscontinuityAlpha;\n}\n"},offscreen:{"composite.frag":"#include <util/fsPrecision.glsl>\n\nuniform sampler2D tex;\n\nvarying vec2 vtc;\n\nvoid main() {\n  gl_FragColor = texture2D(tex, vtc);\n}\n","compositeOccluded.frag":"#include <util/fsPrecision.glsl>\n\nuniform sampler2D occludedColorMap;\nuniform float opacity;\n\nvarying vec2 vtc;\n\nvoid main() {\n  vec4 occludedColor = texture2D(occludedColorMap, vtc);\n  gl_FragColor = occludedColor * opacity;\n}\n","compositeTransparentToHUDVisibility.frag":"#include <util/fsPrecision.glsl>\n\nuniform sampler2D tex;\n\nvarying vec2 vtc;\n\nvoid main() {\n  gl_FragColor = vec4(1.0 - texture2D(tex, vtc).a);\n}\n","offscreen.vert":"#include <util/vsPrecision.glsl>\n\nattribute vec2 position;\nvarying vec2 vtc;\n\nvoid main(void) {\n  gl_Position = vec4(position.xy, 0.0, 1.0);\n  vtc = position.xy * 0.5 + 0.5;\n}\n"},ssao:{"blur.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/depth.glsl>\n\n#ifndef RADIUS\n#define RADIUS 4\n#endif\n\nuniform sampler2D normalMap;\nuniform sampler2D depthMap;\nuniform sampler2D tex;\n\nuniform vec2 blurSize;\n\nuniform float g_BlurFalloff;\nuniform float projScale;\n\nuniform vec2 nearFar;\n//set z scaling, used to prevent division in ortho mode\nuniform vec2 zScale;\n\nvarying vec2 uv;\n\nfloat BlurFunction(vec2 uv, float r, float center_d, inout float w_total, float sharpness) {\n  float c = texture2D(tex, uv).r;\n  float d = linearDepth(depthMap, uv, nearFar);\n\n  float ddiff = d - center_d;\n\n  float w = exp(-r*r*g_BlurFalloff - ddiff*ddiff*sharpness);\n\n  w_total += w;\n\n  return w*c;\n}\n\nvoid main(void) {\n  float b = 0.0;\n  float w_total = 0.0;\n\n  float center_d = linearDepth(depthMap, uv, nearFar);\n\n  float sharpness = -0.05 * projScale/(center_d*zScale.x+zScale.y);\n  for (int r = -RADIUS; r <= RADIUS; ++r) {\n    float rf = float(r);\n    vec2 uvOffset = uv + rf*blurSize;\n    b += BlurFunction(uvOffset, rf, center_d, w_total, sharpness);\n  }\n\n  gl_FragColor = vec4(b/w_total);\n}\n",
"ssao.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/depth.glsl>\n\n#ifndef SAMPLES\n#define SAMPLES 4\n#endif\n\nuniform mat4 projMatrixInv;\n\nuniform sampler2D normalMap;\nuniform sampler2D depthMap;\n\nuniform float intensity;\n\nuniform float projScale;\nuniform float radius;\nuniform vec2 nearFar;\nuniform vec4 projInfo;\nuniform vec2 screenDimensions;\n\n//noise texture lookup could be replaced with hash function if WebGL gets XOR functionality\nuniform vec3 pSphere[SAMPLES]; //tap position\nuniform vec2 rnmScale;\nuniform sampler2D rnm; //noise texture\n\n//set z scaling, used to prevent division in ortho mode\nuniform vec2 zScale;\n\nvarying vec2  uv;\nvarying vec4  camPos;\n\nfloat fallOffFunction(float vv, float vn, float bias) {\n  float radius2 = radius * radius;\n\n  // A: From the HPG12 paper\n  // Note large epsilon to avoid overdarkening within cracks\n  // return float(vv < radius2) * max((vn - bias) / (epsilon + vv), 0.0) * radius2 * 0.6;\n\n  // B: Smoother transition to zero (lowers contrast, smoothing out corners). [Recommended]\n  float f = max(radius2 - vv, 0.0); return f * f * f * max(vn-bias, 0.0);\n\n  // C: Medium contrast (which looks better at high radii), no division.  Note that the\n  // contribution still falls off with radius^2, but we've adjusted the rate in a way that is\n  // more computationally efficient and happens to be aesthetically pleasing.\n  // return 4.0 * max(1.0 - vv * invRadius2, 0.0) * max(vn - bias, 0.0);\n\n  // D: Low contrast, no division operation\n  // return 2.0 * float(vv < radius * radius) * max(vn - bias, 0.0);\n}\n\n\n/** Compute the occlusion due to sample point \\a Q about camera-space point \\a C with unit normal \\a n_C */\nfloat aoValueFromPositionsAndNormal(vec3 C, vec3 n_C, vec3 Q) {\n  vec3 v = Q - C;\n  float vv = dot(v, v);\n  float vn = dot(normalize(v), n_C);\n  return fallOffFunction(vv, vn, 0.1);\n}\n\n\n/**\n * Reconstruct camera-space P.xyz from screen-space S = (x, y) in\n * pixels and camera-space z < 0.  Assumes that the upper-left pixel center\n * is at (0.5, 0.5) [but that need not be the location at which the sample tap\n * was placed!]\n *\n * Costs 3 MADD.  Error is on the order of 10^3 at the far plane, partly due to z precision.\n */\nvec3 reconstructCSPosition(vec2 S, float z) {\n  return vec3(( (S.xy) * projInfo.xy + projInfo.zw)*(z*zScale.x+zScale.y), z);\n}\n\nvoid main(void) {\n  //Hash function used in the HPG12 AlchemyAO paper\n  //Not supported in WebGL -> using texture lookup as in old SSAO shader instead\n  //ivec2 ssC = ivec2(gl_FragCoord.xy);\n  //float randomPatternRotationAngle = float((3 * ssC.x ^ ssC.y + ssC.x * ssC.y) * 10);\n  vec3 fres = normalize((texture2D(rnm, uv * rnmScale).xyz * 2.0) - vec3(1.0));\n\n  float currentPixelDepth = linearDepth(depthMap, uv, nearFar);\n\n  if (-currentPixelDepth>nearFar.y || -currentPixelDepth<nearFar.x) {\n    gl_FragColor = vec4(0.0);\n    return;\n  }\n\n  vec3 currentPixelPos = reconstructCSPosition(gl_FragCoord.xy,currentPixelDepth);\n\n  // get the normal of current fragment\n  vec4 norm4 = texture2D(normalMap, uv);\n  vec3 norm = vec3(-1.0) + 2.0 * norm4.xyz;\n  bool isTerrain = norm4.w<0.5;\n\n  float sum = .0;\n\n  vec4 occluderFragment;\n  vec3 ray;\n\n  vec3 tapPixelPos;\n\n  // note: the factor 2.0 should not be necessary, but makes ssao much nicer.\n  // bug or deviation from CE somewhere else?\n  float ps = projScale/(2.0*currentPixelPos.z*zScale.x+zScale.y);\n\n  for(int i = 0; i < SAMPLES; ++i) {\n    // get a vector (randomized inside of a sphere with radius 1.0) from a texture and reflect it\n    //float ssR;\n    //vec2 unitOffset = tapLocation(i, randomPatternRotationAngle, ssR);\n    // get the depth of the occluder fragment\n    //vec2 offset = vec2(-unitOffset*radius*ssR*ps);\n\n    vec2 unitOffset = reflect(pSphere[i], fres).xy;\n    vec2 offset = vec2(-unitOffset*radius*ps);\n\n    //don't use current or very nearby samples\n    if ( abs(offset.x)<2.0 || abs(offset.y)<2.0) continue;\n\n    vec2 tc = vec2(gl_FragCoord.xy + offset);\n    if (tc.x < 0.0 || tc.y < 0.0 || tc.x > screenDimensions.x || tc.y > screenDimensions.y) continue;\n    vec2 tcTap = tc/screenDimensions;\n    float occluderFragmentDepth = linearDepth(depthMap, tcTap, nearFar);\n\n    if (isTerrain) {\n      bool isTerrainTap = texture2D(normalMap, tcTap).w<0.5;\n      if (isTerrainTap) {\n        continue;\n      }\n    }\n\n    tapPixelPos = reconstructCSPosition(tc, occluderFragmentDepth);\n\n    sum+= aoValueFromPositionsAndNormal(currentPixelPos, norm, tapPixelPos);\n  }\n\n  // output the result\n\n  float A = max(1.0-sum*intensity/float(SAMPLES),0.0);\n\n  // Anti-tone map to reduce contrast and drag dark region farther\n  // (x^0.2 + 1.2 * x^4)/2.2\n  A = (pow(A, 0.2) + 1.2 * A*A*A*A) / 2.2;\n\n  //gl_FragColor = vec4(norm/2.0+0.5, 1.0);\n  //gl_FragColor = vec4(-currentPixelDepth/1000.0);\n  //gl_FragColor = vec4(tapPixelPos.x/100.0);\n  gl_FragColor = vec4(A);\n}\n"}},terrainRenderer:{"colorPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/sceneLighting.glsl>\n#include <util/screenSizePerspective.glsl>\n#include <util/shadow.glsl>\n#include <util/slice.glsl>\n#include <terrainRenderer/overlay.glsl>\n\nuniform vec3 lightDirection;\nuniform vec3 viewDirection;\nuniform sampler2D depthTex;\nuniform int shadowMapNum;\nuniform vec4 shadowMapDistance;\nuniform mat4 shadowMapMatrix[4];\nuniform float depthHalfPixelSz;\nuniform sampler2D ssaoTex;\nuniform vec4 viewportPixelSz;\nuniform sampler2D tex;\nuniform float opacity;\n\n#if defined(WIREFRAME_TEXTURE) || defined(TILE_BORDERS)\nstruct WireframeSettings {\n  float width;\n  float falloff;\n  float subdivision;\n  vec4 color;\n  float wireOpacity;\n  float surfaceOpacity;\n};\n\nuniform WireframeSettings wireframe;\n#endif\n\nvarying vec3 vnormal;\nvarying vec3 vpos;\nvarying vec2 vtc;\n\n#if defined(WIREFRAME_TEXTURE) || defined(TILE_BORDERS)\nvarying vec2 vuv;\n#endif\n\n#ifdef ATMOSPHERE\nvarying vec3 wpos;\nvarying vec3 wview;\nvarying vec3 wnormal;\nvarying vec3 wlight;\n#endif\n\n#ifdef SCREEN_SIZE_PERSPECTIVE /* debug only */\nuniform vec4 screenSizePerspective;\n\nvarying float screenSizeDistanceToCamera;\nvarying float screenSizeCosAngle;\n#endif\n\nconst vec3 ambient = vec3(0.2,0.2,0.2);\nconst vec3 diffuse = vec3(0.8,0.8,0.8);\nconst float diffuseHardness = 2.5;\nconst float sliceOpacity = 0.2;\n\n#ifdef OVERLAY\nuniform sampler2D overlay0Tex;\nuniform sampler2D overlay1Tex;\nuniform float overlayOpacity;\nvarying vec4 vtcOverlay;\n#endif\n\n#ifdef RECEIVE_SHADOWS\nvarying float linearDepth;\n#endif\n\nfloat lum(vec3 c) {\n  float max = max(max(c.r, c.g), c.b);\n  float min = min(min(c.r, c.g), c.b);\n  return (min + max) * 0.5;\n}\n\n#ifdef ATMOSPHERE\nvec3 atmosphere(vec3 lightPos, vec3 normal, vec3 view) {\n  vec3 surfaceColor   = vec3(0.0);\n  vec3 fuzzySpecColor = vec3(1.0);\n  vec3 subColor       = vec3(0.0);\n  float rollOff       = 1.0;\n\n  vec3 Ln = normalize(lightPos);\n  vec3 Nn = normalize(normal);\n  vec3 Hn = normalize(view + Ln);\n\n  float ldn = dot(Ln, Nn);\n  float diffComp = max(0.0, ldn);\n  float vdn = 1.0 - dot(view, Nn);\n  float ndv = dot(view, Ln);\n\n  vec3 diffContrib = surfaceColor * diffComp;\n  float subLamb = max(0.0, smoothstep(-rollOff, 1.0, ldn) - smoothstep(0.0, 1.0, ldn));\n\n  vec3 subContrib = subLamb * subColor;\n  vec3 vecColor = vec3(vdn);\n\n  vec3 diffuseContrib = (subContrib + diffContrib);\n  vec3 specularContrib = (vecColor * fuzzySpecColor);\n\n  return (diffContrib + specularContrib) * rollOff;\n}\n#endif\n\nvoid main() {\n  vec3 a = ambient;\n\n  float shadow = 0.0;\n#ifdef RECEIVE_SHADOWS\n  shadow = evalShadow(vpos, linearDepth, depthTex, shadowMapNum, shadowMapDistance, shadowMapMatrix, depthHalfPixelSz);\n#endif\n  float vndl = dot(normalize(vnormal), lightDirection);\n  float k = smoothstep(0.0, 1.0, clamp(vndl*diffuseHardness, 0.0, 1.0));\n  vec3 d = (1.0 - shadow/1.8) * diffuse * k;\n\n  float ssao = viewportPixelSz.w < .0 ? 1.0 : texture2D(ssaoTex, (gl_FragCoord.xy - viewportPixelSz.xy) * viewportPixelSz.zw).a;\n\n  vec4 tileColor = texture2D(tex, vtc) * opacity;\n\n#ifdef OVERLAY\n  vec4 overlayColor = getOverlayColor(overlay0Tex, overlay1Tex, vtcOverlay, overlayOpacity);\n\n  // tileColor and overlayTexCols have pre-multiplied alpha\n  tileColor = tileColor * (1.0 - overlayColor.a) + overlayColor;\n#endif\n\n  if (rejectBySlice(vpos)) {\n    tileColor *= sliceOpacity;\n  }\n\n  vec3 atm = vec3(0.0);\n#ifdef ATMOSPHERE\n  float ndotl = max(0.0, min(1.0, vndl));\n  atm = atmosphere(wlight, wnormal, -viewDirection);\n  atm *= max(0.0, min(1.0, (1.0-lum(tileColor.rgb)*1.5))); //avoid atmosphere on bright base maps\n  atm *= max(0.0, min(1.0, ndotl*2.0)); // avoid atmosphere on dark side of the globe\n  atm *= tileColor.a; // premultiply with tile alpha\n#endif\n\n  vec3 albedo = atm + tileColor.rgb;\n  vec3 normal = normalize(vnormal);\n\n  // heuristic shading function used in the old terrain, now used to add ambient lighting\n  float additionalAmbientScale = smoothstep(0.0, 1.0, clamp(vndl*2.5, 0.0, 1.0));\n  vec3 additionalLight = ssao * lightingMainIntensity * additionalAmbientScale * ambientBoostFactor * lightingGlobalFactor;\n\n  gl_FragColor = vec4(evaluateSceneLighting(normal, albedo, shadow, 1.0 - ssao, additionalLight), tileColor.a);\n\n#ifdef SCREEN_SIZE_PERSPECTIVE /* debug only */\n  // This is only used for debug rendering the screenSize perspective\n\n  float perspectiveScale = screenSizePerspectiveScaleFloat(1.0, screenSizeCosAngle, screenSizeDistanceToCamera, screenSizePerspective);\n\n  if (perspectiveScale <= 0.25) {\n    gl_FragColor = mix(gl_FragColor, vec4(1.0, 0.0, 0.0, 1.0), perspectiveScale * 4.0);\n  }\n  else if (perspectiveScale <= 0.5) {\n    gl_FragColor = mix(gl_FragColor, vec4(0.0, 0.0, 1.0, 1.0), (perspectiveScale - 0.25) * 4.0);\n  }\n  else if (perspectiveScale >= 0.99) {\n    gl_FragColor = mix(gl_FragColor, vec4(0.0, 1.0, 0.0, 1.0), 0.2);\n  }\n  else {\n    gl_FragColor = mix(gl_FragColor, vec4(1.0, 0.0, 1.0, 1.0), (perspectiveScale - 0.5) * 2.0);\n  }\n\n#endif\n\n#if defined(WIREFRAME_TEXTURE) || defined(TILE_BORDERS)\n\n  vec2 vuvScaled = vuv * wireframe.subdivision;\n  vec2 vuvMod = fract(vuvScaled);\n\n  vec2 dVuv = fwidth(vuvScaled);\n  dVuv = max(vec2(0.00001), dVuv); // workaround against flickering skirts, see #10245\n\n  vec2 edgeFactors = smoothstep((wireframe.width - wireframe.falloff) * dVuv,\n                                wireframe.width * dVuv, min(vuvMod, 1.0 - vuvMod));\n\n  float edgeFactor = 1.0 - min(edgeFactors.x, edgeFactors.y);\n\n#ifdef WIREFRAME_TEXTURE\n  vec3 wireframeColor = mix(gl_FragColor.rgb, wireframe.color.rgb, edgeFactor * wireframe.color.a);\n  float wireframeAlpha = mix(wireframe.surfaceOpacity, wireframe.wireOpacity, edgeFactor);\n  gl_FragColor = vec4(wireframeColor * wireframeAlpha, wireframeAlpha * gl_FragColor.a);\n#endif\n\n\n#ifdef TILE_BORDERS\n  dVuv = fwidth(vuv);\n  edgeFactors = smoothstep((wireframe.width - wireframe.falloff) * dVuv,\n                            wireframe.width * dVuv, min(vuv, 1.0 - vuv));\n  edgeFactor = 1.0 - min(edgeFactors.x, edgeFactors.y);\n\n  gl_FragColor = mix(gl_FragColor, vec4(1.0, 0.0, 0.0, 1.0), edgeFactor);\n#endif\n\n#endif // defined(WIREFRAME_TEXTURE) || defined(TILE_BORDERS)\n\n  gl_FragColor = highlightSlice(gl_FragColor, vpos);\n}\n","colorPass.vert":"#include <util/vsPrecision.glsl>\n#include <terrainRenderer/skirts.glsl>\n\nuniform mat4 proj;\nuniform mat4 view;\nuniform vec3 origin;\nuniform vec4 texOffsetAndScale;\nuniform mat4 viewNormal;\nuniform float skirtScale;\n\nattribute vec3 position;\nattribute vec2 uv0;\n\nvarying vec3 vnormal;\nvarying vec3 vpos;\nvarying vec2 vtc;\n\n#ifdef RECEIVE_SHADOWS\nvarying float linearDepth;\n#endif\n\n#if defined(WIREFRAME_TEXTURE) || defined(TILE_BORDERS)\nvarying vec2 vuv;\n#endif\n\n#ifdef ATMOSPHERE\nuniform vec3 lightDirection;\nvarying vec3 wpos;\nvarying vec3 wview;\nvarying vec3 wnormal;\nvarying vec3 wlight;\n#endif\n\n#ifdef OVERLAY\n// these variables combine two possible overlays into one by using a vec4:\n// components x/y are x/y of overlay 0, and components z/w are x/y of overlay 1\nuniform vec4 overlayTexOffset;\nuniform vec4 overlayTexScale;\nvarying vec4 vtcOverlay;\n#endif\n\n#ifdef SCREEN_SIZE_PERSPECTIVE /* debug only */\n\nuniform vec4 screenSizePerspective;\n\nvarying float screenSizeDistanceToCamera;\nvarying float screenSizeCosAngle;\n\n#endif\n\nvoid main(void) {\n  vpos = position;\n\n#if VIEWING_MODE == VIEWING_MODE_GLOBAL\n  vnormal = normalize(vpos + origin);\n#else\n  vnormal = vec3(0.0, 0.0, 1.0); // WARNING: up-axis dependent code\n#endif\n\nvec2 uv = uv0;\nvpos = applySkirts(uv, vpos, vnormal, skirtScale);\n\n#ifdef ATMOSPHERE\n  wpos = (view * vec4(vpos, 1.0)).xyz;\n  wnormal = (viewNormal * vec4(normalize(vpos+origin), 1.0)).xyz;\n  wlight = (view  * vec4(lightDirection, 1.0)).xyz;\n#endif\n\n#if defined(WIREFRAME_TEXTURE) || defined(TILE_BORDERS)\n  vuv = uv;\n#endif\n\n#ifdef SCREEN_SIZE_PERSPECTIVE /* debug only */\n\n  vec3 viewPos = (view * vec4(vpos, 1.0)).xyz;\n\n  screenSizeDistanceToCamera = length(viewPos);\n\n  vec3 viewSpaceNormal = (viewNormal * vec4(normalize(vpos + origin), 1.0)).xyz;\n  screenSizeCosAngle = abs(viewSpaceNormal.z);\n\n#endif\n\n  gl_Position = proj * view * vec4(vpos, 1.0);\n\n#ifdef RECEIVE_SHADOWS\n  // Shadowmap's cascading index used to be based on '1.0 / gl_FragCoord.w'\n  // (i.e. the perspective interpolation of 'gl_Position.w'). Precision\n  // issues on iPad/iPhone with the 'w' component require the depth to be\n  // passed as varying to properly drive the cascading shadow map index.\n  linearDepth = gl_Position.w;\n#endif\n\n  vtc = uv * texOffsetAndScale.zw + texOffsetAndScale.xy;\n\n#ifdef OVERLAY\n  vtcOverlay = vec4(uv, uv) * overlayTexScale + overlayTexOffset;\n#endif\n}\n","depthPass.frag":"#include <util/enableExtensions.glsl>\n#include <util/fsPrecision.glsl>\n#include <util/encoding.glsl>\n#include <util/depth.glsl>\n\nvarying float depth;\nvarying vec3 vpos;\n\nvoid main() {\n#ifndef BIAS_SHADOWMAP\n  gl_FragColor = float2rgba(depth);\n#else\n  gl_FragColor = float2rgba(calcFragDepth(depth));\n#endif\n}\n","depthPass.vert":"#include <util/vsPrecision.glsl>\n#include <terrainRenderer/skirts.glsl>\n\nuniform vec3 origin;\nuniform mat4 proj;\nuniform mat4 view;\nuniform vec2 nearFar;\nuniform float skirtScale;\n\nattribute vec3 position;\nattribute vec2 uv0;\n\nvarying float depth;\nvarying vec3 vpos;\n\nvoid main(void) {\n#if VIEWING_MODE == VIEWING_MODE_GLOBAL\n  vec3 normal = normalize(position + origin);\n#else\n  vec3 normal = vec3(0.0, 0.0, 1.0);\n#endif\n\n  vec2 uv = uv0;\n  vpos = applySkirts(uv, position, normal.xyz, skirtScale);\n\n  vec4 eye = view * vec4(vpos, 1.0);\n  gl_Position = proj * eye;\n  depth = (-eye.z - nearFar[0]) / (nearFar[1] - nearFar[0]) ;\n}\n","highlightPass.frag":"#include <util/fsPrecision.glsl>\n#include <util/highlight.glsl>\n#include <terrainRenderer/overlay.glsl>\n\nuniform sampler2D overlay0Tex;\nuniform sampler2D overlay1Tex;\nuniform float overlayOpacity;\n\nuniform sampler2D depthTex;\nuniform vec4 highlightViewportPixelSz;\n\nvarying vec4 vtcOverlay;\n\nvoid main() {\n  vec4 overlayColor = getOverlayColor(overlay0Tex, overlay1Tex, vtcOverlay, overlayOpacity);\n\n  if (overlayColor.a == 0.0) {\n    // Here we have to write black, instead of discarding the fragment in order to overwrite\n    // the highlights which might have been written by skirts of other tiles.\n    // As a consequence skirts are not visible, but terrain overwrites draped highlights.\n    gl_FragColor = vec4(0.0);\n    return;\n  }\n\n  gl_FragColor = highlightData(gl_FragCoord, depthTex, highlightViewportPixelSz);\n}\n","highlightPass.vert":"#include <util/vsPrecision.glsl>\n#include <terrainRenderer/skirts.glsl>\n\nuniform vec3 origin;\nuniform mat4 proj;\nuniform mat4 view;\nuniform vec4 overlayTexScale;\nuniform vec4 overlayTexOffset;\nuniform float skirtScale;\n\nattribute vec3 position;\nattribute vec2 uv0;\n\nvarying vec3 vpos;\nvarying vec4 vtcOverlay;\n\nvoid main() {\n  #if VIEWING_MODE == VIEWING_MODE_GLOBAL\n    vec3 vnormal = normalize(position + origin);\n  #else\n    vec3 vnormal = vec3(0.0, 0.0, 1.0); // WARNING: up-axis dependent code\n  #endif\n\n  vec2 uv = uv0;\n  vpos = applySkirts(uv, position, vnormal, skirtScale);\n\n  vtcOverlay = vec4(uv, uv) * overlayTexScale + overlayTexOffset;\n\n  gl_Position = proj * view * vec4(vpos, 1.0);\n}\n","normalPass.frag":"#include <util/fsPrecision.glsl>\n\nvarying vec3 vnormal;\nvarying vec3 vpos;\n\nvoid main() {\n  vec3 normal = normalize(vnormal);\n  if (gl_FrontFacing == false) normal = -normal;\n\n#ifndef ALPHA_ZERO\n  gl_FragColor = vec4(vec3(.5) + .5 * normal, 1.0);\n#else\n  gl_FragColor = vec4(vec3(.5) + .5 * normal, 0.0);\n#endif\n}\n","normalPass.vert":"#include <util/vsPrecision.glsl>\n#include <terrainRenderer/skirts.glsl>\n\nuniform vec3 origin;\nuniform mat4 proj;\nuniform mat4 view;\nuniform mat4 viewNormal;\nuniform float skirtScale;\n\nattribute vec3 position;\nattribute vec2 uv0;\n\nvarying vec3 vnormal;\nvarying vec3 vpos;\n\nvoid main(void) {\n#if VIEWING_MODE == VIEWING_MODE_GLOBAL\n  vec4 normal = vec4(normalize(position + origin), 1.0);\n#else\n  vec4 normal = vec4(0.0, 0.0, 1.0, 1.0);\n#endif\n\n  vec2 uv = uv0;\n  vpos = applySkirts(uv, position, normal.xyz, skirtScale);\n\n  gl_Position = proj * view * vec4(vpos, 1.0);\n  vnormal = normalize((viewNormal * normal).xyz);\n}\n","overlay.glsl":"vec4 getOverlayColor(sampler2D overlay0Tex, sampler2D overlay1Tex, vec4 texCoords, float opacity) {\n  vec4 color = vec4(0.0);\n\n  // read textures outside of conditions, to avoid artifacts likely related to non-uniform flow control:\n  // - https://www.khronos.org/opengl/wiki/Sampler_(GLSL)#Non-uniform_flow_control\n  // - https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/13657\n  vec4 colorInner = texture2D(overlay0Tex, texCoords.xy);\n  vec4 colorOuter = texture2D(overlay1Tex, texCoords.zw);\n\n  if ((texCoords.x > 0.0) && (texCoords.x < 1.0) && (texCoords.y > 0.0) && (texCoords.y < 1.0)) {\n    // inner overlay texture coordinates are within bounds -> sample from inner overlay\n    color = colorInner;\n  } else if ((texCoords.z > 0.0) && (texCoords.z < 1.0) && (texCoords.w > 0.0) && (texCoords.w < 1.0)) {\n    // sample from outer overlay\n    color = colorOuter;\n  }\n\n  return color * opacity;\n}\n","skirts.glsl":'vec3 applySkirts(inout vec2 uv, vec3 vpos, vec3 vnormal, float skirtScale) {\n  float skirtLength = 0.0;\n\n  if (uv.x >= 2.0) {\n    skirtLength = uv.y * skirtScale;\n    // decode original uv-coordinates (see "encodeSkirtPos")\n    vec2 x = vec2(uv.x) - vec2(3.5, 4.5);\n    uv = clamp(vec2(1.5) - abs(x), vec2(0.0), vec2(1.0));\n  }\n\n  return vpos - vnormal * skirtLength;\n}\n'},util:{"alignPixel.glsl":"vec4 alignToPixelCenter(vec4 clipCoord, vec2 widthHeight) {\n  // From clip space to (0 : 1), bias towards right pixel edge\n  vec2 xy = vec2(.500123) + .5 * clipCoord.xy / clipCoord.w;\n\n  // Size of a pixel in range (0 : 1)\n  vec2 pixelSz = vec2(1.0) / widthHeight;\n\n  // Round to nearest pixel center\n  vec2 ij = (floor(xy * widthHeight) + vec2(0.5)) * pixelSz;\n\n  // Convert back to clip space\n  vec2 result = (ij * 2.0 - vec2(1.0)) * clipCoord.w;\n\n  return vec4(result, clipCoord.zw);\n}\n\nvec4 alignToPixelOrigin(vec4 clipCoord, vec2 widthHeight) {\n  // From clip space to (0 : 1),\n  vec2 xy = vec2(.5) + .5 * clipCoord.xy / clipCoord.w;\n\n  // Size of a pixel in range (0 : 1)\n  vec2 pixelSz = vec2(1.0) / widthHeight;\n\n  // Round to nearest pixel border, (0 : 1)\n  vec2 ij = floor((xy + .5 * pixelSz) * widthHeight) * pixelSz;\n\n  // Convert back to clip space\n  vec2 result = (ij * 2.0 - vec2(1.0)) * clipCoord.w;\n\n  return vec4(result, clipCoord.zw);\n}\n","color.glsl":"vec4 premultiplyAlpha(vec4 v) {\n  return vec4(v.rgb * v.a, v.a);\n}\n\nvec3 rgb2hsv(vec3 c) {\n  vec4 K = vec4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0);\n  vec4 p = mix(vec4(c.bg, K.wz), vec4(c.gb, K.xy), step(c.b, c.g));\n  vec4 q = mix(vec4(p.xyw, c.r), vec4(c.r, p.yzx), step(p.x, c.r));\n\n  float d = q.x - min(q.w, q.y);\n  float e = 1.0e-10;\n  return vec3(abs(q.z + (q.w - q.y) / (6.0 * d + e)), d / (q.x + e), q.x);\n}\n\nvec3 hsv2rgb(vec3 c) {\n  vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);\n  vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);\n  return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);\n}\n","depth.glsl":"#include <util/encoding.glsl>\n\n// read linear depth either from native depth texture or custom depth texture encoded in rgba\nfloat linearDepth(sampler2D depthTex, vec2 uv, vec2 nearFar) {\n  return -(rgba2float(texture2D(depthTex, uv)) * (nearFar[1] - nearFar[0]) + nearFar[0]);\n}\n\nfloat calcFragDepth(const in float depth) {\n  // calc polygon offset\n  const float SLOPE_SCALE = 2.0;\n  const float BIAS = 2.0 * .000015259;    // 1 / (2^16 - 1)\n  float m = max(abs(dFdx(depth)), abs(dFdy(depth)));\n  float result = depth + SLOPE_SCALE * m + BIAS;\n  return clamp(result, .0, .999999);\n}\n","doublePrecision.glsl":"// based on https://www.thasler.com/blog/blog/glsl-part2-emu\nvec3 dpAdd(vec3 hiA, vec3 loA, vec3 hiB, vec3 loB) {\n  vec3 t1 = hiA + hiB;\n  vec3 e = t1 - hiA;\n  vec3 t2 = ((hiB - e) + (hiA - (t1 - e))) + loA + loB;\n  return t1 + t2;\n}\n","enableExtensions.glsl":"#define EXTENSIONS_ENABLED\n#extension GL_OES_standard_derivatives : enable\n#extension GL_EXT_shader_texture_lod : enable\n","encoding.glsl":"// This is the maximum float value representable as 32bit fixed point,\n// it is rgba2float(vec4(1)) inlined.\nconst float MAX_RGBA_FLOAT =\n  255.0 / 256.0 +\n  255.0 / 256.0 / 256.0 +\n  255.0 / 256.0 / 256.0 / 256.0 +\n  255.0 / 256.0 / 256.0 / 256.0 / 256.0;\n\n// Factors to convert to fixed point, i.e. factors (256^0, 256^1, 256^2, 256^3)\nconst vec4 fixedPointFactors = vec4(1.0, 256.0, 256.0 * 256.0, 256.0 * 256.0 * 256.0);\n\nvec4 float2rgba(const float value) {\n  // Make sure value is in the domain we can represent\n  float valueInValidDomain = clamp(value, 0.0, MAX_RGBA_FLOAT);\n\n  // Decompose value in 32bit fixed point parts represented as\n  // uint8 rgba components. Decomposition uses the fractional part after multiplying\n  // by a power of 256 (this removes the bits that are represented in the previous\n  // component) and then converts the fractional part to 8bits.\n  vec4 fixedPointU8 = floor(fract(valueInValidDomain * fixedPointFactors) * 256.0);\n\n  // Convert uint8 values (from 0 to 255) to floating point representation for\n  // the shader\n  const float toU8AsFloat = 1.0 / 255.0;\n\n  return fixedPointU8 * toU8AsFloat;\n}\n\n// Factors to convert rgba back to float\nconst vec4 rgba2float_factors = vec4(\n  255.0 / (256.0),\n  255.0 / (256.0 * 256.0),\n  255.0 / (256.0 * 256.0 * 256.0),\n  255.0 / (256.0 * 256.0 * 256.0 * 256.0)\n);\n\nfloat rgba2float(vec4 rgba) {\n  // Convert components from 0->1 back to 0->255 and then\n  // add the components together with their corresponding\n  // fixed point factors, i.e. (256^1, 256^2, 256^3, 256^4)\n  return dot(rgba, rgba2float_factors);\n}\n","fsPrecision.glsl":"#ifdef GL_FRAGMENT_PRECISION_HIGH\nprecision highp float;\nprecision highp sampler2D;\n#else\nprecision mediump float;\nprecision mediump sampler2D;\n#endif\n","highlight.glsl":"vec4 highlightData(vec4 fragCoord, sampler2D depthTex, vec4 viewportPixelSize) {\n  float sceneDepth = texture2D(depthTex, (fragCoord.xy - viewportPixelSize.xy) * viewportPixelSize.zw).r;\n  if (fragCoord.z > sceneDepth + 5e-7) {\n    return vec4(1.0, 1.0, 0.0, 1.0);\n  }\n  else {\n    return vec4(1.0, 0.0, 1.0, 1.0);\n  }\n}\n",
"hud.glsl":"#include <util/screenSizePerspective.glsl>\n\nattribute vec3 position;\nattribute vec3 normal;\nattribute vec4 auxpos1;\n\nuniform mat4 proj;\n\nuniform mat4 view;\nuniform mat4 viewNormal;\n\nuniform mat4 model;\nuniform mat4 modelNormal;\n\nuniform vec4 viewport;\n\nuniform vec3 camPos;\n\nuniform float polygonOffset;\nuniform float cameraGroundRelative;\nuniform float pixelRatio;\n\nuniform float perDistancePixelRatio;\n\n#ifdef VERTICAL_OFFSET\n\n// [ screenLength, distanceFactor, minWorldLength, maxWorldLength ]\nuniform vec4 verticalOffset;\n\n#endif\n\n#ifdef SCREEN_SIZE_PERSPECTIVE\n\n// [ divisor, offset, minPixelSize, paddingPixels ]\nuniform vec4 screenSizePerspectiveAlignment;\n\n#endif\n\nuniform sampler2D hudVisibilityTexture;\n\n\n// Corresponds to cos(10 deg), used to compare against dot product of two vectors\nconst float SMALL_OFFSET_ANGLE = 0.984807753012208;\n\nstruct ProjectHUDAux {\n  vec3 posModel;\n  vec3 posView;\n  vec3 vnormal;\n\n  float distanceToCamera;\n  float absCosAngle;\n};\n\n\n/**\n  * Apply the simulated polygon offset for HUD objects that improves\n  * issues with Z-fighting.\n  *\n  * @param posView {vec3} (inout) the position in view space. Will be modified in place.\n  * @param pointGroundDistance {float} the distance from the point geometry to the ground surface.\n  * @param absCosAngle {float} the absolute cosine of the angle between the world-up at the point geometry\n  *   and the view direction.\n  *\n  * Dependencies:\n  *\n  *   Attributes:\n  *     - auxpos1: contains centerOffset and pointGroundDistance\n  *\n  *   Uniforms:\n  *     - cameraGroundRelative: indicates whether camera is above (1) or below (-1) ground.\n  *         This is used for emulated polygon offset for improved visibility of points sitting on the surface.\n  *     - polygonOffset: a constant polygon offset to bring the point closer to the viewer for\n  *         reduced flickering.\n  *     - viewport: the viewport [x, y, width, height]\n  */\nfloat applyHUDViewDependentPolygonOffset(float pointGroundDistance, float absCosAngle, inout vec3 posView) {\n  float pointGroundSign = sign(pointGroundDistance);\n\n  if (pointGroundSign == 0.0) {\n    pointGroundSign = cameraGroundRelative;\n  }\n\n  // cameraGroundRelative is -1 if camera is below ground, 1 if above ground\n  // groundRelative is 1 if both camera and symbol are on the same side of the ground, -1 otherwise\n  float groundRelative = cameraGroundRelative * pointGroundSign;\n\n  // view angle dependent part of polygon offset emulation\n  // we take the absolute value because the sign that is dropped is\n  // instead introduced using the ground-relative position of the symbol and the camera\n  if (polygonOffset > .0) {\n    float cosAlpha = clamp(absCosAngle, 0.01, 1.0);\n\n    float tanAlpha = sqrt(1.0 - cosAlpha * cosAlpha) / cosAlpha;\n    float factor = (1.0 - tanAlpha / viewport[2]);\n\n    // same side of the terrain\n    if (groundRelative > 0.0) {\n      posView *= factor;\n    }\n    // opposite sides of the terrain\n    else {\n      posView /= factor;\n    }\n  }\n\n  return groundRelative;\n}\n\n/**\n * Apply small vertical offset along world normal to reduce flickering. The offset\n * is distance based is approximately half of a pixel in the plane parallel to the\n * view at the HUD origin.\n *\n * @param normalModel {vec3} the normal in model/world space.\n * @param posModel {vec3} (inout) the position in model/world space. This value will\n *   be updated with the additional vertical offset.\n * @param posView {vec3} (inout) the position in view space. This value is used to\n *   determine the distance to the HUD origin and will also be updated with the\n *   additional vertical offset.\n *\n * Dependencies:\n *\n *   Uniforms:\n *     - perDistancePixelRatio: world units per distance per pixel.\n *     - cameraGroundRelative: indicates whether camera is above (1) or below (-1) ground.\n *     - viewNormal: the view normal transformation.\n */\nvoid applyHUDVerticalGroundOffset(vec3 normalModel, inout vec3 posModel, inout vec3 posView) {\n  float distanceToCamera = length(posView);\n\n  // Compute offset in world units for a half pixel shift\n  float pixelOffset = distanceToCamera * perDistancePixelRatio * 0.5;\n\n  // Apply offset along normal in the direction away from the ground surface\n  vec3 modelOffset = normalModel * cameraGroundRelative * pixelOffset;\n\n  // Apply the same offset also on the view space position\n  vec3 viewOffset = (viewNormal * vec4(modelOffset, 1.0)).xyz;\n\n  posModel += modelOffset;\n  posView += viewOffset;\n}\n\n/**\n  * Project the 3d position of a HUD object from world space to clip space. In addition\n  * to standard model view projection, it also emulates a polygon offset to\n  * help with points above/below ground and icon flickering. The resulting location\n  * is the anchor of the HUD object, i.e. the position that is used also for testing\n  * visibility of the HUD object. Note that the returned projected position is not\n  * aligned to a pixel center or border, it is up to the caller to align if necessary.\n  *\n  * Dependencies:\n  *\n  *   Attributes:\n  *     - position: contains the point world position\n  *     - normal: contains the world normal pointing up at the point\n  *     - auxpos1: contains centerOffset and pointGroundDistance\n  *\n  *   Uniforms:\n  *     - model: the object -> world transformation matrix\n  *     - modelNormal: the object -> world normal transformation matrix (inv transp of model)\n  *     - view: the world -> view transformation matrix\n  *     - viewNormal: the world -> view normal transformation matrix (inv transp of view)\n  *     - proj: the view -> clip projection matrix\n  *     - verticalOffset: a vec4 containing:\n  *         - the screen height of the vertical offset\n  *         - the screen height of the vertical offset as a fraction of camera distance.\n  *         - the minimum world size vertical offset.\n  *         - the maximum world size vertical offset.\n  *       This will do a screen sized offset of the point along its normal (used for line callouts)\n  *     - screenSizePerspectiveAlignment: a vec3 containing\n  *         - the view distance dependent divisor\n  *         - the view distance dependent offset\n  *         - the minimum pixel size\n  *         - the amount of padding in pixels around the region to be scaled (not used for alignment)\n  *     - cameraGroundRelative: indicates whether camera is above (1) or below (-1) ground.\n  *         This is used for emulated polygon offset for improved visibility of points sitting on the surface.\n  *     - polygonOffset: a constant polygon offset to bring the point closer to the viewer for\n  *         reduced flickering.\n  *     - camPos: the position of the camera in world space\n  *     - viewport: the viewport [x, y, width, height]\n  */\nvec4 projectPositionHUD(out ProjectHUDAux aux) {\n  // centerOffset is in view space and is used to implement world size offsetting\n  // of labels with respect to objects. It also pulls the label towards the viewer\n  // so that the label is visible in front of the object.\n  vec3 centerOffset = auxpos1.xyz;\n\n  // The pointGroundDistance is the distance of the geometry to the ground and is\n  // negative if the point is below the ground, or positive if the point is above\n  // ground.\n  float pointGroundDistance = auxpos1.w;\n\n  aux.posModel = (model * vec4(position, 1.0)).xyz;\n  aux.posView = (view * vec4(aux.posModel, 1.0)).xyz;\n  aux.vnormal = (modelNormal * vec4(normal, 1.0)).xyz;\n\n  applyHUDVerticalGroundOffset(aux.vnormal, aux.posModel, aux.posView);\n\n  // Screen sized offset in world space, used for example for line callouts\n  // Note: keep this implementation in sync with the CPU implementation, see\n  //   - MaterialUtil.verticalOffsetAtDistance\n  //   - HUDMaterial.applyVerticalOffsetTransformation\n\n  aux.distanceToCamera = length(aux.posView);\n\n  vec3 viewDirObjSpace = normalize(camPos - aux.posModel);\n  float cosAngle = dot(aux.vnormal, viewDirObjSpace);\n\n  aux.absCosAngle = abs(cosAngle);\n\n#ifdef SCREEN_SIZE_PERSPECTIVE\n\n#if defined(VERTICAL_OFFSET) || defined(CENTER_OFFSET_UNITS_SCREEN)\n  vec4 perspectiveFactor = screenSizePerspectiveScaleFactor(aux.absCosAngle, aux.distanceToCamera, screenSizePerspectiveAlignment);\n#endif\n\n#endif\n\n#ifdef VERTICAL_OFFSET\n\n#ifdef SCREEN_SIZE_PERSPECTIVE\n  float verticalOffsetScreenHeight = applyScreenSizePerspectiveScaleFactorFloat(verticalOffset.x, perspectiveFactor);\n#else\n  float verticalOffsetScreenHeight = verticalOffset.x;\n#endif\n\n  float worldOffset = clamp(verticalOffsetScreenHeight * verticalOffset.y * aux.distanceToCamera, verticalOffset.z, verticalOffset.w);\n  vec3 modelOffset = aux.vnormal * worldOffset;\n\n  aux.posModel += modelOffset;\n\n  vec3 viewOffset = (viewNormal * vec4(modelOffset, 1.0)).xyz;\n  aux.posView += viewOffset;\n\n  // Since we elevate the object, we need to take that into account\n  // in the distance to ground\n  pointGroundDistance += worldOffset;\n\n#endif\n\n  float groundRelative = applyHUDViewDependentPolygonOffset(pointGroundDistance, aux.absCosAngle, aux.posView);\n\n#ifndef CENTER_OFFSET_UNITS_SCREEN\n  // Apply x/y in view space, but z in screen space (i.e. along posView direction)\n  aux.posView += vec3(centerOffset.x, centerOffset.y, 0.0);\n\n  // Same material all have same z != 0.0 condition so should not lead to\n  // branch fragmentation and will save a normalization if it's not needed\n  if (centerOffset.z != 0.0) {\n    aux.posView -= normalize(aux.posView) * centerOffset.z;\n  }\n#endif\n\n  vec4 posProj = proj * vec4(aux.posView, 1.0);\n\n#ifdef CENTER_OFFSET_UNITS_SCREEN\n\n#ifdef SCREEN_SIZE_PERSPECTIVE\n  float centerOffsetY = applyScreenSizePerspectiveScaleFactorFloat(centerOffset.y, perspectiveFactor);\n#else\n  float centerOffsetY = centerOffset.y;\n#endif\n\n  posProj.xy += vec2(centerOffset.x, centerOffsetY) * pixelRatio * 2.0 / viewport.zw * posProj.w;\n\n#endif\n\n  // constant part of polygon offset emulation\n  posProj.z -= groundRelative * polygonOffset * posProj.w;\n\n  return posProj;\n}\n\nuniform float uRenderTransparentlyOccludedHUD;\n\n/**\n  * Test for visibility of a HUD object.\n  *\n  * Dependencies:\n  *\n  *   Uniforms:\n  *     - hudVisibilityTexture: the texture that contains the visibility information\n  *     - markerColor: the special marker color that is used to write visibility information\n  *     - viewport: the viewport\n  */\nbool testVisibilityHUD(vec4 posProj) {\n  // For occlusion testing, use the nearest pixel center to avoid\n  // subpixel filtering messing up the color we use to test for\n  vec4 posProjCenter = alignToPixelCenter(posProj, viewport.zw);\n\n  vec4 occlusionPixel = texture2D(hudVisibilityTexture, .5 + .5 * posProjCenter.xy / posProjCenter.w);\n\n  // the red pixel here indicates that the occlusion pixel passed the depth test against solid geometry and was written\n  // the green pixel stores transparency of transparent geometry (1.0 -> fully transparent)\n  // note that we also check against green == 0.0, i.e. transparent geometry that has opaque parts\n\n  // thus we render visible pixels that are occluded by semi-transparent (but not fully transparent!) geometry here\n  if (uRenderTransparentlyOccludedHUD > 0.5) {\n    // multiplying by uRenderTransparentlyOccludedHUD allows us to ignore the second condition if\n    // uRenderTransparentlyOccludedHUD = 0.75\n    return occlusionPixel.r * occlusionPixel.g > 0.0 && occlusionPixel.g * uRenderTransparentlyOccludedHUD < 1.0;\n  }\n  // and visible pixels that are not occluded by semi-transparent geometry here\n  else {\n    return occlusionPixel.r * occlusionPixel.g > 0.0 && occlusionPixel.g == 1.0;\n  }\n\n  // return texture2D(hudVisibilityTexture, .5 + .5 * posProjCenter.xy / posProjCenter.w).r > 0.0;\n}\n","normalEncoding.glsl":"vec3 decodeNormal(vec2 f) {\n    float z = 1.0 - abs(f.x) - abs(f.y);\n    return vec3(f + sign(f) * min(z, 0.0), z);\n}\n","quad.vert":"#include <util/vsPrecision.glsl>\n\nattribute vec2 position;\nvarying vec2 uv;\n\nvoid main(void) {\n  gl_Position = vec4(position.x, position.y, .0, 1.0);\n  uv = position * .5 + vec2(.5);\n}\n","sceneLighting.glsl":"// Scene Lighting Definitions:\n// ================================\n\n// defines:\n//   - SH_ORDER: 1|2|3\n// input:\n//   - normal: vec3\n//   - albedo: vec3\n//   - shadow: float\n//   - ssao: float\n// return:\n//   - color: vec3\n\n// main light\n/////////////////////////////////////////\nuniform vec3 lightingMainDirection;\nuniform vec3 lightingMainIntensity;\n\n// ambient lighting\n/////////////////////////////////////////\n#ifndef SH_ORDER\n  #define SH_ORDER 2\n#endif\n\n#if SH_ORDER == 0\n  uniform vec3 lightingAmbientSH0;\n#elif SH_ORDER == 1\n  uniform vec4 lightingAmbientSH_R;\n  uniform vec4 lightingAmbientSH_G;\n  uniform vec4 lightingAmbientSH_B;\n#elif SH_ORDER == 2\n  uniform vec3 lightingAmbientSH0;\n  uniform vec4 lightingAmbientSH_R1;\n  uniform vec4 lightingAmbientSH_G1;\n  uniform vec4 lightingAmbientSH_B1;\n  uniform vec4 lightingAmbientSH_R2;\n  uniform vec4 lightingAmbientSH_G2;\n  uniform vec4 lightingAmbientSH_B2;\n#endif\n\n// special tweaking\n//////////////////////////////////////////\nuniform float lightingFixedFactor;\nuniform float lightingGlobalFactor;\n\nuniform float ambientBoostFactor;\n\n// evaluation\n//////////////////////////////////////////\n\nvec3 evaluateSceneLighting(vec3 normal, vec3 albedo, float shadow, float ssao, vec3 additionalLight) {\n  // evaluate the main light\n  #if defined(TREE_RENDERING)\n    // Special case for tree rendering:\n    // We shift the Lambert lobe to the back, allowing it to reach part of the hemisphere\n    // facing away from the light. The idea is to get an effect where light is transmitted\n    // through the tree.\n    float minDot = -0.5;\n    float dotRange = 1.0 - minDot;\n    float dotNormalization = 0.66; // guessed & hand tweaked value, for an exact value we could precompute an integral over the sphere\n\n    float dotVal = dotNormalization * (clamp(-dot(normal, lightingMainDirection), 1.0 - dotRange, 1.0) - minDot) * (1.0 / dotRange);\n  #else\n    float dotVal = clamp(-dot(normal, lightingMainDirection), 0.0, 1.0);\n  #endif\n\n  // move lighting towards (1.0, 1.0, 1.0) if requested\n  dotVal = mix(dotVal, 1.0, lightingFixedFactor);\n\n  vec3 mainLight = (1.0 - shadow) * lightingMainIntensity * dotVal;\n\n  // evaluate the sh ambient light\n  #if SH_ORDER == 0\n    vec3 ambientLight = 0.282095 * lightingAmbientSH0;\n  #elif SH_ORDER == 1\n    vec4 sh0 = vec4(\n      0.282095,\n      0.488603 * normal.x,\n      0.488603 * normal.z,\n      0.488603 * normal.y\n    );\n    vec3 ambientLight = vec3(\n      dot(lightingAmbientSH_R, sh0),\n      dot(lightingAmbientSH_G, sh0),\n      dot(lightingAmbientSH_B, sh0)\n    );\n  #elif SH_ORDER == 2\n    vec3 ambientLight = 0.282095 * lightingAmbientSH0;\n\n    vec4 sh1 = vec4(\n      0.488603 * normal.x,\n      0.488603 * normal.z,\n      0.488603 * normal.y,\n      1.092548 * normal.x * normal.y\n    );\n    vec4 sh2 = vec4(\n      1.092548 * normal.y * normal.z,\n      0.315392 * (3.0 * normal.z * normal.z - 1.0),\n      1.092548 * normal.x * normal.z,\n      0.546274 * (normal.x * normal.x - normal.y * normal.y)\n    );\n    ambientLight += vec3(\n      dot(lightingAmbientSH_R1, sh1),\n      dot(lightingAmbientSH_G1, sh1),\n      dot(lightingAmbientSH_B1, sh1)\n    );\n    ambientLight += vec3(\n      dot(lightingAmbientSH_R2, sh2),\n      dot(lightingAmbientSH_G2, sh2),\n      dot(lightingAmbientSH_B2, sh2)\n    );\n  #endif\n  ambientLight *= (1.0 - ssao);\n\n  // inverse gamma correction on the albedo color\n  float gamma = 2.1;\n  vec3 albedoGammaC = pow(albedo, vec3(gamma));\n\n  // physically correct BRDF normalizes by PI\n  const float PI = 3.14159;\n  vec3 totalLight = mainLight + ambientLight + additionalLight;\n  totalLight = min(totalLight, vec3(PI, PI, PI));\n  vec3 outColor = vec3((albedoGammaC / PI) * (totalLight));\n\n  // apply gamma correction to the computed color\n  outColor = pow(outColor, vec3(1.0/gamma));\n\n  return outColor;\n}\n\nvec3 sceneLightingAdditionalLightGlobal(vec3 worldPos, float ssao, out float additionalAmbientScale) {\n  // heuristic lighting model originally used in the terrain shading\n  // now used to generated additional ambient light\n\n#if VIEWING_MODE == VIEWING_MODE_GLOBAL\n    float vndl = -dot(normalize(worldPos), lightingMainDirection);\n#else\n    float vndl = -dot(vec3(0.0, 0.0, 1.0), lightingMainDirection);\n#endif\n\n  additionalAmbientScale = smoothstep(0.0, 1.0, clamp(vndl * 2.5, 0.0, 1.0));\n  return ssao * lightingMainIntensity * additionalAmbientScale * ambientBoostFactor * lightingGlobalFactor;\n}\n","screenSizePerspective.glsl":"// Note that the implementation here should be kept in sync with the corresponding\n// CPU implementation (used for hitTest etc) in screenSizePerspectiveUtils.ts\n\n/**\n * Compute the screen size perspective lower bound from pre-computed screen\n * size perspective factors (or parameters, since both store the pixel lower\n * bound information in the same place). When computing the minimum size,\n * the padding (e.g. text halo) is scaled with the same factor as the\n * original size scales to reach the minimum size.\n *\n * {\n *    x: N/A\n *    y: N/A\n *    z: minPixelSize (abs),\n *    w: sizePaddingInPixels (abs)\n * }\n */\nfloat screenSizePerspectiveMinSize(float size, vec4 factor) {\n\n  // Original calculation:\n  //   padding = 2 * factor.w\n  //   minSize = factor.z\n  //\n  //   minSize + minSize / size * padding\n  //\n  // Incorporates padding (factor.w, e.g. text halo size) into the\n  // minimum bounds calculation, taking into account that padding\n  // would scale down proportionally to the size.\n  //\n  // Calculation below is the same, but avoids division by zero when\n  // size would be zero, without branching using step.\n  // https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/10683\n\n  // nonZeroSize is 1 if size > 0, and 0 otherwise\n  float nonZeroSize = 1.0 - step(size, 0.0);\n\n  return (\n    factor.z * (\n      1.0 +\n      nonZeroSize *                // Multiply by nzs ensures if size is 0, then we ignore\n                                   // proportionally scaled padding\n      2.0 * factor.w / (\n        size + (1.0 - nonZeroSize) // Adding 1 - nzs ensures we divide either by size, or by 1\n      )\n    )\n  );\n}\n\n/**\n * Computes the view angle dependent screen size perspective factor. The goal\n * of this factor is that:\n *\n *   1. There is no perspective when looking top-down\n *   2. There is a smooth and quick transition to full perspective when\n *      tilting.\n */\nfloat screenSizePerspectiveViewAngleDependentFactor(float absCosAngle) {\n  return absCosAngle * absCosAngle * absCosAngle;\n}\n\n/**\n * Precomputes a set of factors that can be used to apply screen size perspective\n * The factors are based on the viewing angle, distance to camera and the screen size\n * perspective parameters:\n * {\n *    x: distanceDivisor,\n *    y: distanceOffset,\n *    z: minPixelSize (abs),\n *    w: sizePaddingInPixels (abs)\n * }\n *\n * The result is a set of factors that can be used to apply the perspective:\n *\n * {\n *    x: distance based relative scale factor (0 -> 1)\n *    y: view dependent scale factor\n *    z: minPixelSize (abs)\n *    w: sizePaddingInPixels (abs)\n * }\n */\nvec4 screenSizePerspectiveScaleFactor(float absCosAngle, float distanceToCamera, vec4 params) {\n  return vec4(min(params.x / (distanceToCamera - params.y), 1.0), screenSizePerspectiveViewAngleDependentFactor(absCosAngle), params.z, params.w);\n}\n\n/**\n * Applies screen size perspective factors to a single dimension size, given the viewing angle,\n * distance to camera and perspective parameters. The factors can be calculated from the screen size\n * perspective parameters using screenSizePerspectiveScaleFactorFloat.\n *\n * Note that for single scale application, the screenSizePerspectiveScaleFloat can be used, which\n * will call this method, providing it the factors calculated from screenSizePerspectiveScaleFactorFloat.\n */\n\nfloat applyScreenSizePerspectiveScaleFactorFloat(float size, vec4 factor) {\n  return max(mix(size * factor.x, size, factor.y), screenSizePerspectiveMinSize(size, factor));\n}\n\n/**\n * Applies screen size perspective parameters to a single dimension size, given the viewing angle,\n * distance to camera and perspective parameters\n * {\n *    x: distanceDivisor,\n *    y: distanceOffset,\n *    z: minPixelSize (abs),\n *    w: sizePaddingInPixels (abs)\n * }\n */\nfloat screenSizePerspectiveScaleFloat(float size, float absCosAngle, float distanceToCamera, vec4 params) {\n  return applyScreenSizePerspectiveScaleFactorFloat(size, screenSizePerspectiveScaleFactor(absCosAngle, distanceToCamera, params));\n}\n\n/**\n * Applies screen size perspective factors to a vec2 size (width/height), given the viewing angle,\n * distance to camera and perspective parameters. The factors can be calculated from the screen size\n * perspective parameters using screenSizePerspectiveScaleFactorVec2.\n *\n * Note that for single scale application, the screenSizePerspectiveScaleVec2 can be used, which\n * will call this method, providing it the factors calculated from screenSizePerspectiveScaleFactorVec2.\n */\nvec2 applyScreenSizePerspectiveScaleFactorVec2(vec2 size, vec4 factor) {\n  return mix(size * clamp(factor.x, screenSizePerspectiveMinSize(size.y, factor) / size.y, 1.0), size, factor.y);\n}\n\n/**\n * Applies screen size perspective parameters to a vec2 size (width/height), given the viewing angle,\n * distance to camera and perspective parameters\n * {\n *    x: distanceDivisor,\n *    y: distanceOffset,\n *    z: minPixelSize (abs),\n *    w: sizePaddingInPixels (abs)\n * }\n */\nvec2 screenSizePerspectiveScaleVec2(vec2 size, float absCosAngle, float distanceToCamera, vec4 params) {\n  return applyScreenSizePerspectiveScaleFactorVec2(size, screenSizePerspectiveScaleFactor(absCosAngle, distanceToCamera, params));\n}\n","shadow.glsl":'#include <util/encoding.glsl>\n\n// "matrix" parameter used to have const qualifier as well, but IE11 couldn\'t deal with it at time of writing.\n// once IE11 is fine with it, const should probably be re-introduced\nfloat evalShadow(const in vec3 vpos, const in float depth, const in sampler2D depthTex, const int num, const in vec4 distance, in mat4 matrix[4], const in float halfPxSz) {\n  //choose correct cascade\n  int i = depth < distance[1] ? 0 : depth < distance[2] ? 1 : depth < distance[3] ? 2 : 3;\n\n  if (i >= num) { return .0; }\n\n  mat4 mat = i == 0 ? matrix[0] : i == 1 ? matrix[1] : i == 2 ? matrix[2] : matrix[3];\n\n  vec4 lv = mat * vec4(vpos, 1.0);\n  lv.xy /= lv.w;\n\n  //vertex completely outside? -> no shadow\n  vec3 lvpos = .5 * lv.xyz + vec3(.5);\n  if (lvpos.z >= 1.0) { return .0; }\n  if (lvpos.x < .0 || lvpos.x > 1.0 || lvpos.y < .0 || lvpos.y > 1.0) { return .0; }\n\n  //calc coord in cascade texture\n  vec2 uv = vec2(float(i - 2 * (i / 2)) *.5, float(i / 2) * .5) + .5 * lvpos.xy;\n\n  float texSize = .5 / halfPxSz;\n\n  //filter, offset by half pixels\n  vec2 st = fract((vec2(halfPxSz) + uv) * texSize);\n\n  float s00 = rgba2float(texture2D(depthTex, uv + vec2(-halfPxSz, -halfPxSz))) < lvpos.z ? 1.0 : .0;\n  float s10 = rgba2float(texture2D(depthTex, uv + vec2(halfPxSz, -halfPxSz))) < lvpos.z ? 1.0 : .0;\n  float s11 = rgba2float(texture2D(depthTex, uv + vec2(halfPxSz, halfPxSz))) < lvpos.z ? 1.0 : .0;\n  float s01 = rgba2float(texture2D(depthTex, uv + vec2(-halfPxSz, halfPxSz))) < lvpos.z ? 1.0 : .0;\n\n  return mix(mix(s00, s10, st.x), mix(s01, s11, st.x), st.y);\n}\n',"slice.glsl":"#ifdef SLICE\nuniform vec3 slicePlaneOrigin;\nuniform vec3 slicePlaneBasis1;\nuniform vec3 slicePlaneBasis2;\n\nstruct SliceFactors {\n  float front;\n  float side0;\n  float side1;\n  float side2;\n  float side3;\n};\n\nSliceFactors calculateSliceFactors(vec3 pos) {\n  vec3 rel = pos - slicePlaneOrigin;\n\n  vec3 slicePlaneNormal = -cross(slicePlaneBasis1, slicePlaneBasis2);\n  float slicePlaneW = -dot(slicePlaneNormal, slicePlaneOrigin);\n\n  float basis1Len2 = dot(slicePlaneBasis1, slicePlaneBasis1);\n  float basis2Len2 = dot(slicePlaneBasis2, slicePlaneBasis2);\n\n  float basis1Dot = dot(slicePlaneBasis1, rel);\n  float basis2Dot = dot(slicePlaneBasis2, rel);\n\n  return SliceFactors(\n    dot(slicePlaneNormal, pos) + slicePlaneW,\n    -basis1Dot - basis1Len2,\n    basis1Dot - basis1Len2,\n    -basis2Dot - basis2Len2,\n    basis2Dot - basis2Len2\n  );\n}\n\nbool sliceByFactors(SliceFactors factors) {\n  return factors.front < 0.0\n    && factors.side0 < 0.0\n    && factors.side1 < 0.0\n    && factors.side2 < 0.0\n    && factors.side3 < 0.0;\n}\n\nbool sliceByPlane(vec3 pos) {\n  return sliceByFactors(calculateSliceFactors(pos));\n}\n\n#ifdef EXTENSIONS_ENABLED\n\nvec4 applySliceHighlight(vec4 color, vec3 pos) {\n  SliceFactors factors = calculateSliceFactors(pos);\n\n  if (sliceByFactors(factors)) {\n    return color;\n  }\n\n  const float HIGHLIGHT_WIDTH = 1.0;\n  const vec4 HIGHLIGHT_COLOR = vec4(0.0, 0.0, 0.0, 0.3);\n\n  factors.front /= (2.0 * HIGHLIGHT_WIDTH) * fwidth(factors.front);\n  factors.side0 /= (2.0 * HIGHLIGHT_WIDTH) * fwidth(factors.side0);\n  factors.side1 /= (2.0 * HIGHLIGHT_WIDTH) * fwidth(factors.side1);\n  factors.side2 /= (2.0 * HIGHLIGHT_WIDTH) * fwidth(factors.side2);\n  factors.side3 /= (2.0 * HIGHLIGHT_WIDTH) * fwidth(factors.side3);\n\n  float highlightFactor = (1.0 - step(0.5, factors.front))\n    * (1.0 - step(0.5, factors.side0))\n    * (1.0 - step(0.5, factors.side1))\n    * (1.0 - step(0.5, factors.side2))\n    * (1.0 - step(0.5, factors.side3));\n\n  return mix(color, vec4(HIGHLIGHT_COLOR.rgb, color.a), highlightFactor * HIGHLIGHT_COLOR.a);\n}\n\n#else // EXTENSIONS_ENABLED\n\n// GL_OES_standard_derivatives must be enabled for applySliceHighlight\n\n#endif // EXTENSIONS_ENABLED\n\n#define rejectBySlice(_pos_) sliceByPlane(_pos_)\n#define discardBySlice(_pos_) { if (sliceByPlane(_pos_)) discard; }\n#define highlightSlice(_color_, _pos_) applySliceHighlight(_color_, _pos_)\n\n#else // SLICE\n\n#define rejectBySlice(_pos_) false\n#define discardBySlice(_pos_) {}\n#define highlightSlice(_color_, _pos_) (_color_)\n\n#endif // SLICE\n","visualVariables.glsl":"#if defined(VV_SIZE)\n  #define VV_CUSTOM_MODEL_MATRIX\n#endif\n\n#if defined(VV_SIZE)\n  uniform vec3 vvSizeMinSize;\n  uniform vec3 vvSizeMaxSize;\n  uniform vec3 vvSizeOffset;\n  uniform vec3 vvSizeFactor;\n#elif defined(VV_CUSTOM_MODEL_MATRIX)\n  uniform vec3 vvSizeValue;\n#endif\n\n#ifdef VV_CUSTOM_MODEL_MATRIX\n  uniform mat3 vvSymbolRotationMatrix;\n#endif\n\n#ifdef VV_CUSTOM_MODEL_MATRIX\n  uniform vec3 vvSymbolAnchor;\n#endif\n\n#ifdef VV_COLOR\n  #define VV_COLOR_N 8\n  uniform float vvColorValues[VV_COLOR_N];\n  uniform vec4 vvColorColors[VV_COLOR_N];\n#endif\n\n// Evaluation of size\n#if defined(VV_SIZE)\n  vec3 vvGetScale(vec4 featureAttribute) {\n    return clamp(vvSizeOffset + featureAttribute.x * vvSizeFactor, vvSizeMinSize, vvSizeMaxSize);\n  }\n#elif defined(VV_CUSTOM_MODEL_MATRIX)\n  vec3 vvGetScale(vec4 featureAttribute) {\n    return vvSizeValue;\n  }\n#endif\n\n// Applying the model matrix\n#ifdef VV_CUSTOM_MODEL_MATRIX\n  vec4 vvTransformPosition(vec3 position, vec4 featureAttribute) {\n    return vec4(vvSymbolRotationMatrix * (vvGetScale(featureAttribute) * (position + vvSymbolAnchor)), 1.0);\n  }\n\n  vec4 vvTransformNormal(vec3 normal, vec4 featureAttribute) {\n    // Normal transform is the inverse transpose of model transform\n    return vec4(vvSymbolRotationMatrix * normal / vvGetScale(featureAttribute), 1.0);\n  }\n#endif\n\n#ifdef VV_COLOR\n  vec4 vvGetColor(vec4 featureAttribute, float values[VV_COLOR_N], vec4 colors[VV_COLOR_N]) {\n    float value = featureAttribute.y;\n    if (value <= values[0]) {\n      return colors[0];\n    }\n\n    for (int i = 1; i < VV_COLOR_N; ++i) {\n      if (values[i] >= value) {\n        float f = (value - values[i-1]) / (values[i] - values[i-1]);\n        return mix(colors[i-1], colors[i], f);\n      }\n    }\n\n    return colors[VV_COLOR_N - 1];\n  }\n#endif\n","vsPrecision.glsl":"precision highp float;\nprecision highp sampler2D;\n"}}});